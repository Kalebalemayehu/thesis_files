Authors,Title,DOI,Link,Abstract,Author Keywords,Index Keywords
"Abbasi R., Martinez P., Ahmad R.","An ontology model to represent aquaponics 4.0 system's knowledge","10.1016/j.inpa.2021.12.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122809334&doi=10.1016%2fj.inpa.2021.12.001&partnerID=40&md5=e8528d133d47189d1e509725ade28060","Aquaponics, one of the vertical farming methods, is a combination of aquaculture and hydroponics. To enhance the production capabilities of the aquaponics system and maximize crop yield on a commercial level, integration of Industry 4.0 technologies is needed. Industry 4.0 is a strategic initiative characterized by the fusion of emerging technologies such as big data and analytics, internet of things, robotics, cloud computing, and artificial intelligence. The realization of aquaponics 4.0, however, requires an efficient flow and integration of data due to the presence of complex biological processes. A key challenge in this essence is to deal with the semantic heterogeneity of multiple data resources. An ontology that is regarded as one of the normative tools solves the semantic interoperation problem by describing, extracting, and sharing the domains’ knowledge. In the field of agriculture, several ontologies are developed for the soil-based farming methods, but so far, no attempt has been made to represent the knowledge of the aquaponics 4.0 system in the form of an ontology model. Therefore, this study proposes a unified ontology model, AquaONT, to represent and store the essential knowledge of an aquaponics 4.0 system. This ontology provides a mechanism for sharing and reusing the aquaponics 4.0 system's knowledge to solve the semantic interoperation problem. AquaONT is built from indoor vertical farming terminologies and is validated and implemented by considering experimental test cases related to environmental parameters, design configuration, and product quality. The proposed ontology model will help vertical farm practitioners with more transparent decision-making regarding crop production, product quality, and facility layout of the aquaponics farm. For future work, a decision support system will be developed using this ontology model and artificial intelligence techniques for autonomous data-driven decisions. © 2021 China Agricultural University","Aquaponics 4.0; Decision support system; Industry 4.0; Knowledge modeling; Ontology modeling","Agricultural technology; Artificial intelligence; Crops; Cultivation; Data Analytics; Decision making; Decision support systems; Hydroponics; Industry 4.0; Product design; Quality control; Semantics; Aquaponic; Aquaponic 4.0; Aquaponic system; Interoperation problem; Knowledge model; Ontology model; Ontology's; Production capabilities; Products quality; System knowledge; Ontology; aquaculture; automation; decision support system; hydroponics; knowledge; modeling"
"Abdollahnejadbarough H., Mupparaju K.S., Shah S., Golding C.P., Leites A.C., Popp T.D., Shroyer E., Golany Y.S., Robinson A.G., Akgun V.","Verizon uses advanced analytics to rationalize its tail spend suppliers","10.1287/inte.2020.1038","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087161022&doi=10.1287%2finte.2020.1038&partnerID=40&md5=a24b23a4a1a432709faa5d4969f14788","The Verizon Global Supply Chain organization currently manages thousands of active supplier contracts. These contracts account for several billion dollars of annualized Verizon spend. Managing thousands of suppliers, controlling spend, and achieving the best price per unit (PPU) through negotiations are costly and labor-intensive tasks handled by Verizon strategic sourcing teams. Verizon engages thousands of suppliers for many reasons-best price, diversity, short-term requirements, and so forth. Whereas managing a few larger spend suppliers can be done manually by dedicated sourcing managers, managing thousands of smaller suppliers at the tail spend is challenging, can often introduce risk, and can be expensive. At Verizon, a unique blend of descriptive, predictive, and prescriptive analytics, as well as Verizon-specific sourcing acumen was leveraged to tackle this problem and rationalize Verizon's tail spend suppliers. Through the creative application of operations research, machine learning, text mining, natural language processing, and artificial intelligence, Verizon reduced spend by millions of dollars and acquired the lowest PPU for the sourced products and services. Other benefits Verizon realized were centralized and transparent contract and supplier relationship management, overhead cost reduction, decreased contract execution lead time, and service quality improvement for Verizon's strategic sourcing teams. © 2020 INFORMS Inst.for Operations Res.and the Management Sciences. All rights reserved.","Business process outsourcing; Global procurement; Spend analytics; Strategic sourcing; Supplier rationalization",
"Aejas B., Bouras A., Belhi A., Gasmi H.","Smart Contracts Implementation Based on Bidirectional Encoder Representations from Transformers","10.1007/978-3-030-94335-6_21","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125260403&doi=10.1007%2f978-3-030-94335-6_21&partnerID=40&md5=8c546d0a2158dcc144450c521db38704","The distribution and immutability properties of blockchains made it possible to use them in various fields, such as Supply Chain, finance and health. The automation of the creation and execution of transactions in a blockchain in a decentralized and transparent manner is realized through Smart Contracts programming codes. This paper presents the implementation of Smart Contracts in specific manufacturing Supply Chains and discusses their life cycle and impact on the Supply Chain management. The presented application deals with the possibility of transforming natural language contracts of a given Supply Chain to automated Smart Contracts that makes the Supply Chain management faster and safer. A first solution is proposed based on Bidirectional Encoder Representations from Transformers (BERT) model and limited to the implementation of Smart Contracts of the Supply Chain legal contracts. Also described here is the ways of extracting contract elements from legal contracts by applying the BERT Deep Learning method on annotated contract dataset of a corpus of 13000 annotations over 510 contracts. © 2022, IFIP International Federation for Information Processing.","BERT; Blockchain; NLP; Smart Contract; Supply chain","Blockchain; Deep learning; Life cycle; Signal encoding; Supply chain management; Bidirectional encoder representation from transformer; Block-chain; Decentralised; Learning methods; Legal contracts; Natural languages; Programming codes; Property; Supply chain finances; Transformer modeling; Smart contract"
"Aguilar-Palacios C., Munoz-Romero S., Rojo-Alvarez J.L.","Causal Quantification of Cannibalization during Promotional Sales in Grocery Retail","10.1109/ACCESS.2021.3062222","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101755246&doi=10.1109%2fACCESS.2021.3062222&partnerID=40&md5=2720a7a194c134d291dba26477f2faff","In food and grocery retail, sales cannibalisation during promotions occurs when a promoted product has a knock-on effect on the sales of a non-promoted one. The quantification of its effect is important for retailers, as cannibalisation can lead to wasted food and lost profits. The performance of promotions is ultimately dependent on their features but also on the characteristics of the stores, i.e. type of store or its location. Generally speaking, there is no homogeneous response to a promotion, and by extension to sales cannibalisation. Accordingly, in this paper we describe a framework to analyse the effects of cannibalisation due to individual promotions based on the relationship amongst their sales. The novelty of our work resides in understanding cannibalisation as a causal effect where the increase in sales of the promoted product is partly due to the decrease in sales of the non-promoted one. As such, we propose to use causal inference to measure the impact of cannibalisation due to promotions. Our method reviews each product that has been on promotion, searching for potential cannibals, given by products whose promotion have resulted in large sales uplifts, and for the fall-outs, given by those products experiencing a reduction in sales due to the cannibals. Then each cannibal-victim pair is analysed with Causal Impact, a time-series method which allows one to infer the causal effect of an intervention. We demonstrate the practical application of detecting cannibalisation on vast datasets of promotions within several stores and their many departments. To provide with an overview of the cannibalisation for entire departments and not simply for individual products, we build a directed graph. This is both unique and of utmost value to store managers and marketing teams. Additionally, we discuss in the Appendix the application of explainable forecasting to cannibalisation on a surrogate model. © 2013 IEEE.","Causal inference; interpretable machine learning (iML); retail promotions; sales cannibalization; supply chain","Chemical contamination; Directed graphs; Human resource management; Causal inferences; Knock-on effect; Large sales; Marketing team; Surrogate model; Time series method; Sales"
"Aguilar-Palacios C., Munoz-Romero S., Rojo-Alvarez J.L.","Cold-Start Promotional Sales Forecasting through Gradient Boosted-Based Contrastive Explanations","10.1109/ACCESS.2020.3012032","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089577655&doi=10.1109%2fACCESS.2020.3012032&partnerID=40&md5=e45e58d49cf3ab8f30e7eb77197c5bde","Multiple Machine Learning solutions in Industry exist where interpretability is required. In retail, this is especially important when dealing with cold-start forecasting of promotional sales. In the planning phase of these promotions, retailers produce sales predictions that are scrutinised by both forecasting experts and managers. In this paper, we combine the predictive benefits of Gradient Boosted Decision Trees regressors and the interpretability of contrastive explanations. These are implicitly generated by the manner we shape data. Our method presents the cold-start forecasts in relation to the observed promotional sales of other products, which we call neighbours. They are selected based on a measure of closeness to the predicted promotion, which is derived from the variable importance calculated during the training of the regressors. With this information, the expert reviewer adjusts the cold-start prediction by simply varying the contribution of the neighbours. To validate our results we test our method on a surrogate model, as well as on real-market data. The results on the surrogate model demonstrate that our method is able to accurately identify the features that contribute to sales and then select the closest neighbours to produce a contrastive explanation. The results on real-market data also show that the proposed method performs at a similar level to widespread methods such as conventional CatBoost, NGBoost or AutoGluon, and has the advantage of providing interpretability. © 2013 IEEE.","Cold-start forecasting; contrastive explanations; interpretable ML (iML); retail promotions; supply chain","Commerce; Decision trees; Forecasting; Personnel training; Boosted decision trees; Interpretability; Multiple machine; Planning phase; Real markets; Sales forecasting; Surrogate model; Variable importances; Sales"
"Aguilar-Palacios C., Munoz-Romero S., Rojo-Alvarez J.L.","Forecasting Promotional Sales Within the Neighbourhood","10.1109/ACCESS.2019.2920380","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068347274&doi=10.1109%2fACCESS.2019.2920380&partnerID=40&md5=083e43af2ae33d8678ecec452f5689c6","Promotions are a widely used strategy to engage consumers and as such, retailers dedicate immense effort and resources to their planning and forecasting. This paper introduces a novel interpretable machine learning method specifically tailored to the automatic prediction of promotional sales in real-market applications. Particularly, we present fully automated weighted k-nearest neighbors where the distances are calculated based on a feature selection process that focuses on the similarity of promotional sales. The method learns online, thereby avoiding the model being retrained and redeployed. It is robust and able to infer the mechanisms leading to sales as demonstrated on detailed surrogate models. Also, to validate this method, real market data provided by a worldwide retailer have been used, covering numerous categories from three different countries and several types of stores. The algorithm is benchmarked against an ensemble of regression trees and the forecast provided by the retailer and it outperforms both on a merit figure composed not only by the mean absolute error but also by the error deviations used in the retail business. The proposed method significantly improves the accuracy of the forecast in many diverse categories and geographical locations, yielding significant and operative benefits for supply chains. Additionally, we briefly discuss in the Appendix how to deploy our method as a RESTful service in a production environment. © 2013 IEEE.","Automated feature selection; non-negative least squares; online learning; predictive models; promotions; supply chain; weighted k-nearest neighbors","Commerce; Feature extraction; Forecasting; Motion compensation; Nearest neighbor search; Sales; Supply chains; Trees (mathematics); Automated features; Least Square; Online learning; Predictive models; promotions; Weighted k-nearest neighbors; Learning systems"
"Aguirre-Zapata E., Morales H., Dagatti C.V., di Sciascio F., Amicarelli A.N.","Semi physical growth model of Lobesia botrana under laboratory conditions for Argentina's Cuyo region","10.1016/j.ecolmodel.2021.109803","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119932566&doi=10.1016%2fj.ecolmodel.2021.109803&partnerID=40&md5=178bad598f92a33dfa267e6b20229be1","Lobesia botrana is a quarantine pest from Argentina and other countries in the world. It causes damage to the vine in its different growth stages leading to losses in wine production. To develop pest control strategies based on knowledge of the moth, different mathematical models can be found in specific literature to predict its biological cycle, establish its relationship with environmental variables, describe the voltinism of the pest, among others. Based on the proposed models, it is possible to establish a minimum temperature threshold considering the development of the moth and the number of degrees’ days (DD) that must be accumulated for there to be a change of stage. Many of these models are empirical. They are limited because they do not consider some variables such as growth and mortality rates, also they lack a conceptual basis. This makes that professionals or institutions interested in the development of decision support systems (DSS) may not use them. This also prevents them from being easily extrapolated to other regions of the world. In this work, a semi-physical model based on first principles (FPBSM) is proposed to describe how the different growth stages of the vine moth change quantitatively throughout its normal development time under controlled and specific laboratory conditions for the Cuyo region in Argentina. The proposed model, based on a white box structure, considers important parameters in the development of the moth, such as growth and mortality rates. Opposite to the models reported in the literature, the proposed model is conceptually more simple, easy to calculate or adjust, and Its parameters are interpretable in the model's application context. The previous characteristics facilitate the proposal model's use by sectors interested in the development of DSS systems. The reported mathematical model has been validated with experimental data for three different temperature conditions. © 2021 Elsevier B.V.","European grape moth; FPBSM; Lobesia botrana; Mathematical modeling","Artificial intelligence; Population statistics; Wine; Argentina; Different growth stages; European grape moth; FPBSM; Growth models; Laboratory conditions; Lobesium botranum; Mathematical modeling; Model-based OPC; Mortality rate; Decision support systems; crop pest; growth rate; mortality; moth; numerical model; quarantine; vine; Argentina; Lobesia botrana"
"Ahmed M.A., Chatterjee M., Dadure P., Pakray P.","The Role of Biased Data in Computerized Gender Discrimination","10.1145/3524501.3527599","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138406970&doi=10.1145%2f3524501.3527599&partnerID=40&md5=c6a81196e14f8d6fb6df056669fcbfa6","Gender bias is prevalent in all walks of life from schools to colleges, corporate as well as government offices. This has led to the under-representation of the female gender in many professions. Most of the Artificial Intelligence-Natural Language Processing (AI-NLP) models learning from these underrepresented real world datasets amplify the bias in many cases, resulting in traditional biases being reinforced. In this paper, we have discussed how gender bias became ingrained in our society and how it results in the underrepresentation of the female gender in several fields such as education, healthcare, STEM, film industry, food industry, and sports. We shed some light on how traditional gender bias is reflected in AI-NLP systems such as automated resume screening, machine translation, text generation, etc. Future prospects of these AI-NLP applications need to include possible solutions to these existing biased AI-NLP applications, such as debiasing the word embeddings and having guidelines for more ethical and transparent standards. ACM Reference Format: Md. Arshad Ahmed, Madhura Chatterjee, Pankaj Dadure, and Partha Pakray. 2022. The Role of Biased Data in Computerized Gender Discrimination. In Third Workshop on Gender Equality, Diversity, and Inclusion in Software Engineering (GE@ICSE'22), May 20, 2022, Pittsburgh, PA, USA. ACM, New York, NY, USA, 6 pages. https://doi.org/10.1145/3524501.3527599 © 2022 ACM.","Artificial Intelligence; Debiasing; Gender Bias; Natural Language Processing","Natural language processing systems; Software engineering; Corporate offices; De-biasing; Gender bias; Gender discrimination; Government offices; Language processing; Natural language processing; Natural language processing applications; Natural languages; Processing model; Artificial intelligence"
"Ahmed M.S., Tazwar M.T., Khan H., Roy S., Iqbal J., Rabiul Alam M.G., Hassan M.R., Hassan M.M.","Yield Response of Different Rice Ecotypes to Meteorological, Agro-Chemical, and Soil Physiographic Factors for Interpretable Precision Agriculture Using Extreme Gradient Boosting and Support Vector Regression","10.1155/2022/5305353","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139490887&doi=10.1155%2f2022%2f5305353&partnerID=40&md5=91ebeaa7d8d3c6f433b56bbc7949f169","The food security of more than half of the world's population depends on rice production which is one of the key objectives of precision agriculture. The traditional rice almanac used astronomical and climate factors to estimate yield response. However, this research integrated meteorological, agro-chemical, and soil physiographic factors for yield response prediction. Besides, the impact of those factors on the production of three major rice ecotypes has also been studied in this research. Moreover, this study found a different set of those factors with respect to the yield response of different rice ecotypes. Machine learning algorithms named Extreme Gradient Boosting (XGBoost) and Support Vector Regression (SVR) have been used for predicting the yield response. The SVR shows better results than XGBoost for predicting the yield of the Aus rice ecotype, whereas XGBoost performs better for forecasting the yield of the Aman and Boro rice ecotypes. The result shows that the root mean squared error (RMSE) of three different ecotypes are in between 9.38% and 24.37% and that of R-squared values are between 89.74% and 99.13% on two different machine learning algorithms. Moreover, the explainability of the models is also shown in this study with the help of the explainable artificial intelligence (XAI) model called Local Interpretable Model-Agnostic Explanations (LIME). © 2022 Md. Sabbir Ahmed et al.",,"Adaptive boosting; Food supply; Forecasting; Lime; Machine learning; Mean square error; Agro-chemicals; Food security; Gradient boosting; Key objective; Machine learning algorithms; Precision Agriculture; Rice production; Support vector regressions; World population; Yield response; Precision agriculture"
"Albraikan A.A., Aljebreen M., Alzahrani J.S., Othman M., Mohammed G.P., Ibrahim Alsaid M.","Modified Barnacles Mating Optimization with Deep Learning Based Weed Detection Model for Smart Agriculture","10.3390/app122412828","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144865047&doi=10.3390%2fapp122412828&partnerID=40&md5=8a7a7681a3b0b8a1b4c8817c90d46af4","Weed control is a significant means to enhance crop production. Weeds are accountable for 45% of the agriculture sector’s crop losses, which primarily occur because of competition with crops. Accurate and rapid weed detection in agricultural fields was a difficult task because of the presence of a wide range of weed species at various densities and growth phases. Presently, several smart agriculture tasks, such as weed detection, plant disease detection, species identification, water and soil conservation, and crop yield prediction, can be realized by using technology. In this article, we propose a Modified Barnacles Mating Optimization with Deep Learning based weed detection (MBMODL-WD) technique. The MBMODL-WD technique aims to automatically identify the weeds in the agricultural field. Primarily, the presented MBMODL-WD technique uses the Gabor filtering (GF) technique for the noise removal process. For automated weed detection, the presented MBMODL-WD technique uses the DenseNet-121 model as feature extraction with the MBMO algorithm as hyperparameter optimization. The design of the MBMO algorithm involves the integration of self-population-based initialization with the standard BMO algorithm. At last, the Elman Neural Network (ENN) method was applied for the weed classification process. To demonstrate the enhanced performance of the MBMODL-WD approach, a series of simulation analyses were performed. A comprehensive set of simulations highlighted the enhanced performance of the presented MBMODL-WD methodology over other DL models with a maximum accuracy of 98.99%. © 2022 by the authors.","computer vision; crop productivity; deep learning; smart agriculture; weed management",
"Alonso R.S., Sittón-Candanedo I., García Ó., Prieto J., Rodríguez-González S.","An intelligent Edge-IoT platform for monitoring livestock and crops in a dairy farming scenario","10.1016/j.adhoc.2019.102047","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076174369&doi=10.1016%2fj.adhoc.2019.102047&partnerID=40&md5=820e8334fe1a78f763d927e6ba88ec0e","Today's globalized and highly competitive world market has broadened the spectrum of requirements in all the sectors of the agri-food industry. This paper focuses on the dairy industry, on its need to adapt to the current market by becoming more resource efficient, environment-friendly, transparent and secure. The Internet of Things (IoT), Edge Computing (EC) and Distributed Ledger Technologies (DLT) are all crucial to the achievement of those improvements because they allow to digitize all parts of the value chain, providing detailed information to the consumer on the final product and ensuring its safety and quality. In Smart Farming environments, IoT and DLT enable resource monitoring and traceability in the value chain, allowing producers to optimize processes, provide the origin of the produce and guarantee its quality to consumers. In comparison to a centralized cloud, EC manages the Big Data generated by IoT devices by processing them at the network edge, allowing for the implementation of services with shorter response times, and a higher Quality of Service (QoS) and security. This work presents a platform oriented to the application of IoT, Edge Computing, Artificial Intelligence and Blockchain techniques in Smart Farming environments, by means of the novel Global Edge Computing Architecture, and designed to monitor the state of dairy cattle and feed grain in real time, as well as ensure the traceability and sustainability of the different processes involved in production. The platform is deployed and tested in a real scenario on a dairy farm, demonstrating that the implementation of EC contributes to a reduction in data traffic and an improvement in the reliability in communications between the IoT-Edge layers and the Cloud. © 2019 Elsevier B.V.","Distributed ledger technologies; Edge computing; Internet of things; Livestock monitoring; Precision agriculture; Smart farming","Agriculture; Computer architecture; Edge computing; International trade; Precision agriculture; Quality of service; Sustainable development; Agri-food industry; Application of iot; Computing architecture; Environment friendly; Internet of thing (IOT); Resource monitoring; Resource-efficient; Smart farming; Internet of things"
"Andre C.M., Soukoulis C.","Food quality assessed by chemometrics","10.3390/foods9070897","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091295170&doi=10.3390%2ffoods9070897&partnerID=40&md5=9ebe6bb81d8c08b0b96d55459d0a9f00","Food market globalization, food security as well as increasing consumer demand for safe, minimally processed and healthy food impose the need to establish new approaches for identifying and assessing food quality markers. Nowadays, food industry stakeholders are challenged to assure food quality and safety without compromising several prerequisites such as sustainable and ecologically resilient food production, prolonged shelf life, satisfactory sensory quality, enhanced nutritional value and health-promoting properties. In addition, food fraud related to deliberate product mislabeling or economically intended adulteration is of major concern for both industry and regulatory authorities due to cost and public health implications. Notwithstanding the great number of state-of-the-art analytical tools available for quantifying food quality markers, their implementation results in highly complex and big datasets, which are not easily interpretable. In this context, chemometrics e.g., supervised and unsupervised multivariate exploratory analyses, design-of-experiment methodology, univariate or multivariate regression modelling etc., are commonly implemented as part of food process optimization and food quality assessment. In this Special Issue, we aimed to publish innovative research and perspective papers on chemometric-assisted case studies relating to food quality assessment, food authenticity, mathematical modelling and optimization of processes involved in food manufacturing. © 2020 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (http://creativecommons.org/licenses/by/4.0/).","Chemometrics; Data mining; Food authenticity; Food product development; Food quality; Foodomics; Process optimization and modelling",
"Arun P.V., Karnieli A.","Learning of physically significant features from earth observation data: an illustration for crop classification and irrigation scheme detection","10.1007/s00521-022-07019-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126222781&doi=10.1007%2fs00521-022-07019-5&partnerID=40&md5=7082dfb11012a0b9b44df96501e4be30","Earth observation data processing requires interpretable deep learning (DL) models that learn physically significant and meaningful features. The current study proposes approaches to make the network to learn meaningful features. In addition, a set of interpretability- and explanation-based evaluation strategies are proposed to evaluate the DL models. Adversarial variational encoding along with constraints to regulate latent representations and embed label information are employed to learn interpretable manifold. The proposed architecture, called interpretable adversarial encoding network (IAENet), significantly improves the results compared to other main existing DL models. The proposed IAENet learns the features which are essential in distinguishing the different classes thereby improving the interpretability of the model. The explanations for the different models are generated through analysis of the concepts learned by each model using activation maximization. Besides, the relevance assigned by the model to input features is also estimated using the layer-wise relevance propagation approach. Experiments on the phenological curve-based crop classification illustrate that IAENet learn relevant features (giving importance to the non-rainy season) to distinguish different irrigation schemes. The performance can be attributed to the learned interpretable manifold, and the refinement of architectural units and convolutions considering the point-nature and irregular sampling of the input data. Experiments on learning crop-specific features from multispectral images for crop-type classification indicate that IAENet learns red and green edge features crucial in distinguishing the studied crops. The improvement in interpretability of the DL models is found to reduce the sensitivity toward network parameters. The proposed evaluation measures facilitate ascertaining the physical significance of the learned manifold. © 2022, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.","Classification; Crop-specific features; Deep learning; Interpretability; Phenological curves; VENµS","Activation analysis; Classification (of information); Data handling; Deep learning; Encoding (symbols); Irrigation; Signal encoding; Crop classification; Crop-specific feature; Deep learning; Earth observation data; Interpretability; Irrigation schemes; Learn+; Learning models; Phenological curve; VENµS; Crops"
"Asmussen C.B., Møller C.","Smart literature review: a practical topic modelling approach to exploratory literature review","10.1186/s40537-019-0255-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073674481&doi=10.1186%2fs40537-019-0255-7&partnerID=40&md5=d4dc3b907cdb315d1f62a2f1679e27f0","Manual exploratory literature reviews should be a thing of the past, as technology and development of machine learning methods have matured. The learning curve for using machine learning methods is rapidly declining, enabling new possibilities for all researchers. A framework is presented on how to use topic modelling on a large collection of papers for an exploratory literature review and how that can be used for a full literature review. The aim of the paper is to enable the use of topic modelling for researchers by presenting a step-by-step framework on a case and sharing a code template. The framework consists of three steps; pre-processing, topic modelling, and post-processing, where the topic model Latent Dirichlet Allocation is used. The framework enables huge amounts of papers to be reviewed in a transparent, reliable, faster, and reproducible way. © 2019, The Author(s).","Automatic literature review; Latent Dirichlet Allocation; Supply chain management; Topic modelling",
"Bilgin A., Hagras H., Van Helvert J., Alghazzawi D.","A Linear General Type-2 Fuzzy-Logic-Based Computing with Words Approach for Realizing an Ambient Intelligent Platform for Cooking Recipe Recommendation","10.1109/TFUZZ.2015.2453400","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963900015&doi=10.1109%2fTFUZZ.2015.2453400&partnerID=40&md5=50c5f59d8950b5163ababe159764fd70","This paper addresses the need to enhance transparency in ambient intelligent environments by developing more natural ways of interaction, which allow the users to communicate easily with the hidden networked devices rather than embedding obtrusive tablets and computing equipment throughout their surroundings. Ambient intelligence vision aims to realize digital environments that adapt to users in a responsive, transparent, and context-aware manner in order to enhance users' comfort. It is, therefore, appropriate to employ the paradigm of 'computing with words' (CWWs), which aims to mimic the ability of humans to communicate transparently and manipulate perceptions via words. One of the daily activities that would increase the comfort levels of the users (especially people with disabilities) is cooking and performing tasks in the kitchen. Existing approaches on food preparation, cooking, and recipe recommendation stress on healthy eating and balanced meal choices while providing limited personalization features through the use of intrusive user interfaces. Herein, we present an application, which transparently interacts with users based on a novel CWWs approach in order to predict the recipe's difficulty level and to recommend an appropriate recipe depending on the user's mood, appetite, and spare time. The proposed CWWs framework is based on linear general type-2 (LGT2) fuzzy sets, which linearly quantify the linguistic modifiers in the third dimension in order to better represent the user perceptions while avoiding the drawbacks of type-1 and interval type-2 fuzzy sets. The LGT2-based CWWs framework can learn from user experiences and adapt to them in order to establish more natural human-machine interaction. We have carried numerous real-world experiments with various users in the University of Essex intelligent flat. The comparison analysis between interval type-2 fuzzy sets and LGT2 fuzzy sets demonstrates up to 55.43% improvement when general type-2 fuzzy sets are used than when interval type-2 fuzzy sets are used instead. The quantitative and qualitative analysis both show the success of the system in providing a natural interaction with the users for recommending food recipes where the quantitative analysis shows the high statistical correlation between the system output and the users' feedback; the qualitative analysis presents social science evaluation confirming the strong user acceptance of the system. © 1993-2012 IEEE.","ambient intelligence; computing with words; general type-2 fuzzy sets","Artificial intelligence; Computation theory; Cooking; Fuzzy sets; Human computer interaction; Soft computing; Thermal processing (foods); User interfaces; Ambient intelligence; Ambient intelligent environments; Computing with word (CWW); Computing with words approaches; General type-2 fuzzy sets; Human machine interaction; Interval type-2 fuzzy sets; Quantitative and qualitative analysis; Fuzzy logic"
"Brock Porth C., Porth L., Zhu W., Boyd M., Tan K.S., Liu K.","Remote Sensing Applications for Insurance: A Predictive Model for Pasture Yield in the Presence of Systemic Weather","10.1080/10920277.2020.1717345","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079362308&doi=10.1080%2f10920277.2020.1717345&partnerID=40&md5=787a3b359861069a148fdb4eebc22b52","A robust predictive model for crop yield is essential for designing a commercially viable index-based insurance policy. Index-based insurance for crops is still at a relatively infant stage, and more research and development is needed in order to address a main limitation, which is referred to as basis risk. Traditionally, ground weather station measurements have been the most common approach used in weather indices, and this approach has often led to high levels of basis risk. Recent advances in satellite-based remote sensing provide new opportunities to use publicly available and transparent “big data,” to potentially make index-based insurance policies more relevant by reducing basis risk. This is the first article to provide a comprehensive comparison of 13 pasture production indices (PPIs), including those developed based on satellite-derived vegetation and biophysical parameter indices using data products from the Moderate Resolution Imaging Spectroradiometer (MODIS). A validation protocol is established, and a unique dataset covering the period 2002 to 2016 from a network of pasture clip sites in the province of Alberta, Canada, is used to demonstrate new applications for insurance based on remote sensing–derived data. The results of the satellite-derived PPIs are compared to PPIs based on ground weather station data as benchmarks, which to date are the most common design for index-based insurance. Overall, the satellite-based indices report higher correlations with the ground truth forage yield data compared to the weather station PPIs. As an example, in 2015 and 2016 the best performing satellite-based PPIs produced correlations close to 90%. When considering the whole sample period, the highest overall average correlation is 62.0% for the biophysical parameter PPI based on FPAR 500-m MODIS, and the lowest overall average correlation is 43.8% for the vegetation PPI based on EVI 250-m MODIS. Comparatively, the highest correlation reported for the weather station indices is for precipitation, at 12.51%. Other predictive models based on principal component analysis and shrinkage methods (such as lasso, ridge regression, and elastic net) are considered to address the issues of variable selection and dimension reduction in insurance design. This research makes an important contribution to the field of actuarial science and insurance, because it highlights potential new opportunities for insurance design and predictive analytics using large and comprehensive satellite datasets that remain relatively unexplored to date in insurance practice. Though forage is used as the example here, the research could be extended to other crops, and other areas in the property and casualty sector, including for fire and flood. © 2020, © 2020 Society of Actuaries.",,
"Cao Y., Yuan P., Xu H., Martínez-Ortega J.F., Feng J., Zhai Z.","Detecting Asymptomatic Infections of Rice Bacterial Leaf Blight Using Hyperspectral Imaging and 3-Dimensional Convolutional Neural Network With Spectral Dilated Convolution","10.3389/fpls.2022.963170","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134972978&doi=10.3389%2ffpls.2022.963170&partnerID=40&md5=759276157f9df366f9e2f5db1d126c44","Rice is one of the most important food crops for human beings. Its total production ranks third in the grain crop output. Bacterial Leaf Blight (BLB), as one of the three major diseases of rice, occurs every year, posing a huge threat to rice production and safety. There is an asymptomatic period between the infection and the onset periods, and BLB will spread rapidly and widely under suitable conditions. Therefore, accurate detection of early asymptomatic BLB is very necessary. The purpose of this study was to test the feasibility of detecting early asymptomatic infection of the rice BLB disease based on hyperspectral imaging and Spectral Dilated Convolution 3-Dimensional Convolutional Neural Network (SDC-3DCNN). First, hyperspectral images were obtained from rice leaves infected with the BLB disease at the tillering stage. The spectrum was smoothed by the Savitzky–Golay (SG) method, and the wavelength between 450 and 950 nm was intercepted for analysis. Then Principal Component Analysis (PCA) and Random Forest (RF) were used to extract the feature information from the original spectra as inputs. The overall performance of the SDC-3DCNN model with different numbers of input features and different spectral dilated ratios was evaluated. Lastly, the saliency map visualization was used to explain the sensitivity of individual wavelengths. The results showed that the performance of the SDC-3DCNN model reached an accuracy of 95.4427% when the number of inputs is 50 characteristic wavelengths (extracted by RF) and the dilated ratio is set at 5. The saliency-sensitive wavelengths were identified in the range from 530 to 570 nm, which overlaps with the important wavelengths extracted by RF. According to our findings, combining hyperspectral imaging and deep learning can be a reliable approach for identifying early asymptomatic infection of the rice BLB disease, providing sufficient support for early warning and rice disease prevention. Copyright © 2022 Cao, Yuan, Xu, Martínez-Ortega, Feng and Zhai.","asymptomatic infection; bacterial leaf blight; deep learning; hyperspectral imaging; interpretable; spectral dilated convolution",
"Carrières V., Lemieux A.-A., Pellerin R.","Opportunities of Blockchain Traceability Data for Environmental Impact Assessment in a Context of Sustainable Production","10.1007/978-3-030-85874-2_13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115272679&doi=10.1007%2f978-3-030-85874-2_13&partnerID=40&md5=1108460f8c559586a2698d323aeb524d","Supply chains face various challenges for collecting reliable, transparent, and up-to-date data due to their increased complexity and globalization. This threatens their sustainability and limits the efficiency of environmental impact assessment of products with Life Cycle Assessment (LCA) methodology. This paper explores the opportunities, limitations, and research paths for assessing products' environmental impact using blockchain-based traceability data based on a systematic literature review. Results showed that blockchains are mainly used for product traceability and could be further used for the environmental impact assessment of products. A first architecture model and integration framework was proposed in the literature for the integration of blockchain-based LCA systems. However, the maturity of blockchain and supply chain organization are the prevalent barriers to implementing these systems. Further research is essential to shape these first results with strong opportunities identified. © 2021, IFIP International Federation for Information Processing.","Blockchain; Environmental impact; LCA; Literature review; Sustainability; Traceability","Artificial intelligence; Blockchain; Environmental impact; Environmental impact assessments; Industrial management; Supply chains; Sustainable development; Architecture modeling; Chain organizations; Integration frameworks; Life Cycle Assessment (LCA); Product traceability; Sustainable production; Systematic literature review; Life cycle"
"Chakraborty D., Başağaoğlu H., Alian S., Mirchi A., Moriasi D.N., Starks P.J., Verser J.A.","Multiscale extrapolative learning algorithm for predictive soil moisture modeling & applications","10.1016/j.eswa.2022.119056","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141268640&doi=10.1016%2fj.eswa.2022.119056&partnerID=40&md5=2f1eb9dd79c904c3e067ae34c83db9f7","We present Multiscale Extrapolative Learning Algorithm (MELA) as a novel artificial-intelligence (AI)-based data extrapolator. MELA is capable of extending temporally limited local hydroclimatic measurements at fine spatial resolution to longer periods, using remotely-sensed hydroclimatic data readily available for longer periods but at coarse spatial resolution. We demonstrate the implementation of MELA to extrapolate the monthly local soil moisture measurements at multiple depths from 2015–2021 to 1958–2021 in a semi-arid region. Such data extrapolators are imperative to generate longer historical data needed to adequately train and test AI models while enhancing the chance of capturing the effects of extreme climates on spatially variable soil moisture. The MELA-extrapolated local soil moisture subsequently allowed the construction of monthly time-series of field-scale soil moisture distributions with a normalized accuracy of 72% and prediction of countywide annual winter wheat yields – using MELA-extrapolated soil moisture data and eXplainable AI (XAI) – with a normalized accuracy of 81%. Furthermore, the XAI model ranked the predictors based on their importance in estimating winter wheat yields, in which the soil moisture near the surface and in the root zone and precipitation totals were found to be more influential than temperature on crop yields in the semi-arid region. The XAI model also unveiled the inflection points of the predictors beyond which crop yields would increase or decrease. Moreover, the AI-based analyses in conjunction with climate projections from global climate models suggest potential reductions in rainfed crop yields in the study area by 2050 and 2100 in the absence of climate-resilient mitigation and adaptation plans. © 2022 The Author(s)","Artificial Intelligence; Climate change impacts; Crop yield analysis; Data generator; Soil moisture analysis","Arid regions; Artificial intelligence; Climate change; Climate models; Crops; Extrapolation; Image resolution; Soil moisture; Climate change impact; Crop yield; Crop yield analyse; Data generator; Hydroclimatic; Semi-arid region; Soil moisture analysis; Spatial resolution; Winter wheat yields; Yield analysis; Learning algorithms"
"Chung W.W.C., Wong K.C.M., Soon P.T.K.","An ANN-based DSS system for quality assurance in production network","10.1108/17410380710817282","https://www.scopus.com/inward/record.uri?eid=2-s2.0-34548444663&doi=10.1108%2f17410380710817282&partnerID=40&md5=dd64888d65ff1769852155f591ef6d2f","Purpose - The purpose of this paper is to propose an integrated model of decision support system (DSS), artificial neural network, information and communication technologies and statistical process control (SPC) to facilitate agreement by different stakeholders with special interests to commit to the decision that will be taken to stop the production line when something goes wrong somewhere in a supplier network environment. Design/methodology/approach - A DSS is proposed to capture exceptional signals from source on deterioration of product quality to alert preventive actions needed before the problems are getting out of hand. The supervisors are given a set of guidelines to support making the decision. Real-time SPC and rule-based decision support procedures are used to trigger pre-defined exceptional signals for forwarding to the most appropriate person (the knowledge holder in the problem domain) to make a decision to stop the line. All servers in all remote sites are internet-connected and provide real-time quality data to the regional supply chain manager. A case study is described to show how this is implemented in a lens manufacturing company. Findings - A significant improvement in quality level can be achieved by holding the knowledge worker accountable for making the decision to stop the production line rather than made by default as is with most traditional operations. Practical implications - To provide a concept to structure activities for decision support so that the persons responsible for making the decision to stop the production line is held accountable by all stakeholders. Originality/value - Practitioners can replicate the approach used in this paper to their own situations involving decisions to be made to address un-structured problems and unclear responsibilities. © Emerald Group Publishing Limited.","Communication technologies; Decision support systems; Decision-making; Neural nets; Problem solving; Statistical process control","Decision making; Neural networks; Problem solving; Quality assurance; Statistical process control; Supply chains; Communication technologies; Product quality; Production network; Decision support systems"
"Coulibaly S., Kamsu-Foguem B., Kamissoko D., Traore D.","Explainable deep convolutional neural networks for insect pest recognition","10.1016/j.jclepro.2022.133638","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136281253&doi=10.1016%2fj.jclepro.2022.133638&partnerID=40&md5=8377edfd70224c189d5e276c8361d134","Fungal infestation of crops is critical to food security as it affects yield and quality of production. Indeed, one element responsible for this situation is insect pests. Early detection of pests based on parcel images is a real challenge in the context of precision agriculture. Nowadays, technical advances in deep neural networks have led to better results in all areas, including crop health management in agriculture. Despite these satisfactory results of deep neural networks in image classification tasks, one of the drawbacks is that it is difficult to decode what the neural networks have learned. The proposed method consists of identifying and locating insect pests in crops using a Convolutional Neural Network (CNN). The localization of insects from the input data is based on explainability methods. For this, explainability highlights the colors and shapes captured by the CNNs using visualization maps. This provides opportunities for human interaction with the learning system for validation of the results provided by the CNN models. In this study, we used over 75,000 images for 102 different pest categories from the IP102 reference dataset. Various explainability methods are combined to formally interpret insect location. The degree of combination is quantified by the mutual information score. The obtained results allow a better interpretation of the reasoning performed by the deep learning system and identified an optimal number of feature extraction layers. Consequently, we simplified a CNN model by decreasing the number of network parameters by 58.90%. This facilitates their explanation in the field of plant science for the effective application in crop diagnosis. © 2022 Elsevier Ltd","Deep learning; Explainability of neural networks; Image classification; Insect pest detection in crops; Transfer learning","Convolution; Convolutional neural networks; Deep neural networks; Food supply; Image classification; Learning systems; Transfer learning; Convolutional neural network; Deep learning; Explainability of neural network; Food security; Images classification; Insect pest detection in crop; Insects pests; Neural network model; Neural-networks; Transfer learning; Crops"
"Cox H., Mowatt S.","Consumer-driven innovation networks and e-business management systems","10.1108/13522750410512840","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84993099325&doi=10.1108%2f13522750410512840&partnerID=40&md5=833f1e899e6acb8a4f4f9b41b706170d","This paper examines the use of consumer-driven innovation networks within the UK food-retailing industry using qualitative interview-based research analysed within an economic framework. This perspective revealed that, by exploiting information gathered directly from their customers at point-of-sale and data mining, supermarkets are able to identify consumer preferences and co-ordinate new product development via innovation networks. This has been made possible through their information control of the supply-chain established through the use of transparent inventory management systems. As a result, supermarkets’ e-business systems have established new competitive processes in the UK food-processing and retailing industry and are an example of consumer-driven innovation networks. The informant-based qualitative approach also revealed that trust-based transacting relationships operated differently from those previously described in the literature. © 2004, Emerald Group Publishing Limited","Complexity theory; Consumers; Electronic commerce; Inventory control; Supplier relations; Trust",
"Daglarli E.","Explainable artificial intelligence (xAI) approaches and deep meta-learning models for cyber-physical systems","10.4018/978-1-7998-5101-1.ch003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137479143&doi=10.4018%2f978-1-7998-5101-1.ch003&partnerID=40&md5=829f309d0502930d25c812a0e93675f1","Today, the effects of promising technologies such as explainable artificial intelligence (xAI) and meta-learning (ML) on the internet of things (IoT) and the cyber-physical systems (CPS), which are important components of Industry 4.0, are increasingly intensified. However, there are important shortcomings that current deep learning models are currently inadequate. These artificial neural network based models are black box models that generalize the data transmitted to it and learn from the data. Therefore, the relational link between input and output is not observable. For these reasons, it is necessary to make serious efforts on the explanability and interpretability of black box models. In the near future, the integration of explainable artificial intelligence and meta-learning approaches to cyber-physical systems will have effects on a high level of visualization and simulation infrastructure, real-time supply chain, cyber factories with smart machines communicating over the internet, maximizing production efficiency, analysis of service quality and competition level. © 2021, IGI Global.",,
"Danilevicz M.F., Bayer P.E., Boussaid F., Bennamoun M., Edwards D.","Maize yield prediction at an early developmental stage using multispectral images and genotype data for preliminary hybrid selection","10.3390/rs13193976","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116465740&doi=10.3390%2frs13193976&partnerID=40&md5=a9aa15704c73807d2d9bbcb8325c4ecd","Assessing crop production in the field often requires breeders to wait until the end of the season to collect yield-related measurements, limiting the pace of the breeding cycle. Early prediction of crop performance can reduce this constraint by allowing breeders more time to focus on the highest-performing varieties. Here, we present a multimodal deep learning model for predicting the performance of maize (Zea mays) at an early developmental stage, offering the potential to accelerate crop breeding. We employed multispectral images and eight vegetation indices, collected by an uncrewed aerial vehicle approximately 60 days after sowing, over three consecutive growing cycles (2017, 2018 and 2019). The multimodal deep learning approach was used to integrate field management and genotype information with the multispectral data, providing context to the conditions that the plants experienced during the trial. Model performance was assessed using holdout data, in which the model accurately predicted the yield (RMSE 1.07 t/ha, a relative RMSE of 7.60% of 16 t/ha, and R2 score 0.73) and identified the majority of high-yielding varieties, outperforming previously published models for early yield prediction. The inclusion of vegetation indices was important for model performance, with a normalized difference vegetation index and green with normalized difference vegetation index contributing the most to model performance. The model provides a decision support tool, identifying promising lines early in the field trial. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Computer vision; Crop breeding; Explainable artificial intelligence; High-throughput phenotyping; Machine learning; Multimodal learning; Uncrewed aerial vehicles; Vegetation indices; Zea mays","Antennas; Computer vision; Cultivation; Decision support systems; Deep learning; Forecasting; Grain (agricultural product); Unmanned aerial vehicles (UAV); Vegetation; Crop breeding; Developmental stage; Explainable artificial intelligence; High-throughput phenotyping; Modeling performance; Multi-modal learning; Uncrewed aerial vehicles; Vegetation index; Yield prediction; Zea mays; Crops"
"De Clercq D., Wen Z., Fei F., Caicedo L., Yuan K., Shang R.","Interpretable machine learning for predicting biomethane production in industrial-scale anaerobic co-digestion","10.1016/j.scitotenv.2019.134574","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077512775&doi=10.1016%2fj.scitotenv.2019.134574&partnerID=40&md5=9f837acd69dd9a8898fdcc85d1766a0a","The objective of this study is to apply machine learning models to accurately predict daily biomethane production in an industrial-scale co-digestion facility. The methodology involved applying elasticnet, random forest, and extreme gradient boosting to input–output data from an industrial-scale anaerobic co-digestion (ACoD) facility. The models were used to predict biomethane for 1-day, 3-day, 5-day, 10-day, 20-day, 30-day, and 40-day time horizons. These models were fit on four years of operational data. The results showed that elastic net (a model with assumptions of linearity) was clearly outperformed by random forest and extreme gradient boosting (XGBoost), which had out-of-sample R2 values ranging between 0.80 and 0.88, depending on the time horizon. In addition, feature importance and partial dependence analysis demonstrated the marginal and interaction effects on biomethane of selected biowaste inputs. For instance, food waste co-digested with percolate were shown to have strong positive interaction effects. One implication of this study is that XGBoost and random forest algorithms applied to industrial-scale ACoD data provide dependable prediction results and may be a useful complement for experimental and mechanistic/theoretical models of anaerobic digestion, especially where detailed substrate characterization is difficult. However, these models have limitations, and suggestions for deriving additional value from these methods are proposed. © 2019 Elsevier B.V.","Anaerobic co-digestion; Biomethane; Machine learning; Random forest; XGBoost","Decision trees; Forecasting; Learning systems; Machine learning; Anaerobic co-digestion; Biomethane; Machine learning models; Positive interaction; Random forest algorithm; Random forests; Substrate characterization; XGBoost; Anaerobic digestion; anaerobic digestion; biogas; data interpretation; gas production; input-output analysis; machine learning; methane; prediction; anaerobic digestion; article; elastic tissue; food waste; prediction; random forest; theoretical study; anaerobic growth; food; machine learning; waste disposal; methane; Anaerobiosis; Food; Machine Learning; Methane; Refuse Disposal"
"Deponte H., Tonda A., Gottschalk N., Bouvier L., Delaplace G., Augustin W., Scholl S.","Two complementary methods for the computational modeling of cleaning processes in food industry","10.1016/j.compchemeng.2020.106733","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078057056&doi=10.1016%2fj.compchemeng.2020.106733&partnerID=40&md5=01844870bcfa03045c456f1ee5cf625b","Insufficient cleaning in the food industry can create serious hygienic risks. However, when attempting to avoid these risks, food-processing plants frequently tend to clean for too long, at extremely high temperatures, or with too many chemicals, resulting in high cleaning costs and severe environmental impacts. Therefore, the optimization of cleaning processes in the food industry has significant economic and ecological potential. Unfortunately, in-situ assessments of cleaning processes are difficult, and the multitude of different cleaning situations complicates the definition of a comprehensive approach. In this study, two methodological approaches for the comprehensive modeling of cleaning processes are introduced. The resulting models facilitate comparisons of different cleaning processes and they can be scaled up for processes with similar conditions, using cleaning time as a response. A dimensional analysis is performed to obtain general results and to allow transfer of the approaches to other cleaning situations. The models are established according to the statistical rules for the deduction of multiple regression equations for the prediction of the response based on the input parameters. The terms of the model equation are confirmed with a significance analysis. A machine learning approach is also used to create model equations with symbolic regression. Both methods and the obtained model equations are validated. The two applied approaches reveal similar significant terms and models. Significant dimensionless numbers are the Reynolds number, the density number that describes the ratio of the density of the soil to the density of the cleaning agent, and the soil number, which is a new dimensionless number that characterizes the properties of food soils. The methodology of both approaches is transparent; therefore, the resulting equations can be compared and similarities are found. Both methods are deemed applicable for the computational modeling of cleaning processes in food industry. © 2020","Cleaning process; Dimensional analysis; Food industry; Machine learning; Statistical analysis; Symbolic regression","Chemical contamination; Computation theory; Environmental impact; Learning systems; Machine learning; Regression analysis; Reynolds number; Soils; Statistical methods; Thermal processing (foods); Cleaning process; Dimensional analysis; Food industries; Food processing plants; Machine learning approaches; Methodological approach; Multiple regression equations; Symbolic regression; Cleaning"
"Doreswamy, Gad I., Manjunatha B.R.","Hybrid data warehouse model for climate big data analysis","10.1109/ICCPCT.2017.8074229","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037334607&doi=10.1109%2fICCPCT.2017.8074229&partnerID=40&md5=00c041bee3417a7d88c30b660c6c366a","The amount of data being collected and stored in the world is a highly unprecedented rate. The management and processing of huge data sets are time-consuming, costly, and hindrance to research. So, the process to store, manage, analyze and extract meaningful value from the vast volume of data is a big challenge to researchers. Data warehouse is a Decision Support System (DSS) technology that allows extracting, grouping and analyzing historical data from different sources in order to discover information relevant to decision making. Climate data is collected and stored in the national climatic data center (NCDC), the format of dataset support a rich set of meteorological elements. The data warehouse has the ability to manage data having a huge size in Terabytes range or higher, data is collected from different meteorological stations and stored in records to analyze it later in future. The process of big data analysis has become increasingly important for climate analysis field, which requires rapid and transparent data access. Recently, a new distributed computing paradigm, called MapReduce and it is implemented in an open source Hadoop, which has been widely adopted due to its impressive scalability and flexibility to handle structured, unstructured and semi-structured data. The purpose of this paper is to develop a conceptual data model and the implementation of hybrid data warehouse model to store NCDC's weather variables. The hybrid data warehouse model for climate big data enables the identification of weather patterns that would be useful for agriculture fields, climatic change studies and contingency plans over weather extreme conditions. © 2017 IEEE.","Data Warehouse; Hadoop; Hive; NCDC data set; Pig; Sqoop; Weather","Artificial intelligence; Climate change; Climate models; Computer circuits; Data handling; Data warehouses; Decision making; Decision support systems; Distributed computer systems; Information analysis; Open systems; Weathering; Conceptual data modeling; Data set; Decision support system (dss); Hadoop; Hive; Meteorological elements; National climatic data centers; Sqoop; Big data"
"Dragoni M., Donadello I., Eccher C.","Explainable AI meets persuasiveness: Translating reasoning results into behavioral change advice","10.1016/j.artmed.2020.101840","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084334581&doi=10.1016%2fj.artmed.2020.101840&partnerID=40&md5=2d68f3ae7d4f75105f67c95fab5f8073","Explainable AI aims at building intelligent systems that are able to provide a clear, and human understandable, justification of their decisions. This holds for both rule-based and data-driven methods. In management of chronic diseases, the users of such systems are patients that follow strict dietary rules to manage such diseases. After receiving the input of the intake food, the system performs reasoning to understand whether the users follow an unhealthy behavior. Successively, the system has to communicate the results in a clear and effective way, that is, the output message has to persuade users to follow the right dietary rules. In this paper, we address the main challenges to build such systems: (i) the Natural Language Generation of messages that explain the reasoner inconsistency; and, (ii) the effectiveness of such messages at persuading the users. Results prove that the persuasive explanations are able to reduce the unhealthy users’ behaviors. © 2020","Explainable AI; Explainable reasoning; MHealth; Natural Language Generation; Ontologies","Intelligent systems; Behavioral changes; Building intelligent systems; Chronic disease; Data-driven methods; Natural language generation; Reasoner; Rule based; Natural language processing systems; Article; artificial intelligence; behavior assessment; behavior change; clinical effectiveness; knowledge base; natural language processing; ontology; persuasive communication; priority journal; reasoning; human; persuasive communication; Artificial Intelligence; Humans; Persuasive Communication"
"Eashwar S., Chawla P.","Evolution of Agritech Business 4.0 - Architecture and Future Research Directions","10.1088/1755-1315/775/1/012011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108704286&doi=10.1088%2f1755-1315%2f775%2f1%2f012011&partnerID=40&md5=bbd79dc3dc92738196cfc5200c1ae676","Protection of farmer's welfare, improving their standard of living and maintaining the connect between urban and rural population are important for sustainable development. Agriculture 4.0 based on Industry 4.0 evolved to produce crops in different manner by applying new technologies, adopt emerging technologies to bring efficiency in food web, incorporate cross industry technologies and applications. Agri Food 4.0 is a survey based on industrial farming using advancements in Blockchain, Artificial Intelligence, IOT, Big Data. The challenge is to make the technologies interoperable and also to integrate agriculture production with food distribution network. In this research work, we propose to present the architecture of Agritech Business 4.0, a transparent model to integrate agriculture production with food distribution network by adopting I4.0 technologies. It is necessary to have a common framework that uses Internet of Things, Smart DLT, Big Data Analytics etc. thereby the communication between the technologies can be harnessed for better agricultural production, food security, transparency and decentralization. We have also presented few open research problems and future research directions in this paper. © Published under licence by IOP Publishing Ltd.","Agriculture 4.0; Artificial Intelligence; Blockchain; IOT; SDG; Smart Distributed Ledger Technology; Sustainability","Advanced Analytics; Agricultural robots; Artificial intelligence; Big data; Data Analytics; Food supply; Network architecture; Sustainable development; Agricultural productions; Agriculture productions; Emerging technologies; Food distribution; Future research directions; Research problems; Standard of living; Technologies and applications; Agriculture"
"Ellis D.I., Broadhurst D., Kell D.B., Rowland J.J., Goodacre R.","Rapid and quantitative detection of the microbial spoilage of meat by fourier transform infrared spectroscopy and machine learning","10.1128/AEM.68.6.2822-2828.2002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0036269481&doi=10.1128%2fAEM.68.6.2822-2828.2002&partnerID=40&md5=d828d2c26f99d0d925db3186d0fe5c3a","Fourier transform infrared (FT-IR) spectroscopy is a rapid, noninvasive technique with considerable potential for application in the food and related industries. We show here that this technique can be used directly on the surface of food to produce biochemically interpretable ""fingerprints."" Spoilage in meat is the result of decomposition and the formation of metabolites caused by the growth and enzymatic activity of microorganisms. FT-IR was exploited to measure biochemical changes within the meat substrate, enhancing and accelerating the detection of microbial spoilage. Chicken breasts were purchased from a national retailer, comminuted for 10 s, and left to spoil at room temperature for 24 h. Every hour, FT-IR measurements were taken directly from the meat surface using attenuated total reflectance, and the total viable counts were obtained by classical plating methods. Quantitative interpretation of FT-IR spectra was possible using partial least-squares regression and allowed accurate estimates of bacterial loads to be calculated directly from the meat surface in 60 s. Genetic programming was used to derive rules showing that at levels of 107 bacteria·g-1 the main biochemical indicator of spoilage was the onset of proteolysis. Thus, using FT-IR we were able to acquire a metabolic snapshot and quantify, noninvasively, the microbial loads of food samples accurately and rapidly in 60 s, directly from the sample surface. We believe this approach will aid in the Hazard Analysis Critical Control Point process for the assessment of the microbiological safety of food at the production, processing, manufacturing, packaging, and storage levels.",,"Attenuation; Decomposition; Fourier transform infrared spectroscopy; Learning systems; Least squares approximations; Metabolites; Regression analysis; Microbial spoilage; Microbiology; detection method; animal tissue; article; bacterial count; chicken; enzyme activity; food safety; food spoilage; infrared spectroscopy; meat; microbial growth; nonhuman; protein degradation; quantitative analysis; regression analysis; Artificial Intelligence; Bacteria; Food Contamination; Meat; Spectroscopy, Fourier Transform Infrared; Animalia; Bacteria (microorganisms); Gallus gallus"
"Fu Y., Gou W., Hu W., Mao Y., Tian Y., Liang X., Guan Y., Huang T., Li K., Guo X., Liu H., Li D., Zheng J.-S.","Integration of an interpretable machine learning algorithm to identify early life risk factors of childhood obesity among preterm infants: A prospective birth cohort","10.1186/s12916-020-01642-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087830204&doi=10.1186%2fs12916-020-01642-6&partnerID=40&md5=80f18d218858786db1a34c1516450762","Background: The early life risk factors of childhood obesity among preterm infants are unclear and little is known about the influence of the feeding practices. We aimed to identify early life risk factors for childhood overweight/obesity among preterm infants and to determine feeding practices that could modify the identified risk factors. Methods: A total of 338,413 mother-child pairs were enrolled in the Jiaxing Birth Cohort (1999 to 2013), and 2125 eligible singleton preterm born children were included for analyses. We obtained data on health examination, anthropometric measurement, lifestyle, and dietary habits of each participant at their visits to clinics. An interpretable machine learning-based analytic framework was used to identify early life predictors for childhood overweight/obesity, and Poisson regression was used to examine the associations between feeding practices and the identified leading predictor. Results: Of the eligible 2125 preterm infants (863 [40.6%] girls), 274 (12.9%) developed overweight/obesity at age 4-7 years. We summarized early life variables into 25 features and identified two most important features as predictors for childhood overweight/obesity: trajectory of infant BMI (body mass index) Z-score change during the first year of corrected age and maternal BMI at enrollment. According to the impacts of different BMI Z-score trajectories on the outcome, we classified this feature into the favored and unfavored trajectories. Compared with early introduction of solid foods (≤ 3 months of corrected age), introducing solid foods after 6 months of corrected age was significantly associated with 11% lower risk (risk ratio, 0.89; 95% CI, 0.82 to 0.97) of being in the unfavored trajectory. Conclusions: The trajectory of BMI Z-score change within the first year of life is the most important predictor for childhood overweight/obesity among preterm infants. Introducing solid foods after 6 months of corrected age is a recommended feeding practice for mitigating the risk of being in the unfavored trajectory. © 2020 The Author(s).","Childhood obesity; Early life risk factors; Machine learning; Preterm infants","age distribution; anthropometry; Apgar score; Article; birth weight; breast feeding; child; childhood obesity; cohort analysis; conceptual framework; controlled study; disease severity; early life stress; female; gestational age; human; infant; learning algorithm; machine learning; major clinical study; male; medical examination; nutritional assessment; preschool child; prospective study; risk factor; school child; algorithm; childhood obesity; China; complication; growth, development and aging; newborn; prematurity; risk factor; Algorithms; Child; Child, Preschool; China; Cohort Studies; Female; Humans; Infant; Infant, Newborn; Infant, Premature; Machine Learning; Male; Pediatric Obesity; Prospective Studies; Risk Factors"
"Gage J.L., Richards E., Lepak N., Kaczmar N., Soman C., Chowdhary G., Gore M.A., Buckler E.S.","In-Field Whole-Plant Maize Architecture Characterized by Subcanopy Rovers and Latent Space Phenotyping","10.2135/tppj2019.07.0011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079874396&doi=10.2135%2ftppj2019.07.0011&partnerID=40&md5=515cb6979e4ae0f1bd6b0b2d14313ab1","Core Ideas Subcanopy rovers enabled 3D characterization of thousands of hybrid maize plots. Machine learning produces heritable latent traits that describe plant architecture. Rover-based phenotyping is far more efficient than manual phenotyping. Latent phenotypes from rovers are ready for application to plant biology and breeding. Collecting useful, interpretable, and biologically relevant phenotypes in a resource-efficient manner is a bottleneck to plant breeding, genetic mapping, and genomic prediction. Autonomous and affordable subcanopy rovers are an efficient and scalable way to generate sensor-based datasets of in-field crop plants. Rovers equipped with lidar can produce three-dimensional reconstructions of entire hybrid maize (Zea mays L.) fields. In this study, we collected 2103 lidar scans of hybrid maize field plots and extracted phenotypic data from them by latent space phenotyping. We performed latent space phenotyping by two methods, principal component analysis and a convolutional autoencoder, to extract meaningful, quantitative latent space phenotypes (LSPs) describing whole-plant architecture and biomass distribution. The LSPs had heritabilities of up to 0.44, similar to some manually measured traits, indicating that they can be selected on or genetically mapped. Manually measured traits can be successfully predicted by using LSPs as explanatory variables in partial least squares regression, indicating that the LSPs contain biologically relevant information about plant architecture. These techniques can be used to assess crop architecture at a reduced cost and in an automated fashion for breeding, research, or extension purposes, as well as to create or inform crop growth models. © 2019 The Authors.",,
"Gansky B., McDonald S.","CounterFAccTual: How FAccT Undermines Its Organizing Principles","10.1145/3531146.3533241","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132972016&doi=10.1145%2f3531146.3533241&partnerID=40&md5=6fcd5e347dd04f04df400d2edffe28d4","This essay joins recent scholarship in arguing that FAccT's fundamental framing of the potential to achieve the normative conditions for justice through bettering the design of algorithmic systems is counterproductive to achieving said justice in practice. Insofar as the FAccT community's research tends to prioritize design-stage interventions, it ignores the fact that the majority of the contextual factors that practically determine FAccT outcomes happen in the implementation and impact stages of AI/ML lifecycles. We analyze an emergent and widely-cited movement within the FAccT community for attempting to honor the centrality of contextual factors in shaping social outcomes, a set of strategies we term g metadata maximalism'. Symptomatic of design-centered approaches, metadata maximalism abstracts away its reliance on institutions and structures of justice that are, by every observable metric, already struggling (where not failing) to provide accessible, enforceable rights. These justice infrastructures, moreover, are currently wildly under-equipped to manage the disputes arising from digital transformation and machine learning. The political economy of AI/ML implementation provides further obstructions to realizing rights. Data and software supply chains, in tandem with intellectual property protections, introduce structural sources of opacity. Where duties of care to vulnerable persons should reign, profit incentives are given legal and regulatory primacy. Errors are inevitable and inextricable from the development of machine learning systems. In the face of these realities, FAccT programs, including metadata maximalism, tend to project their efforts in a fundamentally counter-factual universe: one in which functioning institutions and processes for due diligence in implementation and for redress of harms are working and ready to interoperate with. Unfortunately, in our world, these institutions and processes have been captured by the interests they are meant to hold accountable, intentionally hollowed-out, and/or were never designed to function in today's sociotechnical landscape. Continuing to produce (fair! accountable! transparent!) data-enabled systems that operate in high-impact areas, irrespective of this landscape's radically insufficient paths to justice, given the unavoidability of errors and/or intentional misuse in implementation, and the exhaustively-demonstrated disproportionate distribution of resulting harms onto already-marginalized communities, is a choice - a choice to be CounterFAccTual. © 2022 Owner/Author.",,"Life cycle; Machine learning; Supply chains; Algorithmics; Community researches; Condition; Contextual factors; Design stage; Digital machines; Digital transformation; Machine-learning; Political economy; Social outcomes; Metadata"
"Garnaik S., Samant P.K., Mandal M., Mohanty T.R., Dwibedi S.K., Patra R.K., Mohapatra K.K., Wanjari R.H., Sethi D., Sena D.R., Sapkota T.B., Nayak J., Patra S., Parihar C.M., Nayak H.S.","Untangling the effect of soil quality on rice productivity under a 16-years long-term fertilizer experiment using conditional random forest","10.1016/j.compag.2022.106965","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128509211&doi=10.1016%2fj.compag.2022.106965&partnerID=40&md5=06957f5cc1b8500ff5fbb6c76dee18ea","In a 16-years long-term fertilizer experiment, an in-depth study was carried out to evaluate the changes in soil physical, chemical, and biological properties under long-term fertilizer application and establish cause and effect relationship between soil properties and rice productivity using interpretable machine learning. There were 12 treatments involving control (without fertilizer application), 100% N (recommended dose of nitrogen), 100% NP (recommended dose of nitrogen and phosphorus), 100% PK (recommended dose of phosphorus and potassium), 100% NPK (recommended dose of nitrogen, phosphorus, and potassium), 150% NPK (50% higher nitrogen, phosphorus, and potassium than recommended), 100% NPK + Zn (recommended nitrogen, phosphorus, and potassium along with Zinc), 100% NPK + FYM (recommended nitrogen, phosphorus, and potassium along with farmyard manure (FYM)), 100% NPK + FYM + LIME (recommended nitrogen, phosphorus, and potassium along with FYM and lime), 100% NPK + Zn + S (recommended nitrogen, phosphorus, and potassium along with zinc and sulphur), 100% NPK + Zn + B (recommended nitrogen, phosphorus, and potassium along with Zinc and Boron) and 100% NPK + Lime (recommended nitrogen, phosphorus, and potassium along with lime). At first, a conditional random forest model was built, based on which important variables were selected using the permutation-based variable importance approach. Further, the accumulated local effect plot was used to establish a cause and effect relationship between important soil properties and rice yield. Although most of the soil properties varied across the treatments, total potassium, protease, urease, and permanganate oxidisable carbon are the most important soil properties, individually accounting for up to 400 kg ha−1 variation in the rice productivity. The study demonstrated how interpretable machine learning techniques could be used in long-term fertilizer experiments to unravel the most meaningful information, and these techniques can be used in other similar long-term experiments. © 2022 Elsevier B.V.","Accumulated local effect plots; Interpretable machine learning; Rice-rice system; Soil properties; Variable importance","Decision trees; Machine learning; Nitrogen fertilizers; Phosphorus; Productivity; Random forests; Soils; Zinc; Accumulated local effect plot; Farmyard manure; Fertilizer applications; Interpretable machine learning; Local effects; Long-term fertilizer experiments; Nitrogen phosphorus; Rice-rice system; Soil property; Variable importances; Lime; crop production; fertilizer application; machine learning; rice; soil quality"
"Gary C.","Evaluation, design and control of sustainable horticultural cropping systems","10.17660/ActaHortic.2004.638.4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-71949120491&doi=10.17660%2fActaHortic.2004.638.4&partnerID=40&md5=10a09f313c2ba3ca8f9cf3ab38b2f51e","As all other human activities, horticulture is accountable for its impact on the resources available, now and in the future, to our societies. The problem is of particular importance in production systems that are often intensive and require high amounts of inputs. To fit with the increasing number of regulations and contracts growers have to respect, tools must be created to evaluate existing cropping systems and design and control original ones with respect to sustainability. Whatever the adopted technique, a systemic approach is required. Evaluation is possible either beforehand or during the implementation of the sequence and spatial combination of crops and corresponding technical operations that constitute a cropping system. Sets of agro-ecological indicators have been designed to evaluate the fittingness to specifications of ecological sustainability of the various components of cropping systems. They can be used to assess the global environmental impact of cropping systems on environmental resources. Existing or novel management strategies can also be evaluated with simulation models. Conception of crop management strategies consistent with objectives of sustainability has been made possible by the use of specific techniques belonging to the fields of linear programming and artificial intelligence. They make possible the generation of original crop successions and sequences of technical operations. At last an on-line control of the cropping system is compulsory to keep it within the limits of the strategic plan. To this end, indicators can be organised in a control board, and combined to decision rules. Artificial intelligence provides a way of formalising decision rules based on either scientific or expert knowledge, and generate decisions at a tactical level. Such examples show that indicators, models and decision support systems are relevant tools to assess the fittingness of horticultural cropping systems to the new standards of resource management.","Decision support system; Environment; Indicator; Modelling",
"Ghosal S., Blystone D., Singh A.K., Ganapathysubramanian B., Singh A., Sarkar S.","An explainable deep machine vision framework for plant stress phenotyping","10.1073/pnas.1716999115","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046251281&doi=10.1073%2fpnas.1716999115&partnerID=40&md5=afbc7c464a69da1512f524e5570f1145","Current approaches for accurate identification, classification, and quantification of biotic and abiotic stresses in crop research and production are predominantly visual and require specialized training. However, such techniques are hindered by subjectivity resulting from inter- and intrarater cognitive variability. This translates to erroneous decisions and a significant waste of resources. Here, we demonstrate a machine learning framework’s ability to identify and classify a diverse set of foliar stresses in soybean [Glycine max (L.) Merr.] with remarkable accuracy. We also present an explanation mechanism, using the top-K high-resolution feature maps that isolate the visual symptoms used to make predictions. This unsupervised identification of visual symptoms provides a quantitative measure of stress severity, allowing for identification (type of foliar stress), classification (low, medium, or high stress), and quantification (stress severity) in a single framework without detailed symptom annotation by experts. We reliably identified and classified several biotic (bacterial and fungal diseases) and abiotic (chemical injury and nutrient deficiency) stresses by learning from over 25,000 images. The learned model is robust to input image perturbations, demonstrating viability for high-throughput deployment. We also noticed that the learned model appears to be agnostic to species, seemingly demonstrating an ability of transfer learning. The availability of an explainable model that can consistently, rapidly, and accurately identify and quantify foliar stresses would have significant implications in scientific research, plant breeding, and crop production. The trained model could be deployed in mobile platforms (e.g., unmanned air vehicles and automated ground scouts) for rapid, large-scale scouting or as a mobile application for real-time detection of stress by farmers and researchers. © 2018 National Academy of Sciences. All rights reserved.","Explainable deep learning; Machine learning; Plant stress phenotyping; Precision agriculture; Resolving rater variabilities","Article; bacterial blight; bacterial plant disease; Cercospora; Cercospora sojina; chemical stress; controlled study; fungal plant disease; Fusarium; Fusarium virguliforme; machine learning; measurement accuracy; nonhuman; phenotype; plant leaf; plant nutrient; plant stress; prediction; priority journal; Pseudomonas syringae pv. savastanoi; reliability; Septoria glycines; soybean; Xanthomonas axonopodis; classification; machine learning; metabolism; phenotype; physiological stress; physiology; plant; plant breeding; plant disease; plant physiology; procedures; soybean; Machine Learning; Phenotype; Plant Breeding; Plant Diseases; Plant Leaves; Plant Physiological Phenomena; Plants; Soybeans; Stress, Physiological"
"Glowacki E.M., Glowacki J.B., Chung A.D., Wilcox G.B.","Reactions to foodborne Escherichia coli outbreaks: A text-mining analysis of the public's response","10.1016/j.ajic.2019.04.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065624325&doi=10.1016%2fj.ajic.2019.04.004&partnerID=40&md5=60feb75b1252ebf53b402002e9667d50","Foodborne illnesses caused by bacteria are being reported at an increasing rate in the United States. We performed a text-mining analysis to look at nearly 13,000 tweets from two foodborne Escherichia coli outbreaks in 2018. Concerns from the public included staying informed about contaminated lettuce, recognizing signs of infection, and holding responsible farms accountable. At the end of the second outbreak, comments were focused on assessing symptoms, using the traceback process to locate outbreak sources, and calling for better food labeling practices. © 2019 Association for Professionals in Infection Control and Epidemiology, Inc.","Food safety; Foodborne illness; Health communication; Public health; Social media; Twitter","Article; clinical feature; crop production; data mining; epidemic; Escherichia coli; food contamination; food packaging; food poisoning; human; lettuce; public opinion; social media; United States; Escherichia coli; food poisoning; health survey; isolation and purification; procedures; Data Mining; Disease Outbreaks; Escherichia coli; Foodborne Diseases; Humans; Population Surveillance; United States"
"Guehika A.","TRIZ, a Systematic Approach to Create Quantum Activation Function for Deep Learning’s Hidden Layers, in Order to Make AI Explainable with Quantum Computer","10.1007/978-3-030-32497-1_30","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075582766&doi=10.1007%2f978-3-030-32497-1_30&partnerID=40&md5=63825897cec3dbfa47a11decb270d899","Artificial Intelligence (AI)’s market is growing very fast all over the world, along with Deep Learning (DL) technologies requiring more and more data and speed to process them, in healthcare, agriculture, automotive, security, and in among several other industries. However, despite this AI rapid and increasing market expansion, there are numerous related challenges need to be tackled. In this paper, the purpose is to show through another structured approach derived from ARIZ algorithm and some principles coined by TrizStartup movement [1], some of the problems deep learning industries are trying to handle. This paper shows how TRIZ can be applied to fix one of those AI problems. In fact, due to DL neural networks (NN) hidden layers, their outputs are not reliable. If an error occurs, how could human reproduce the issue? Human are not able to identify activated neurons to analyse root causes of this malfunction. Therefore, reliability issue from hidden layers versus rapid AI market skyrocket, data and speed processing, generates innovation problems. In order to resolve this, principle 35-parameter changes with Althshuler Matrix, little people, Su-Field analysis, seventy-six standards solutions, have been used to generate quantum functions. The result described in this paper is a new function called QuantumReLU (QReLU), created with Quantum computer in order to extend classical activation function ReLU. It is then possible to fire neuron with activation function QReLU, and to use quantum states to identify activated neurons within hidden layers. Thus, Triz systematic approach led switching neural networks algorithms from classical to quantum computer, and therefore to build deep learning NN on quantum computer, based on the new QReLU activation function. © IFIP International Federation for Information Processing 2019.","Deep learning; Quantum computer; QuantumReLU; TRIZ","Chemical activation; Commerce; Data handling; Developing countries; Learning algorithms; Multilayer neural networks; Neurons; Quantum computers; Quantum theory; Qubits; Rhenium compounds; Activation functions; Market expansions; Neural network (nn); Quantum functions; QuantumReLU; Structured approach; Switching neural network; TRIZ; Deep learning"
"Guidotti R., Rossetti G., Pappalardo L., Giannotti F., Pedreschi D.","Personalized Market Basket Prediction with Temporal Annotated Recurring Sequences","10.1109/TKDE.2018.2872587","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054379547&doi=10.1109%2fTKDE.2018.2872587&partnerID=40&md5=899419013c97a5d01538368bbf947eae","Nowadays, a hot challenge for supermarket chains is to offer personalized services to their customers. Market basket prediction, i.e., supplying the customer a shopping list for the next purchase according to her current needs, is one of these services. Current approaches are not capable of capturing at the same time the different factors influencing the customer's decision process: co-occurrence, sequentuality, periodicity, and recurrency of the purchased items. To this aim, we define a pattern Temporal Annotated Recurring Sequence (TARS) able to capture simultaneously and adaptively all these factors. We define the method to extract TARS and develop a predictor for next basket named TBP (TARS Based Predictor) that, on top of TARS, is able to understand the level of the customer's stocks and recommend the set of most necessary items. By adopting the TBP the supermarket chains could crop tailored suggestions for each individual customer which in turn could effectively speed up their shopping sessions. A deep experimentation shows that TARS are able to explain the customer purchase behavior, and that TBP outperforms the state-of-the-art competitors. © 2018 IEEE.","data mining; interpretable model; market basket analysis; Next basket prediction; temporal recurring sequences; user-centric model","Analytical models; Data mining; Data structures; Forecasting; History; Markov processes; Retail stores; Adaptation models; Market basket analysis; Predictive models; Temporal Recurring Sequences; User-centric modeling; Sales"
"Guillard V., Buche P., Destercke S., Tamani N., Croitoru M., Menut L., Guillaume C., Gontard N.","A Decision Support System to design modified atmosphere packaging for fresh produce based on a bipolar flexible querying approach","10.1016/j.compag.2014.12.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921031926&doi=10.1016%2fj.compag.2014.12.010&partnerID=40&md5=b4297f9a70e28cb9e1945696d1caee83","To design new packaging for fresh food, stakeholders of the food chain express their needs and requirements, according to some goals and objectives. These requirements can be gathered into two groups: (i) fresh food related characteristics and (ii) packaging intrinsic characteristics. Modified Atmosphere Packaging (MAP) is an efficient way to delay senescence and spoilage and thus to extend the very short shelf life of respiring products such as fresh fruits and vegetables. Consequently, packaging O2/CO2 permeabilities must fit the requirements of fresh fruits and vegetable as predicted by virtual MAP simulating tools. Beyond gas permeabilities, the choice of a packaging material for fresh produce includes numerous other factors such as the cost, availability, potential contaminants of raw materials, process ability, and waste management constraints. For instance, the user may have the following multi-criteria query for his/her product asking for a packaging with optimal gas permeabilities that guarantee product quality and optionally a transparent packaging material made from renewable resources with a cost for raw material less than 3€/kg. To help stakeholders taking a rational decision based on the expressed needs, a new multi-criteria Decision Support System (DSS) for designing biodegradable packaging for fresh produce has been built. In this paper we present the functional specification, the software architecture and the implementation of the developed tool. This tool includes (i) a MAP simulation module combining mass transfer models and respiration of the food, (ii) a multi-criteria flexible querying module which handles imprecise, uncertain and missing data stored in the database. We detail its operational functioning through a real life case study to determine the most satisfactory materials for apricots packaging. © 2014 Elsevier B.V.","Decision support system; Knowledge engineering; MAP modeling; Multi-criteria querying; Respiring product","Artificial intelligence; Decision support systems; Fruits; Gas permeability; Knowledge engineering; Mass transfer; Packaging; Packaging materials; Query processing; Vegetables; Waste management; Biodegradable packaging; Functional specification; Intrinsic characteristics; Mass transfer models; Multi-criteria; Multi-criteria decision support systems; Potential contaminants; Respiring product; Modified atmosphere packaging; biodegradation; decision support system; design; food industry; multicriteria analysis; numerical model; nut; permeability; software"
"Gupta C., Farahat A.","Deep Learning for Industrial AI: Challenges, New Methods and Best Practices","10.1145/3394486.3406482","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090406535&doi=10.1145%2f3394486.3406482&partnerID=40&md5=718d27f5f6b294b2b318a1f9334c1117","Industrial AI is concerned with the application of Artificial Intelligence (AI), Machine Learning (ML) and related technologies towards addressing real-world use cases in industrial and societal domains. These uses cases can be broadly categorized into the horizontal areas of maintenance and repair, operations and supply chain, quality, safety, design, and end-to-end optimization - with applications in a variety of verticals. In the last few years, we have witnessed a growing interest in applying Deep Learning (DL) techniques to Industrial AI problems, ranging from using sequence models such as Long Short-Term Memory (LSTM) for predicting failures in equipment, to using Deep Reinforcement Learning (Deep RL) for scheduling and dispatching. Applying deep learning techniques to industrial applications imposes a set of unique challenges, which include, but are not limited to, (1) limited data, highly skewed class distribution and occurrence of rare classes such as failures, (2) multi-modal data (sensors, events, images, text, etc.) indexed over space and time (3) the need for explainable decisions, (4) a need to attain consistency between different but ""related"" models and between multiple generations of the same model, and (5) decision making to optimize business outcomes where the cost of a mistake could be very high. This tutorial presents an overview of these challenges, along with new methods and best practices to address them. Examples of these methods include using sequence DL models and Functional Neural Networks (FNNs) for modeling sensor and spatiotemporal measurements; using multi-task learning, graph models and ensemble learning for improving consistency of DL models; using deep RL for health indicator learning and dynamic dispatching; cost-based decision making for prognostics; and using GANs for generating senor data for prognostics. Finally, we will present some open problems in Industrial AI and how the research community can shape the future of the next industrial and societal revolution. © 2020 Owner/Author.","artificial intelligence; deep learning; industrial applications","Data mining; Decision making; Industrial research; Learning systems; Long short-term memory; Modal analysis; Multi-task learning; Reinforcement learning; Supply chains; Business outcomes; Ensemble learning; Functional neural networks; Health indicators; Learning techniques; Research communities; Skewed class distributions; Spatiotemporal measurement; Deep learning"
"Gurbuz O., Alanis-Lobato G., Picart-Armada S., Sun M., Haslinger C., Lawless N., Fernandez-Albert F.","Knowledge Graphs for Indication Expansion: An Explainable Target-Disease Prediction Method","10.3389/fgene.2022.814093","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127634012&doi=10.3389%2ffgene.2022.814093&partnerID=40&md5=f974ee244e30b13cf69b20a48b6e77e8","Indication expansion aims to find new indications for existing targets in order to accelerate the process of launching a new drug for a disease on the market. The rapid increase in data types and data sources for computational drug discovery has fostered the use of semantic knowledge graphs (KGs) for indication expansion through target centric approaches, or in other words, target repositioning. Previously, we developed a novel method to construct a KG for indication expansion studies, with the aim of finding and justifying alternative indications for a target gene of interest. In contrast to other KGs, ours combines human-curated full-text literature and gene expression data from biomedical databases to encode relationships between genes, diseases, and tissues. Here, we assessed the suitability of our KG for explainable target-disease link prediction using a glass-box approach. To evaluate the predictive power of our KG, we applied shortest path with tissue information- and embedding-based prediction methods to a graph constructed with information published before or during 2010. We also obtained random baselines by applying the shortest path predictive methods to KGs with randomly shuffled node labels. Then, we evaluated the accuracy of the top predictions using gene-disease links reported after 2010. In addition, we investigated the contribution of the KG’s tissue expression entity to the prediction performance. Our experiments showed that shortest path-based methods significantly outperform the random baselines and embedding-based methods outperform the shortest path predictions. Importantly, removing the tissue expression entity from the KG severely impacts the quality of the predictions, especially those produced by the embedding approaches. Finally, since the interpretability of the predictions is crucial in indication expansion, we highlight the advantages of our glass-box model through the examination of example candidate target-disease predictions. Copyright © 2022 Gurbuz, Alanis-Lobato, Picart-Armada, Sun, Haslinger, Lawless and Fernandez-Albert.","drug discovery; knowledge graphs; ontologies; target repositioning; target repurposing","interleukin 6; transforming growth factor beta receptor 1; ubiquitin; Article; artificial neural network; computer model; cross validation; data processing; disease activity; disease ontology; drug indication; drug interaction; drug repositioning; Food and Drug Administration; gene disruption; gene expression; gene ontology; gene set enrichment analysis; gene targeting; hop based prediction; human; information processing; knowledge graph; long short term memory network; machine learning; mathematical analysis; molecularly targeted therapy; mRNA expression level; natural language processing; nerve cell network; phylogeny; prediction; protein expression; protein localization; protein protein interaction; receiver operating characteristic; support vector machine; target disease prediction; tissue characterization"
"Han L., Yang G., Yang X., Song X., Xu B., Li Z., Wu J., Yang H., Wu J.","An explainable XGBoost model improved by SMOTE-ENN technique for maize lodging detection based on multi-source unmanned aerial vehicle images","10.1016/j.compag.2022.106804","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125148347&doi=10.1016%2fj.compag.2022.106804&partnerID=40&md5=e312a7b04f746ff7846d7a9d285f80a1","Remote sensing image is becoming an increasingly popular tool for crop lodging detection because it conveniently provides features for building machine learning models and predicting lodging. However, difficulties in interpreting machine learning models and their predictions limit the confidence of using remote sensing images to detect lodging. In addition, the lodging datasets used for modeling are difficult to balance under natural conditions. Designing a robust and interpretable classification model for the detection of lodging in an imbalanced distribution dataset poses a particularly difficult challenge. In this study, visible and multi-spectral images were collected with a UAV to extract relevant features from remote sensing images. In a preliminary step, Synthetic Minority Oversampling Technique (SMOTE) and Edited Nearest Neighbors (ENN) method were used to treat imbalanced datasets. The SMOTE-ENN-XGBoost model is proposed for the efficient identification of maize lodging at the plot scale. The SMOTE-ENN-XGBoost model achieved an F1-score of 0.930 and a recall of 0.899 on a testing set, suggesting that it can be used for modeling lodging detection. Additionally, the SHapley Additive exPlanations (SHAP) approach was employed to interpret the identification and prioritization of features that determine lodging classification and activity prediction. The results showed that canopy structure and textural features are relatively stable compared with spectral features, which are susceptible to the external environment when modeling is employed to detect lodging. This work also showed that canopy structural, spectral, and textural information should be considered simultaneously rather than separately when detecting crop lodging in a crop breeding program in order to prevent differences in expression controlled by the interaction between genotype and environment obscuring the change in a single feature before and after lodging. For practical applications of machine learning models in crop lodging detection, such insights are of critical relevance. Taken together, the results of this study encourage further applications of remote sensing techniques to build interpretable machine learning models. © 2022","Lodging; Remote sensing; SHAP; SMOTE; XGBoost","Antennas; Classification (of information); Feature extraction; Forecasting; Image enhancement; Machine learning; Remote sensing; Spectroscopy; Unmanned aerial vehicles (UAV); Lodging; Machine learning models; Nearest neighbors techniques; Nearest-neighbour; Remote sensing images; Remote-sensing; Shapley; Shapley additive explanation; Synthetic minority over-sampling techniques; Xgboost; Crops; data set; detection method; image analysis; image classification; maize; numerical model; spectral analysis; unmanned vehicle"
"Harfouche A.L., Jacobson D.A., Kainer D., Romero J.C., Harfouche A.H., Scarascia Mugnozza G., Moshelion M., Tuskan G.A., Keurentjes J.J.B., Altman A.","Accelerating Climate Resilient Plant Breeding by Applying Next-Generation Artificial Intelligence","10.1016/j.tibtech.2019.05.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067510759&doi=10.1016%2fj.tibtech.2019.05.007&partnerID=40&md5=d98ac02d1cd5db06ba7c99f97937137d","Breeding crops for high yield and superior adaptability to new and variable climates is imperative to ensure continued food security, biomass production, and ecosystem services. Advances in genomics and phenomics are delivering insights into the complex biological mechanisms that underlie plant functions in response to environmental perturbations. However, linking genotype to phenotype remains a huge challenge and is hampering the optimal application of high-throughput genomics and phenomics to advanced breeding. Critical to success is the need to assimilate large amounts of data into biologically meaningful interpretations. Here, we present the current state of genomics and field phenomics, explore emerging approaches and challenges for multiomics big data integration by means of next-generation (Next-Gen) artificial intelligence (AI), and propose a workable path to improvement. © 2019 Elsevier Ltd","augmented breeding; explainable AI; field phenomics; genomics; next-generation artificial intelligence; smart farming","Artificial intelligence; Ecosystems; Food supply; augmented breeding; Biological mechanisms; Environmental perturbations; field phenomics; Genomics; High-throughput genomics; Large amounts of data; smart farming; Data integration; agricultural worker; artificial intelligence; big data; climate; genomics; human; plant breeding; review; artificial intelligence; biomass; climate; climate change; crop; ecosystem; genetics; genomics; genotype; phenotype; plant breeding; procedures; Artificial Intelligence; Biomass; Climate; Climate Change; Crops, Agricultural; Ecosystem; Genomics; Genotype; Humans; Phenomics; Phenotype; Plant Breeding"
"He B., Zhao Y., Mao W., Griffin-Nolanb R.J.","Explainable artificial intelligence reveals environmental constraints in seagrass distribution","10.1016/j.ecolind.2022.109523","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139298036&doi=10.1016%2fj.ecolind.2022.109523&partnerID=40&md5=4e92fc77aa523f17b5f615ab6bf8064d","Seagrass is a globally vital marine resource that plays an essential global role in combating climate change, protecting coastlines, ensuring food security, and enriching biodiversity. However, global climate change and human activities have led to dramatic environmental changes severely affecting seagrass growth and development. Therefore, it is crucial to understand accurately how environmental changes, affect seagrass distribution. In this study, we selected the seagrass distribution area in Hainan, China, as the study area and proposed an ensemble model combining five machine learning models to predict the potential distribution of seagrass. Fifteen environmental variables were entered into the model, and the study results showed that the ensemble model provided the highest accuracy (Area Under Curve (AUC) = 0.91). The environmental variables were then classified into regional and site explanations with the help of explainable artificial intelligence (XAI) methods. The difference in the contribution of regional and site environmental variables is demonstrated, and the model provides a more reasonable explanation for the site. The Shapley value (SHAP) and Partial dependency plot (PDP) analysis methods explain the importance of environmental variables in the seagrass distribution model and the effect of multiple environmental variable interactions on the prediction results, which implies opening the black box model for machine learning. More evidence that explainable artificial intelligence can explain the effects of environmental variables in seagrass distribution models will help to improve environmental understanding in seagrass conservation processes. © 2022 The Author(s)","Ensemble Model; Explainable artificial intelligence; Seagrass; SHAP; Species distribution model","Climate change; Food supply; Machine learning; Marine biology; Plants (botany); Distribution models; Ensemble models; Environmental change; Environmental constraints; Environmental variables; Explainable artificial intelligence; Marine resources; Seagrasses; Shapley value; Species distribution modeling; Biodiversity; artificial intelligence; ensemble forecasting; environmental change; seagrass; species diversity; China; Hainan"
"He Y.","Ontology-supported research on vaccine efficacy, safety and integrative biological networks","10.1586/14760584.2014.923762","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84902341834&doi=10.1586%2f14760584.2014.923762&partnerID=40&md5=a7f11035cf2bac9c8555b0da6e5bc584","While vaccine efficacy and safety research has dramatically progressed with the methods of in silico prediction and data mining, many challenges still exist. A formal ontology is a human-and computer-interpretable set of terms and relations that represent entities in a specific domain and how these terms relate to each other. Several community-based ontologies (including Vaccine Ontology, Ontology of Adverse Events and Ontology of Vaccine Adverse Events) have been developed to support vaccine and adverse event representation, classification, data integration, literature mining of host-vaccine interaction networks, and analysis of vaccine adverse events. The author further proposes minimal vaccine information standards and their ontology representations, ontology-based linked open vaccine data and meta-analysis, an integrative One Network ('OneNet') Theory of Life, and ontology-based approaches to study and apply the OneNet theory. In the Big Data era, these proposed strategies provide a novel framework for advanced data integration and analysis of fundamental biological networks including vaccine immune mechanisms. © 2014 Informa UK, Ltd.","adverse event; data mining; interaction network; literature mining; meta-analysis; ontology; theory; vaccine; vaccine efficacy; vaccine safety","influenza vaccine; live vaccine; measles mumps rubella vaccine; smallpox vaccine; vaccine; yellow fever vaccine; 4CMenB vaccine; Brucella vaccine; Meningococcus vaccine; vaccine; adaptive immunity; computer model; data base; data mining; disease classification; drug efficacy; drug mechanism; drug research; drug safety; food and drug administration; gene interaction; human; immune response; Medical Dictionary for Regulatory Activities; medical ontology; meta analysis (topic); molecular interaction; natural language processing; ontology; ontology development; prediction; priority journal; review; side effect; vaccination; biological ontology; computer simulation; drug design; factual database; immunology; Meningitis, Meningococcal; Neisseria meningitidis; statistical analysis; Biological Ontologies; Brucella Vaccine; Computer Simulation; Data Interpretation, Statistical; Databases, Factual; Drug Design; Humans; Meningitis, Meningococcal; Meningococcal Vaccines; Neisseria meningitidis; Vaccines"
"Henkhaus N., Bartlett M., Gang D., Grumet R., Jordon-Thaden I., Lorence A., Lyons E., Miller S., Murray S., Nelson A., Specht C., Tyler B., Wentworth T., Ackerly D., Baltensperger D., Benfey P., Birchler J., Chellamma S., Crowder R., Donoghue M., Dundore-Arias J.P., Fletcher J., Fraser V., Gillespie K., Guralnick L., Haswell E., Hunter M., Kaeppler S., Kepinski S., Li F.-W., Mackenzie S., McDade L., Min Y., Nemhauser J., Pearson B., Petracek P., Rogers K., Sakai A., Sickler D., Taylor C., Wayne L., Wendroth O., Zapata F., Stern D.","Plant science decadal vision 2020–2030: Reimagining the potential of plants for a healthy and sustainable future","10.1002/pld3.252","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090015644&doi=10.1002%2fpld3.252&partnerID=40&md5=cddab70c202c738b7b15270b56794149","Plants, and the biological systems around them, are key to the future health of the planet and its inhabitants. The Plant Science Decadal Vision 2020–2030 frames our ability to perform vital and far-reaching research in plant systems sciences, essential to how we value participants and apply emerging technologies. We outline a comprehensive vision for addressing some of our most pressing global problems through discovery, practical applications, and education. The Decadal Vision was developed by the participants at the Plant Summit 2019, a community event organized by the Plant Science Research Network. The Decadal Vision describes a holistic vision for the next decade of plant science that blends recommendations for research, people, and technology. Going beyond discoveries and applications, we, the plant science community, must implement bold, innovative changes to research cultures and training paradigms in this era of automation, virtualization, and the looming shadow of climate change. Our vision and hopes for the next decade are encapsulated in the phrase reimagining the potential of plants for a healthy and sustainable future. The Decadal Vision recognizes the vital intersection of human and scientific elements and demands an integrated implementation of strategies for research (Goals 1–4), people (Goals 5 and 6), and technology (Goals 7 and 8). This report is intended to help inspire and guide the research community, scientific societies, federal funding agencies, private philanthropies, corporations, educators, entrepreneurs, and early career researchers over the next 10 years. The research encompass experimental and computational approaches to understanding and predicting ecosystem behavior; novel production systems for food, feed, and fiber with greater crop diversity, efficiency, productivity, and resilience that improve ecosystem health; approaches to realize the potential for advances in nutrition, discovery and engineering of plant-based medicines, and ""green infrastructure."" Launching the Transparent Plant will use experimental and computational approaches to break down the phytobiome into a ""parts store"" that supports tinkering and supports query, prediction, and rapid-response problem solving. Equity, diversity, and inclusion are indispensable cornerstones of realizing our vision. We make recommendations around funding and systems that support customized professional development. Plant systems are frequently taken for granted therefore we make recommendations to improve plant awareness and community science programs to increase understanding of scientific research. We prioritize emerging technologies, focusing on non-invasive imaging, sensors, and plug-and-play portable lab technologies, coupled with enabling computational advances. Plant systems science will benefit from data management and future advances in automation, machine learning, natural language processing, and artificial intelligence-assisted data integration, pattern identification, and decision making. Implementation of this vision will transform plant systems science and ripple outwards through society and across the globe. Beyond deepening our biological understanding, we envision entirely new applications. We further anticipate a wave of diversification of plant systems practitioners while stimulating community engagement, underpinning increasing entrepreneurship. This surge of engagement and knowledge will help satisfy and stoke people's natural curiosity about the future, and their desire to prepare for it, as they seek fuller information about food, health, climate and ecological systems. © 2020 The Authors. Plant Direct published by American Society of Plant Biologists and the Society for Experimental Biology and John Wiley & Sons Ltd","research areas; research methods; research organisms",
"Holzinger A., Keiblinger K., Holub P., Zatloukal K., Müller H.","AI for life: Trends in artificial intelligence for biotechnology","10.1016/j.nbt.2023.02.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147548778&doi=10.1016%2fj.nbt.2023.02.001&partnerID=40&md5=e92588cefa544399b512279720b0cc26","Due to popular successes (e.g., ChatGPT) Artificial Intelligence (AI) is on everyone's lips today. When advances in biotechnology are combined with advances in AI unprecedented new potential solutions become available. This can help with many global problems and contribute to important Sustainability Development Goals. Current examples include Food Security, Health and Well-being, Clean Water, Clean Energy, Responsible Consumption and Production, Climate Action, Life below Water, or protect, restore and promote sustainable use of terrestrial ecosystems, sustainably manage forests, combat desertification, and halt and reverse land degradation and halt biodiversity loss. AI is ubiquitous in the life sciences today. Topics include a wide range from machine learning and Big Data analytics, knowledge discovery and data mining, biomedical ontologies, knowledge-based reasoning, natural language processing, decision support and reasoning under uncertainty, temporal and spatial representation and inference, and methodological aspects of explainable AI (XAI) with applications of biotechnology. In this pre-Editorial paper, we provide an overview of open research issues and challenges for each of the topics addressed in this special issue. Potential authors can directly use this as a guideline for developing their paper. © 2023 The Authors","Artificial Intelligence; Biotechnology; Deep Learning; Digital Transformation; Machine Learning","Biotechnology; Data Analytics; Data mining; Decision support systems; Deep learning; E-learning; Food supply; Knowledge based systems; Learning algorithms; Learning systems; Natural language processing systems; 'current; Clean energy; Clean waters; Deep learning; Digital transformation; Food security; Global problems; Machine-learning; Sustainable use; Well being; Biodiversity; Article; artificial intelligence; big data; bioinformatics; biotechnology; data mining; decision support system; human; knowledge discovery; machine learning; medical ontology; natural language processing; trust"
"Hu S., Xiong C.","High-dimensional population inflow time series forecasting via an interpretable hierarchical transformer","10.1016/j.trc.2022.103962","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143712055&doi=10.1016%2fj.trc.2022.103962&partnerID=40&md5=b9f61596408221587702565a0f9d1d26","Mobile device location data (MDLD) are emerging data sources in the transportation domain that contain large-scale, fine-grained information on population inflow. However, limited studies have built forecasting models based on large-scale MDLD-based population inflow time series. This task is challenging due to complex nonlinear temporal dynamics, high-dimensional time series structure (i.e. multiple time series with multi-shape inputs and outputs), and non-negligible impacts from various external factors. To address these challenges, this study introduces a deep learning framework, the Interpretable Hierarchical Transformer (IHTF), for nationwide county-level population inflow time series forecasting and interpretation. A variety of cutting-edge deep learning techniques are fused, including the variable selection network to incorporate external effects, the gated residual network to handle nonlinearity, and the transformer architecture to learn temporal dynamics. Different interior parameters, such as variable selection weight and temporal attention weight, are extracted to explain patterns learned by the framework. Numerical experiments show that IHTF outperforms extensive baseline models in forecasting accuracy. In addition, feature importance generated by IHTF is similar to the tree-based model, LightGBM, but exhibits a more even distribution, among which point-of-interests (POIs) count, county location, median household income, and percentage of accommodation and food services are the most important static variables. Moreover, attention weight demonstrates that IHTF can automatically learn the seasonality from time series. Taken together, this framework can serve as a reliable travel demand forecasting component in the transportation planning process that allows modeling the travel demand continuously instead of by snapshot. © 2022","Crowd flow; Human mobility; Interpretability; Mobile device location data; Time series forecasting; Transformer","Deep learning; Forecasting; Learning systems; Location; Population statistics; Crowd flows; High-dimensional; Higher-dimensional; Human mobility; Inflow time series; Interpretability; Location data; Mobile device location data; Time series forecasting; Transformer; Time series; experimental study; numerical model; spatiotemporal analysis; time series analysis; transportation planning; travel demand"
"Huh J.-H., Kim S.-K.","The blockchain consensus algorithm for viable management of new and renewable energies","10.3390/su11113184","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067250274&doi=10.3390%2fsu11113184&partnerID=40&md5=1f46a2bc9d3ac41693b76f290d33dae9","Efficient information flow in an intelligent system is vital for effectively controlling the entire system. Currently, intelligent systems are used in many industries related to energy production, sustainable agriculture/transport, and intelligent building/cities. Information technology (IT) and information and communication technologies (ICT) play vital roles in introducing technical or technological innovation in these industries as well as establishing a collaborative network. Also, the digitization of existing systems has been quite effective at creating a sustainable global environment as it allows more efficient and well-balanced control of socio-economic factors. However, it has become clear that adopting an intelligent system to achieve innovation, sustainability, and safety may well depend on the quality of the algorithms to be used for that very system. Despite recent controversies, new and renewable energies are considered as a realistic alternative to fossil fuels, which have been integral to modern industries but are regarded as a cause of environmental or economic problems, not to mention their limited deposits. Therefore, since renewable energies will gradually replace existing energy sources but require more time to be fully available, it is essential to find a method of managing them in a fair and transparent way. The United States, Japan, and some European countries are attempting to achieve such a goal by utilizing a blockchain system, but the issues pertaining to its functionality, security, or efficiency have yet to be addressed. This study introduces a viable consensus algorithm (Hyper Delegation Proof of Randomness, or HDPoR algorithm) for blockchain and attempts to validate its parallel computing capability through simulations. This study also attempts to design an efficient but secure peer-to-peer (P2P) transaction service model for these energies for the future where blockchain-based systems will hold a key position in the digitalized world. As its main contribution, this study introduces an effective method of applying blockchain to a new and renewable energy transaction system by presenting a consensus algorithm that can improve its infrastructure and performance. © 2019 by the authors.","Authentication; Blockchain; BoT; Computer architecture; Gob; Java Android; Java JSON; M2M; Renewable energy; Smart grid; Software; Whitechain","algorithm; alternative energy; alternative fuel; artificial intelligence; digitization; fossil fuel; innovation; parallel computing; smart grid; socioeconomic conditions; software; Japan; United States"
"Hussein W.N., Kamarudin L.M., Hussain H.N., Zakaria A., Badlishah Ahmed R., Zahri N.A.H.","The Prospect of Internet of Things and Big Data Analytics in Transportation System","10.1088/1742-6596/1018/1/012013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048370952&doi=10.1088%2f1742-6596%2f1018%2f1%2f012013&partnerID=40&md5=7236c9dfa9583de4292385c313c72321","Internet of Things (IoT); the new dawn technology that describes how data, people and interconnected physical objects act based on communicated information, and big data analytics have been adopted by diverse domains for varying purposes. Manufacturing, agriculture, banks, oil and gas, healthcare, retail, hospitality, and food services are few of the sectors that have adopted and massively utilized IoT and big data analytics. The transportation industry is also an early adopter, with significant attendant effects on its processes of tracking shipment, freight monitoring, and transparent warehousing. This is recorded in countries like England, Singapore, Portugal, and Germany, while Malaysia is currently assessing the potentials and researching a purpose-driven adoption and implementation. This paper, based on review of related literature, presents a summary of the inherent prospects in adopting IoT and big data analytics in the Malaysia transportation system. Efficient and safe port environment, predictive maintenance and remote management, boundary-less software platform and connected ecosystem, among others, are the inherent benefits in the IoT and big data analytics for the Malaysia transportation system. © 2018 Institute of Physics Publishing. All rights reserved.","Big Data Analytics; Internet of Things; Malaysia transportation systems","Cloud computing; Information management; Internet of things; Oils and fats; Petroleum prospecting; Predictive analytics; Big Data Analytics; Internet of Things (IOT); Physical objects; Predictive maintenance; Remote management; Software platforms; Transportation industry; Transportation system; Big data"
"Ilonen J., Juránek R., Eerola T., Lensu L., Dubská M., Zemčík P., Kälviäinen H.","Comparison of bubble detectors and size distribution estimators","10.1016/j.patrec.2017.11.014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035027807&doi=10.1016%2fj.patrec.2017.11.014&partnerID=40&md5=aa0c54e507be41f11c208eed3c333913","Detection, counting and characterization of bubbles, that is, transparent objects in a liquid, is important in many industrial applications. These applications include monitoring of pulp delignification and multiphase dispersion processes common in the chemical, pharmaceutical, and food industries. Typically the aim is to measure the bubble size distribution. In this paper, we present a comprehensive comparison of bubble detection methods for challenging industrial image data. Moreover, we compare the detection-based methods to a direct bubble size distribution estimation method that does not require the detection of individual bubbles. The experiments showed that the approach based on a convolutional neural network (CNN) outperforms the other methods in detection accuracy. However, the boosting-based approaches were remarkably faster to compute. The power spectrum approach for direct bubble size distribution estimation produced accurate distributions and it is fast to compute, but it does not provide the spatial locations of the bubbles. Selecting the most suitable method depends on the specific application. © 2017 The Author(s)","Boosting-based detection; Bubble detection; Circular arrangements; Convolutional neural networks; Pulping; Size distribution estimation","Bubble columns; Bubbles (in fluids); Convolution; Delignification; Neural networks; Bubble detection; Bubble size distributions; Circular arrangements; Comprehensive comparisons; Convolutional neural network; Multiphase dispersion; Pulping; Transparent objects; Size distribution; Bubbles; Delignification; Dispersions; Neural Networks"
"Jeong K., Abbas A., Shin J., Son M., Kim Y.M., Cho K.H.","Prediction of biogas production in anaerobic co-digestion of organic wastes using deep learning models","10.1016/j.watres.2021.117697","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115942958&doi=10.1016%2fj.watres.2021.117697&partnerID=40&md5=5ffecb7f4492011911c34eb8cfd2bc64","Interest in anaerobic co-digestion (AcoD) has increased significantly in recent decades owing to enhanced biogas productivity due to the utilization of different organic wastes, such as food waste and sewage sludge. In this study, a robust AcoD model for biogas prediction is developed using deep learning (DL). We propose a hybrid DL architecture, i.e., DA–LSTM–VSN, wherein a dual-stage-attention (DA)-based long short-term memory (LSTM) network is integrated with variable selection networks (VSNs). To enhance the model predictability, we perform hyperparameter optimization. The model accuracy is validated using long-term AcoD monitoring data measured over two years of municipal wastewater treatment plant operation and then compared with those of two other DL-based models (i.e., DA–LSTM and the standard LSTM). In addition, the feature importance (FI) is analyzed to investigate the relative contribution of input variables to biogas production prediction. Finally, we demonstrate the successful application of the validated DL model to the AcoD process optimization. Results show that the model accuracy improved significantly by incorporating DA into LSTM, i.e., the coefficient of determination (R2) increased from 0.38 to 0.68; however, the R2 can be further increased to 0.76 by combining DA–LSTM with a VSN. For the biogas prediction of the AcoD model, the VSN contributes significantly by employing the discontinuous time series of measurement data on biodegradable organic-associated variables during AcoD. In addition, the VSN allows the AcoD model to be interpretable via FI analysis using its weighted input features. The FI results show that the relative importance is vital to variables associated with food waste leachate, whereas it is marginal for those associated with the primary and chemically assisted sedimentation sludges. In conclusion, the AcoD model proposed herein can be utilized in practical applications as a robust tool because it can provide the optimal sludge conditions to improve biogas production. This is because it facilitates the time-series biogas prediction at the full scale using unprocessed datasets with either missing value imputation or outlier removal. © 2021 Elsevier Ltd","Anaerobic co-digestion; Biogas; Deep learning; Model-based process optimization; Modeling and prediction","Activated sludge process; Anaerobic digestion; Forecasting; Long short-term memory; Optimization; Process control; Sewage sludge; Sludge digestion; Time series; Wastewater treatment; Anaerobic co-digestion; Biogas production; Deep learning; Digestion models; Dual stage; Model-based OPC; Model-based process optimization; Modelling and predictions; Process optimisation; Variables selections; Biogas; biogas; biofuel; methane; anaerobic digestion; biogas; machine learning; numerical model; organic pollutant; prediction; waste technology; wastewater treatment; accuracy; anaerobic digestion; Article; biofuel production; controlled study; deep learning; food waste; hybrid; leaching; long short term memory network; organic waste; prediction; process optimization; sedimentation; sludge; standard; time series analysis; waste water treatment plant; anaerobic growth; bioreactor; digestion; food; sewage; waste disposal; Anaerobiosis; Biofuels; Bioreactors; Deep Learning; Digestion; Food; Methane; Refuse Disposal; Sewage"
"Jeyasheela Rakkini M.J., Geetha K.","Comprehensive overview on the deployment of machine learning, deep learning, reinforcement learning algorithms in Selfish mining attack in blockchain","10.1109/MysuruCon55714.2022.9972484","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145351270&doi=10.1109%2fMysuruCon55714.2022.9972484&partnerID=40&md5=d238a729de6e2d4946f86bba81035cb2","Blockchain, a disruptive technology, has many applications in the domain of Finance, banking, real estate, insurance, supply chain, gaming industry with much more plethora of applications in near future. In spite of the decentralized, distributed, transparent, tamper-proof, data- provenance nature of the blockchain, it is subject to a lot of security attacks such as forking attacks and block withholding attacks. One such attack under the forking attack is selfish mining, which targets the reward distribution and also the difficulty adjustment algorithms(DAA). An exhaustive surve is done on the existing approaches to detect selfish mining and also on the profitability of selfish mining attacks. This survey is organized particularly around the aspects of selection or exploration of the shortest branch of the blockchain when a fork occurs. We aim to identify the implications of selecting the shorter branch of the fork in the blockchain, especially after 2016 blocks, where a difficulty adjustment occurs. Our survey focuses on the deployment of machine learning and deep learning, reinforcement methods on mitigating the selfish mining attacks in the blockchain. © 2022 IEEE.","Difficulty adjustment algorithms; forking attack; hash rate; Reinforcement learning; Selfish mining","Deep learning; Learning algorithms; Learning systems; Reinforcement learning; Supply chains; Adjustment algorithms; Block-chain; Difficulty adjustment algorithm; Forking attack; Hash rate; Learning reinforcements; Machine-learning; Reinforcement learning algorithms; Reinforcement learnings; Selfish mining; Blockchain"
"Jiang Z., Yip K.-M., Zhang X., Deng J., Wong W., So H.-K., Ngai E.C.H.","Identifying the High-Risk Population for COVID-19 Transmission in Hong Kong Leveraging Explainable Machine Learning","10.3390/healthcare10091624","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138579812&doi=10.3390%2fhealthcare10091624&partnerID=40&md5=f36da3129866f0c67e87b894c842109e","The worldwide spread of COVID-19 has caused significant damage to people’s health and economics. Many works have leveraged machine learning models to facilitate the control and treatment of COVID-19. However, most of them focus on clinical medicine and few on understanding the spatial dynamics of the high-risk population for transmission of COVID-19 in real-world settings. This study aims to investigate the association between population features and COVID-19 transmission risk in Hong Kong, which can help guide the allocation of medical resources and the implementation of preventative measures to control the spread of the pandemic. First, we built machine learning models to predict the number of COVID-19 cases based on the population features of different tertiary planning units (TPUs). Then, we analyzed the distribution of cases and the prediction results to find specific characteristics of TPUs leading to large-scale outbreaks of COVID-19. We further evaluated the importance and influence of various population features on the prediction results using SHAP values to identify indicators for high-risk populations for COVID-19 transmission. The evaluation of COVID-19 cases and the TPU dataset in Hong Kong shows the effectiveness of the proposed methods. The top three most important indicators are identified as people in accommodation and food services, low income, and high population density. © 2022 by the authors.","COVID-19; explainable machine learning; high-risk population; population features; SHAP; tertiary planning unit",
"Jones E.J., Bishop T.F.A., Malone B.P., Hulme P.J., Whelan B.M., Filippi P.","Identifying causes of crop yield variability with interpretive machine learning","10.1016/j.compag.2021.106632","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124307132&doi=10.1016%2fj.compag.2021.106632&partnerID=40&md5=2c6c8589012d542a2da841bcd73a1804","Machine learning approaches have been widely used for crop yield modelling and yield forecasting but there has been limited application to understanding site-specific yield constraints. Crop yield is driven by a complex interaction of spatial and temporal variables, which makes it challenging to define the exact cause of observed spatial yield variability explicitly. This makes it difficult to design efficient management strategies to address production constraints. There is a need for a more quantitative and systematic approach to identify and understand the causes of variation in crop yield in order to implement appropriate management responses. This study investigated the use of interpretive machine learning (IML) to address this need. The developed methodology was demonstrated on furrow-irrigated cotton fields totalling ∼2000 ha in the Condamine-Balonne River catchment, Australia. Digital soil maps of important soil constraints were created at 20 m spatial resolution using 70 soil cores extracted to 1.4 m depth and a combination of on-farm and off-farm spatial data layers. Specifically, the soil constraints represented were exchangeable sodium percentage (ESP – sodicity), pH (alkalinity), and electrical conductivity (ECe – salinity). Terrain infrastructure variable maps of closed depressions, distance down furrow, and cut and fill (from landforming practices) were also developed. Empirical models of cotton lint yield were created with gradient boosted decision trees (XGBoost) using the digital soil maps and terrain infrastructure data as predictor variables. The models could describe the spatial variation in yield well, with a median Lin's concordance correlation coefficient of 0.67 and root-mean-square error of 0.75b ha−1. SHapley Additive exPlanations (SHAP), an IML approach based on game theory, was then used to identify the contribution of each variable to the modelled yield across the study area. The variable most decreasing yield at each point was identified and mapped across the study area, and the spatial extent represented by each variable quantified. The SHAP values for each predictor variable were also extracted and mapped for a case study field, which demonstrated the magnitude of the impact of each variable on yield with spatial context in easily interpretable units (b ha−1). The presented methodology is promising for cost-benefit analysis of implementing remediation strategies, or where not economically feasible, altering management inputs according to a constrained yield potential. © 2021 Elsevier B.V.","Digital agriculture; Digital soil mapping; Precision agriculture; Soil constraints; Yield modelling","Alkalinity; Catchments; Cotton; Crops; E-learning; Game theory; Machine learning; Mean square error; Precision agriculture; Soil surveys; Soils; Crop yield; Digital agriculture; Digital soil mappings; Machine learning approaches; Precision Agriculture; Predictor variables; Shapley; Soil constraints; Soil maps; Yield models; Decision trees; agricultural management; cost-benefit analysis; cotton; crop yield; digital mapping; electrical conductivity; error analysis; forecasting method; identification method; machine learning; management practice; precision; soil depth; soil management; spatial resolution; spatial variation; Australia"
"Kalopesa E., Karyotis K., Tziolas N., Tsakiridis N., Samarinas N., Zalidis G.","Estimation of Sugar Content in Wine Grapes via In Situ VNIR–SWIR Point Spectroscopy Using Explainable Artificial Intelligence Techniques","10.3390/s23031065","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147895134&doi=10.3390%2fs23031065&partnerID=40&md5=79d440d60133c74baaa55aac88fd2368","Spectroscopy is a widely used technique that can contribute to food quality assessment in a simple and inexpensive way. Especially in grape production, the visible and near infrared (VNIR) and the short-wave infrared (SWIR) regions are of great interest, and they may be utilized for both fruit monitoring and quality control at all stages of maturity. The aim of this work was the quantitative estimation of the wine grape ripeness, for four different grape varieties, by using a highly accurate contact probe spectrometer that covers the entire VNIR–SWIR spectrum (350–2500 nm). The four varieties under examination were Chardonnay, Malagouzia, Sauvignon-Blanc, and Syrah and all the samples were collected over the 2020 and 2021 harvest and pre-harvest phenological stages (corresponding to stages 81 through 89 of the BBCH scale) from the vineyard of Ktima Gerovassiliou located in Northern Greece. All measurements were performed in situ and a refractometer was used to measure the total soluble solids content (°Brix) of the grapes, providing the ground truth data. After the development of the grape spectra library, four different machine learning algorithms, namely Partial Least Squares regression (PLS), Random Forest regression, Support Vector Regression (SVR), and Convolutional Neural Networks (CNN), coupled with several pre-treatment methods were applied for the prediction of the °Brix content from the VNIR–SWIR hyperspectral data. The performance of the different models was evaluated using a cross-validation strategy with three metrics, namely the coefficient of the determination ((Formula presented.)), the root mean square error (RMSE), and the ratio of performance to interquartile distance (RPIQ). High accuracy was achieved for Malagouzia, Sauvignon-Blanc, and Syrah from the best models developed using the CNN learning algorithm ((Formula presented.), (Formula presented.)), while a good fit was attained for the Chardonnay variety from SVR ((Formula presented.), (Formula presented.), (Formula presented.)), proving that by using a portable spectrometer the in situ estimation of the wine grape maturity could be provided. The proposed methodology could be a valuable tool for wine producers making real-time decisions on harvest time and with a non-destructive way. © 2023 by the authors.","cultivar; deep learning; NIR spectroscopy; oenological parameters; TSS; vineyard; vis–NIR","Convolutional neural networks; Deep learning; Forestry; Fruits; Infrared devices; Infrared radiation; Learning algorithms; Least squares approximations; Mean square error; Near infrared spectroscopy; Quality control; Spectrometers; Support vector regression; Cultivar; Deep learning; NIR spectroscopy; Oenological parameters; Short wave infrared; TSS; Vineyard; Visible and near infrared; Vis–NIR; Wine grapes; Wine"
"Kaneko T., Nomura K., Yasutake D., Iwao T., Okayasu T., Ozaki Y., Mori M., Hirota T., Kitano M.","A canopy photosynthesis model based on a highly generalizable artificial neural network incorporated with a mechanistic understanding of single-leaf photosynthesis","10.1016/j.agrformet.2022.109036","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131949851&doi=10.1016%2fj.agrformet.2022.109036&partnerID=40&md5=6410baf09261a056ae16436f6b382bbc","Crop productivity is largely dependent on canopy photosynthesis, which is difficult to measure at farming sites. Therefore, real-time estimation of the canopy photosynthetic rate (Ac) is expected to facilitate effective farm management. For the estimation of Ac, two types of mathematical models (i.e., process-based models and empirical models) have been used, although both types have their own weaknesses. Process-based models inevitably require many model parameters that are difficult to identify, while empirical models, including artificial neural network (ANN) models, have a low predictive ability outside of the range of training datasets. To overcome these weaknesses, we developed a hybrid canopy photosynthesis model that included components of both process-based models and ANN models. In this hybrid model, the single-leaf photosynthetic rate (AL) and leaf area index (LAI) were first estimated from information easily obtainable at farming sites: AL was estimated by the process-based model of AL (i.e., the biochemical photosynthesis model of Farquhar et al. (1980)) from environmental data (photosynthetic photon flux density (PPFD), air temperature (Ta), humidity, and atmospheric CO2 concentration (Ca)), and the LAI was estimated by an analysis of crop canopy imagery. As highly explainable information for Ac, the estimated AL and LAI were input into the ANN model to estimate Ac. As such, the ANN model learned the logical relationships between the inputs (AL and LAI) and the output (Ac). Detailed validation analysis using nine spinach Ac datasets revealed that the hybrid ANN model can estimate Ac accurately throughout the whole growth period, even when training and test datasets were obtained in different seasons under different CO2 concentrations and based on training datasets of only three days. This study highlights the high generalizability of the hybrid ANN model, which is a prerequisite for practical application in environmentally controlled crop production. © 2022","Biochemical photosynthesis model; CO2 enrichment; Leaf area index; Machine learning; Open chamber; Time-lapse digital camera","air temperature; artificial neural network; environmental factor; equipment; growth rate; leaf area index; machine learning; photon flux density; photosynthesis"
"Kannan G., Pattnaik M., Karthikeyan G., Balamurugan E., Augustine P.J., Lohith J.J.","Managing the Supply Chain for the Crops Directed from Agricultural Fields using Blockchains","10.1109/ICEARS53579.2022.9752088","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128975737&doi=10.1109%2fICEARS53579.2022.9752088&partnerID=40&md5=35968d3621547e15c1feb70f8391ceb9","Modern supply chain management relies heavily on crop processing technologies and blockchain technology. However, the majority of crop processing technology fails due to a lack of available supply chain management technologies. A supply chain management system based on crop processing is developed in this research. Digital ledger technology (blockchain) takes care of supply chains and deep learning image processing (crop processing). To process the harvested crops, the study makes use of machine learning techniques. Blockchain supply chain management technology is then used to deliver the processed crops to the shops. Consequently, the research permits the accurate and transparent distribution of crops to users in an optimal and secure manner. The full hybrid model is tested in a simulation to see if it can improve agricultural production and supply chain management. This new strategy improves agricultural processing rates, and when combined with the blockchain distributed ledger technology, this results in optimal crop management for the required users. © 2022 IEEE.","Agriculture; Blockchain; Machine Learning; Supply Chain Management","Blockchain; Deep learning; Distributed ledger; Engineering education; Image processing; Supply chain management; Agricultural fields; Agricultural productions; Block-chain; Hybrid model; Images processing; Machine learning techniques; Machine-learning; Management technologies; Processing technologies; Supply chain management system; Crops"
"Kerr D.V., Chaseling J., Chopping G.D., Davison T.M., Busby G.","A study of the effect of inputs on level of production of dairy farms in Queensland - A comparative analysis of survey data","10.1071/EA97153","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0031656407&doi=10.1071%2fEA97153&partnerID=40&md5=e82995496198569de0559068f6737c6d","Multiple linear regression models able to estimate total farm milk production from nutritional inputs were developed from farm survey data provided by dairy farmers in Queensland, Australia. These models were specifically developed for inclusion in a decision support system that could provide dairy farmers with an annual milk production estimate, thus enabling them to compare their production with an average farm using the same inputs in their region. Separate models were developed for each of 4 regions in Queensland and an additional model was developed for farms producing greater than 750 kL of milk per farm per year. The models were tested on dairy farms in Queensland by using the decision support system on farms that were not involved with initial model development. The partial regression coefficients for the models were biologically sensible and, apart from some minor interactions between independent variables in 2 regions, were additive. These interactions were not included in the final model in the interests of parsimony, ease of explanation and a need to provide transparent models within the decision support system. The coefficients of determination (R2) for the models varied from 79.9 to 88.3%. Forward-feed artificial neural network models were also used to confirm the relative accuracy of the multiple linear regression models and to allow for any interactions or non-linear functions in the data and to show that the simple equations are more appropriate for a farmer-orientated decision support system.","Decision support systems; Regression models","agricultural production; comparative study; dairy farming; productivity; Australia; Queensland"
"Kicherer H., Dittrich M., Grebe L., Scheible C., Klinger R.","What you use, not what you do: Automatic classification of recipes","10.1007/978-3-319-59569-6_22","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021746142&doi=10.1007%2f978-3-319-59569-6_22&partnerID=40&md5=e48dff60354b50478096ae29c6851236","Social media data is notoriously noisy and unclean. Recipe collections built by users are no exception, particularly when it comes to cataloging them. However, consistent and transparent categorization is vital to users who search for a specific entry. Similarly, curators are faced with the same challenge given a large collection of existing recipes: They first need to understand the data to be able to build a clean system of categories. This paper presents an empirical study on the automatic classification of recipes on the German cooking website Chefkoch. The central question we aim at answering is: Which information is necessary to perform well at this task? In particular, we compare features extracted from the free text instructions of the recipe to those taken from the list of ingredients. On a sample of 5,000 recipes with 87 classes, our feature analysis shows that a combination of nouns from the textual description of the recipe with ingredient features performs best (48% F1). Nouns alone achieve 45% F1 and ingredients alone 46% F1. However, other word classes do not complement the information from nouns. On a bigger training set of 50,000 instances, the best configuration shows an improvement to 57% highlighting the importance of a sizeable data set. © Springer International Publishing AG 2017.","Classification; Cooking; Food; Multi-label; Recipe; Text mining","Classification (of information); Cooking; Data mining; Food products; Information systems; Text processing; Thermal processing (foods); Automatic classification; Empirical studies; Feature analysis; Multi-label; Recipe; Social media datum; Text mining; Textual description; Natural language processing systems"
"Kirkwood C., Cave M., Beamish D., Grebby S., Ferreira A.","A machine learning approach to geochemical mapping","10.1016/j.gexplo.2016.05.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969988943&doi=10.1016%2fj.gexplo.2016.05.003&partnerID=40&md5=9b0ec8218e6ba3a3a3d80da09eaefdad","Geochemical maps provide invaluable evidence to guide decisions on issues of mineral exploration, agriculture, and environmental health. However, the high cost of chemical analysis means that the ground sampling density will always be limited. Traditionally, geochemical maps have been produced through the interpolation of measured element concentrations between sample sites using models based on the spatial autocorrelation of data (e.g. semivariogram models for ordinary kriging). In their simplest form such models fail to consider potentially useful auxiliary information about the region and the accuracy of the maps may suffer as a result. In contrast, this study uses quantile regression forests (an elaboration of random forest) to investigate the potential of high resolution auxiliary information alone to support the generation of accurate and interpretable geochemical maps. This paper presents a summary of the performance of quantile regression forests in predicting element concentrations, loss on ignition and pH in the soils of south west England using high resolution remote sensing and geophysical survey data. Through stratified 10-fold cross validation we find the accuracy of quantile regression forests in predicting soil geochemistry in south west England to be a general improvement over that offered by ordinary kriging. Concentrations of immobile elements whose distributions are most tightly controlled by bedrock lithology are predicted with the greatest accuracy (e.g. Al with a cross-validated R2 of 0.79), while concentrations of more mobile elements prove harder to predict. In addition to providing a high level of prediction accuracy, models built on high resolution auxiliary variables allow for informative, process based, interpretations to be made. In conclusion, this study has highlighted the ability to map and understand the surface environment with greater accuracy and detail than previously possible by combining information from multiple datasets. As the quality and coverage of remote sensing and geophysical surveys continue to improve, machine learning methods will provide a means to interpret the otherwise-uninterpretable. © 2016 The Authors.","Modelling; Quantile regression; Random forest; Soil geochemistry; South west England; Uncertainty","Artificial intelligence; Chemical analysis; Decision trees; Exploratory geochemistry; Forecasting; Geological surveys; Geophysics; Interpolation; Learning systems; Lithology; Mineral exploration; Models; Regression analysis; Remote sensing; Soils; Surveys; Uncertainty analysis; England; Quantile regression; Random forests; Soil geochemistry; Uncertainty; Geochemistry; algorithm; geophysical survey; machine learning; numerical model; regression analysis; remote sensing; soil chemistry; uncertainty analysis; England; United Kingdom"
"Kitano M., Nomura K., Yamazaki T., Iwao T., Saitou M., Mori M., Yasutake D., Kaneko T., Ukeda H., Ishizuka S., Fujiwara T., Okabayashi T.","Internet of Plants (IoP) Empowers Bottom-up Innovations in Greenhouse Horticulture","10.2525/ecb.60.3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124986962&doi=10.2525%2fecb.60.3&partnerID=40&md5=131e8135f254025ff9c0db3d9e7de0cd","Agriculture can be defined as a kind of the ""Monodzukuri"" industry (manufacturing industry) that utilizes crop photosynthesis to generate products (photosynthates). Agricultural production entirely depends on crop physioecological processes, such as photosynthesis, transpiration, translocation, and vegetative and reproductive growth, which are strongly affected by environmental conditions and farming technologies in crop fields and greenhouses. Since the beginning of agriculture, visualizing time-series data on crop physioecological processes and applying these data in everyday farm work have been impossible because of the difficulties in measuring crop physioecological processes. This invisibility of crop physioecological processes hinders not only farmers' inventive ideas but also Information and Communication Technology (ICT) and Artificial Intelligence (AI) to drive evolution and improvements in everyday farming to achieve demand-oriented crop production. Therefore, we propose an innovative concept, the ""Internet of Plants (IoP),"" as a regional information infrastructure for smart agriculture. This concept is driven by a cloud computing system (IoP Cloud), which is equipped with physioecological and farming support AI engines that visualize, functionalize and share highly explainable information about crop physioecological processes and farming technologies. The IoP is expected to facilitate the bottom-up evolution of agriculture, which will be driven by smart farmers empowered by IoP functions. © 2022 Biotron Institute. All rights reserved.","AI engine; Cloud computing system; Hybrid AI model; Internet of Plants (IoP); Physioecological processes",
"Kow P.-Y., Lu M.-K., Lee M.-H., Lu W.-B., Chang F.-J.","Develop a hybrid machine learning model for promoting microbe biomass production","10.1016/j.biortech.2022.128412","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144060191&doi=10.1016%2fj.biortech.2022.128412&partnerID=40&md5=c4fb957fa461d65d65aeeb3c50df68bf","Since the cultivation condition of microbe biomass production (mycelia yield) involves a variety of factors, it's a laborious process to obtain the optimal cultivation condition of Antrodia cinnamomea (A. cinnamomea). This study proposed a hybrid machine learning approach (i.e., ANFIS-NM) to identify the potent factors and optimize the cultivation conditions of A. cinnamomea based on a 32 fractional factorial design with seven factors. The results indicate that the ANFIS-NM approach successfully identified three key factors (i.e., glucose, potato dextrose broth, and agar) and significantly boosted mycelia yield. The interpretability of ANFIS rules made the cultivation conditions visually interpretable. Subsequently, a three-factor five-level central composite design was used to probe the optimal yield. This study demonstrates the proposed hybrid machine learning approach could significantly reduce the time consumption in laboratory cultivation and increase mycelia yield that meets SDGs 7 and 12, hitting a new milestone for biomass production. © 2022 Elsevier Ltd","Adaptive Neuro-Fuzzy Inference System (ANFIS); Antrodia cinnamomea; Artificial Neural Network (ANN); Biomass; Response Surface Methodology (RSM)","Bacteria; Biomass; Cultivation; Fuzzy inference; Fuzzy neural networks; Fuzzy systems; Machine learning; Adaptive neuro-fuzzy inference; Adaptive neuro-fuzzy inference system; Antrodia cinnamomea; Artificial neural network; Biomass productions; Cultivation conditions; Hybrid machine learning; Neuro-fuzzy inference systems; Response surface methodology; Response-surface methodology; Mycelium; artificial neural network; biomass; composite; machine learning; response surface methodology; Antrodia camphorata; Article; artificial neural network; biomass production; bioprocess; central composite design; factorial design; food industry; fuzzy system; machine learning; microorganism; mycelium; nonhuman; response surface method; biomass; fuzzy logic; Biomass; Fuzzy Logic; Machine Learning; Mycelium; Neural Networks, Computer"
"Kroh P.K., Mrochen J., Rupitsch S.J.","Evaluation of Neural Network Architectures for Classification of Sonar Echoes in Air","10.1109/SENSORS47125.2020.9278686","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098736868&doi=10.1109%2fSENSORS47125.2020.9278686&partnerID=40&md5=9a71ec6eff1566ee8f7e39830c00f858","In this contribution, we will classify sonar targets in air. The gained semantic environment information may be beneficial for autonomous mobile systems, such as robots and transport systems, for navigation in unknown as well as challenging settings with little or ambiguous optical and electromagnetic features. Examples for aforementioned environments may include food processing plants as well as medical buildings, in which obstacles are often comprised of transparent plastic or glass and may also have large shiny/reflecting surfaces. Targets are classified into three generic categories (flat, convex, concave), based on echoes from three subsequent recording positions. Multiple artificial neural networks with different architectures are designed, trained and evaluated as classifiers. The networks show promising prediction accuracy and an embedded implementation appears to be feasible. Especially, combinations of capsule networks and long short-term memory networks appear to be promising candidates for high classification performance. © 2020 IEEE.","feature extraction; neural networks; sonar detection; sonar measurements","Food processing; Functional polymers; Neural networks; Robots; Semantics; Sonar; Autonomous mobile systems; Classification performance; Embedded implementation; Environment information; Food processing plants; Prediction accuracy; Short term memory; Transparent plastics; Network architecture"
"Krupitzer C., Noack T., Borsum C.","Digital Food Twins Combining Data Science and Food Science: System Model, Applications, and Challenges †","10.3390/pr10091781","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138701337&doi=10.3390%2fpr10091781&partnerID=40&md5=6dcb977dd71177431f1ef921cbdfb5cb","The production of food is highly complex due to the various chemo-physical and biological processes that must be controlled for transforming ingredients into final products. Further, production processes must be adapted to the variability of the ingredients, e.g., due to seasonal fluctuations of raw material quality. Digital twins are known from Industry 4.0 as a method to model, simulate, and optimize processes. In this vision paper, we describe the concept of a digital food twin. Due to the variability of the raw materials, such a digital twin has to take into account not only the processing steps but also the chemical, physical, or microbiological properties that change the food independently from the processing. We propose a hybrid modeling approach, which integrates the traditional approach of food process modeling and simulation of the bio-chemical and physical properties with a data-driven approach based on the application of machine learning. This work presents a conceptual framework for our digital twin concept based on explainable artificial intelligence and wearable technology. We discuss the potential in four case studies and derive open research challenges. © 2022 by the authors.","artificial intelligence; digital twin; food processing; Industry 4.0; machine learning; self-aware computing systems",
"Kuchta M., Wubshet S.G., Afseth N.K., Mardal K.-A., Liland K.H.","Encoder–decoder neural networks for predicting future FTIR spectra – application to enzymatic protein hydrolysis","10.1002/jbio.202200097","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132314492&doi=10.1002%2fjbio.202200097&partnerID=40&md5=966c31048208b9c8b30e536497ffddc1","In the process of converting food-processing by-products to value-added ingredients, fine grained control of the raw materials, enzymes and process conditions ensures the best possible yield and economic return. However, when raw material batches lack good characterization and contain high batch variation, online or at-line monitoring of the enzymatic reactions would be beneficial. We investigate the potential of deep neural networks in predicting the future state of enzymatic hydrolysis as described by Fourier-transform infrared spectra of the hydrolysates. Combined with predictions of average molecular weight, this provides a flexible and transparent tool for process monitoring and control, enabling proactive adaption of process parameters. © 2022 The Authors. Journal of Biophotonics published by Wiley-VCH GmbH.","deep learning; encoder–decoder; enzymatic protein hydrolysis; FTIR; process control","Deep neural networks; Enzymatic hydrolysis; Food processing; Forecasting; Fourier transform infrared spectroscopy; Process monitoring; Deep learning; Encoder-decoder; Enzymatic protein hydrolysis; Fine-grained control; FTIR; Material conditions; Neural-networks; Process condition; Protein hydrolysis; Spectra's; Process control; protein; hydrolysis; infrared spectroscopy; molecular weight; Hydrolysis; Molecular Weight; Neural Networks, Computer; Proteins; Spectroscopy, Fourier Transform Infrared"
"Kumar I., Rawat J., Mohd N., Husain S.","Opportunities of Artificial Intelligence and Machine Learning in the Food Industry","10.1155/2021/4535567","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111566911&doi=10.1155%2f2021%2f4535567&partnerID=40&md5=ab06f4e0e34d82de51df750ace03293a","The food processing and handling industry is the most significant business among the various manufacturing industries in the entire world that subsidize the highest employability. The human workforce plays an essential role in the smooth execution of the production and packaging of food products. Due to the involvement of humans, the food industries are failing to maintain the demand-supply chain and also lacking in food safety. To overcome these issues of food industries, industrial automation is the best possible solution. Automation is completely based on artificial intelligence (AI) or machine learning (ML) or deep learning (DL) algorithms. By using the AI-based system, food production and delivery processes can be efficiently handled and also enhance the operational competence. This article is going to explain the AI applications in the food industry which recommends a huge amount of capital saving with maximizing resource utilization by reducing human error. Artificial intelligence with data science can improve the quality of restaurants, cafes, online delivery food chains, hotels, and food outlets by increasing production utilizing different fitting algorithms for sales prediction. AI could significantly improve packaging, increasing shelf life, a combination of the menu by using AI algorithms, and food safety by making a more transparent supply chain management system. With the help of AI and ML, the future of food industries is completely based on smart farming, robotic farming, and drones. © 2021 Indrajeet Kumar et al.",,"Accident prevention; Data Science; Deep learning; Food processing; Food products; Industrial robots; Learning systems; Supply chain management; Delivery process; Fitting algorithms; Increasing production; Industrial automation; Manufacturing industries; Packaging of foods; Resource utilizations; Supply chain management system; Food safety"
"Kurtanjek Ž.","Opportunities and challenges of model predictive control in food technologies",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885870937&partnerID=40&md5=62ab35b55d6ac829e23652144c58f2d2","Modern food industry has gone transformation from classical production concepts based on intensive manual work and off-line monitoring to a highly automated computer on-line controlled processes. The main focus in process automation is on application of modern process analytical technologies (PAT) and computer models for analysis and synthesis of information from on-line sensor signals with basic engineering principles of heat, mass and momentum, chemical and biochemical reactions, and industrial microbiology. New trends in process information synthesis and analysis of complex multidimensional data are based on: chemometric methods, such as principal component analysis (PCA) and partial least squares (PLS); and artificial intelligence (AI) algorithms, such as artificial neural networks (ANN), and fuzzy logic inference. For incorporation of computer algorithms in model predictive control (MPC) needed are developments of mathematical and statistical models for prediction of future outputs of multivariate nonlinear systems over a finite time horizon based on a set on multivariate inputs. Development of accurate and robust multivariate models for food technologies represents the main challenge and is crucial for MPC applicability. Methodology of MPC requires determination of manipulative inputs by optimization of a control objective function with constraints on manipulative and state output variables. From a practical point of view, main advantage of MPC (and the reason for its industrial success) is its true multivariate structure and ability to handle systems with constraints in a systematic and transparent manner. From process management point of view, MPC control can support process operation in a flexible and dynamic way to meet changing market requirements. The MPC technology is used to steer processes closer to their physical limits to obtain a better economical result. Main opportunities of MPC are in process control for production of food with improved nutritional and organoleptic properties, product quality assurance, environment protection, and increased product market value.","Armax models; Model predictive control MPC; Neural networks ann; Partial least squares PLS; Principal component analysis PCA","Algorithms; Artificial intelligence; Chemical analysis; Commerce; Complex networks; Computer control systems; Engineers; Food technology; Fuzzy inference; Fuzzy logic; Fuzzy neural networks; Industrial microbiology; Inference engines; Least squares approximations; Logic Synthesis; Model predictive control; Neural networks; Nutrition; Predictive control systems; Principal component analysis; Process control; Quality assurance; Social networking (online); Analysis and synthesis; ARMAX model; Biochemical reactions; Engineering principles; Environment protection; Organoleptic properties; Partial least square (PLS); Process analytical technology; Quality control"
"Kusherbaeva V., Zhou N., Subramanian D.","Interpretable Multi-Step Production Optimization Utilizing IoT Sensor Data","10.1109/WF-IoT51360.2021.9595035","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119867052&doi=10.1109%2fWF-IoT51360.2021.9595035&partnerID=40&md5=b0920628ca29a500e99e5bad2fc3e7f9","In an industrial manufacturing process, such as petroleum, chemical, and food processing, with the deployment of thousands of sensors in the plants, we have the chance to provide real-time onsite management for the processes. Beyond the real-time status update, utilizing vast IoT data and creating machine learning and optimization models provide us with intelligent business recommendations. Those are used by the site engineers and managers to make real-time decisions in a situation with multiple conflicting operational and business goals. Those goals include maximizing financial gain, minimizing costs, limiting the usage of certain raw materials or additives, decreasing environmental impact, and more. When formalizing these decision-making tasks, often there is no prior knowledge of compromise between the conflicting goals. That poses a challenge to generate a proper objective function. In this paper, we create a Multi-Step optimization process to address this uncertainty of selecting proper objectives and their preferences. Instead of using an explicit trade-off to create a single weighted objective function (as a traditional approach) and rely on a single attempt to find the optimal solution, we decompose this problem into multiple steps. In each step, we optimize only one objective from one KPI with an exact semantic meaning. We demonstrate the usability of the approach using a practical application from an oil sands processing facility, provide modeling results focusing on the response to business priorities, performance, and interpretability. The multi-step approach presents the convergence of the target goal with an outcome KPI with comparison for each step to illustrate the enhanced interpretability. © 2021 IEEE.","Interpretability; Mixed Integer Linear Programming (MILP); multi-step optimization; multistage production; optimization; optimization with sensor data; production optimization","Additives; Benchmarking; Crude oil; Decision making; Economic and social effects; Environmental impact; Industrial plants; Integer programming; Internet of things; Oil sands; Semantics; Integer Linear Programming; Interpretability; Mixed integer linear; Mixed integer linear programming; Multi-step optimization; Multistage production; Multisteps; Optimisations; Optimization with sensor data; Production optimization; Sensors data; Oil sand refining"
"Lei X., Zhao G., Zhang K., Kuo C.-C.J.","TGHop: An explainable, efficient, and lightweight method for texture generation","10.1017/ATSIP.2021.15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119091411&doi=10.1017%2fATSIP.2021.15&partnerID=40&md5=882f8d44e3a195a7fc7914285f30397f","An explainable, efficient, and lightweight method for texture generation, called TGHop (an acronym of Texture Generation PixelHop), is proposed in this work. Although synthesis of visually pleasant texture can be achieved by deep neural networks, the associated models are large in size, difficult to explain in theory, and computationally expensive in training. In contrast, TGHop is small in its model size, mathematically transparent, efficient in training and inference, and able to generate high-quality texture. Given an exemplary texture, TGHop first crops many sample patches out of it to form a collection of sample patches called the source. Then, it analyzes pixel statistics of samples from the source and obtains a sequence of fine-to-coarse subspaces for these patches by using the PixelHop++ framework. To generate texture patches with TGHop, we begin with the coarsest subspace, which is called the core, and attempt to generate samples in each subspace by following the distribution of real samples. Finally, texture patches are stitched to form texture images of a large size. It is demonstrated by experimental results that TGHop can generate texture images of superior quality with a small model size and at a fast speed. © The Author(s), 2021. Published by Cambridge University Press in association with Asia Pacific Signal and Information Processing Association.","Generative model; Successive subspace modeling; Texture generation; Texture synthesis","Deep neural networks; Image texture; Generative model; High quality; Model size; Pixel statistics; Sub-space modelling; Subspace modeling; Successive subspace modeling; Texture generation; Texture image; Texture synthesis; Textures"
"Lei X., Zhao G., Jay Kuo C.-C.","NITES: A Non-Parametric Interpretable Texture Synthesis Method",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100926802&partnerID=40&md5=a7525d610ff1bea820ab242c8d2edede","A non-parametric interpretable texture synthesis method, called NITES, is proposed in this work. Although automatic synthesis of visually pleasant texture can currently be achieved by deep neural networks, the associated generation models are mathematically intractable and their training demands higher computational cost. NITES offers a new texture synthesis solution to address these shortcomings. NITES is mathematically transparent and efficient in training and inference. The input is a single exemplary texture image. The NITES method crops out patches from the input and analyzes the statistical properties of these texture patches to obtain their joint spatial-spectral representations. Then, the probabilistic distributions of samples in the joint spatial-spectral spaces are characterized. Finally, numerous texture images that are visually similar to the exemplary texture image can be generated automatically. Experimental results are provided to show the superior quality of generated texture images and efficiency of the proposed NITES method in terms of both training and inference time. © 2020 APSIPA.",,"Computer graphics; Deep neural networks; Probability distributions; Textures; Automatic synthesis; Computational costs; Non-parametric; Probabilistic distribution; Spectral representations; Spectral spaces; Statistical properties; Texture synthesis; Image texture"
"Li H., Fan W., Shi S., Chou Q.","A Modified LIME and Its Application to Explain Service Supply Chain Forecasting","10.1007/978-3-030-32236-6_58","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075828311&doi=10.1007%2f978-3-030-32236-6_58&partnerID=40&md5=84851823a19a89a3a13b0e11b82d6dbd","Recently, researchers are focusing more on the study of explainable artificial intelligence due to its usefulness on various scenarios that request trust, such as deciding if one should trust a prediction, choosing between models, improving an untrustworthy model and identifying why a model should be trusted. One main research issues is how to improve the interpretability, while preventing any deterioration of accuracy of the model. For this issues the model-agnostic explanation method is a kind of solution. In the paper we propose a modified LIME algorithm based on locally fitted by decision tree regression called tree-LIME which is a model-agnostic method. Further, we clarify the fidelity measure definition in regression explanation problem by using mean absolute error (MAE). The experiments on real service supply chain forecasting application show that (1) our proposed approach can improve the fidelity of the explainer which lead to a more accurate explanations for individual instances and (2) our approach gives a more intuitive and visualized tree expression for explanation. (3) The approach also works well when applied to service supply chain forecasting. © 2019, Springer Nature Switzerland AG.","Decision tree; Explainable artificial intelligence; Local explanation; Model-agnostic","Artificial intelligence; Decision trees; Deterioration; Forecasting; Lime; Supply chains; Trees (mathematics); Decision tree regression; Interpretability; ITS applications; Local explanation; Mean absolute error; Modified lime; Research issues; Service supply chains; Natural language processing systems"
"Lu M., Bi Y., Xue B., Hu Q., Zhang M., Wei Y., Yang P., Wu W.","Genetic Programming for High-Level Feature Learning in Crop Classification","10.3390/rs14163982","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137809878&doi=10.3390%2frs14163982&partnerID=40&md5=d2bebdd2436ebb7a8dd2c58a9dbc2151","Information on crop spatial distribution is essential for agricultural monitoring and food security. Classification with remote-sensing time series images is an effective way to obtain crop distribution maps across time and space. Optimal features are the precondition for crop classification and are critical to the accuracy of crop maps. Although several approaches are available for extracting spectral, temporal, and phenological features for crop identification, these methods depend heavily on domain knowledge and human experiences, adding uncertainty to the final crop classification. This study proposed a novel Genetic Programming (GP) approach to learning high-level features from time series images for crop classification to address this issue. We developed a new representation of GP to extend the GP tree’s width and depth to dynamically generate either fixed or flexible informative features without requiring domain knowledge. This new GP approach was wrapped with four classifiers, i.e., K-Nearest Neighbor (KNN), Decision Tree (DT), Naive Bayes (NB), and Support Vector Machine (SVM), and was then used for crop classification based on MODIS time series data in Heilongjiang Province, China. The performance of the GP features was compared with the traditional features of vegetation indices (VIs) and the advanced feature learning method Multilayer Perceptron (MLP) to show GP effectiveness. The experiments indicated that high-level features learned by GP improved the classification accuracies, and the accuracies were higher than those using VIs and MLP. GP was more robust and stable for diverse classifiers, different feature numbers, and various training sample sets compared with classification using VI features and the classifier MLP. The proposed GP approach automatically selects valuable features from the original data and uses them to construct high-level features simultaneously. The learned features are explainable, unlike those of a black-box deep learning model. This study demonstrated the outstanding performance of GP for feature learning in crop classification. GP has the potential of becoming a mainstream method to solve complex remote sensing tasks, such as feature transfer learning, image classification, and change detection. © 2022 by the authors.","crop classification; feature learning; genetic programming; genetic programming representation; high-level features","Classification (of information); Crops; Data mining; Decision trees; Deep learning; Domain Knowledge; Food supply; Genetic algorithms; Image classification; Learning systems; Remote sensing; Support vector machines; Time series; Crop classification; Domain knowledge; Feature learning; Genetic programming representation; High-level features; Multilayers perceptrons; Performance; Remote-sensing; Times series; Vegetation index; Genetic programming"
"Luetticke D., Meisen T.","Design of an automated measuring system for RFID transponders in complex environments","10.1109/RFID-TA.2018.8552799","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059972955&doi=10.1109%2fRFID-TA.2018.8552799&partnerID=40&md5=4f3797e8c06190d094f7f86979296b42","As industry moves towards more flexible manufacturing processes the topics supply chain management and product tracking gain more and more importance. Identifying each product in the process not only by its type but also knowing its location and most important its current state of build is necessary to manage highly dynamic production processes. Using RFID (radio frequency identification) technology is a promising solution to this task. On the one hand, its main feature of enabling non-line visual identification using radio waves is of great benefit in such scenarios. On the other hand, these advantages also have corresponding disadvantages. Radio waves interfere heavily with certain materials like metal or liquids. For example, attaching RFID transponders to the various parts of a car and attempting to read these transponders during the assembly process, e.g. to monitor the production status, is a difficult challenge. In this paper, we propose an automated gate approach in combination with artificial intelligence to improve the read rate of RFID transponders inside of vehicles. © 2018 IEEE.","Automotive; Machine Learning; RFID; Traceability; Transparent Prototype","Artificial intelligence; Learning systems; Radio waves; Supply chain management; Transponders; Automated measuring system; Automotive; Complex environments; Dynamic production; Flexible manufacturing; Traceability; Transparent Prototype; Visual identification; Radio frequency identification (RFID)"
"Makridis G., Heyrman E., Kotios D., Mavrepis P., Callens B., De Vijver R.V., Maselyne J., Aluwé M., Kyriazis D.","Evaluating machine learning techniques to define the factors related to boar taint","10.1016/j.livsci.2022.105045","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135929528&doi=10.1016%2fj.livsci.2022.105045&partnerID=40&md5=148e40c36a8cd85318ebf9b8fe0ca70e","Several industries and sectors such as health care, agriculture, and finance exploit the added value of data to produce valuable insights for decision-making. The case of so-called ’boar taint’, the unwanted taste and odor that can be present in meat of entire male pigs, is one real-life scenario that showcases the added value of utilizing collected data. This information may yield insights for pig farmers about how they could adjust their management to reduce boar taint. This study examines multiple predictive data-driven approaches coupled with eXplainable AI (XAI) methods, evaluating them against various explainable metrics while trying to generate actionable insights and recommendations. Specifically, in this approach, the examined use case was modeled as a binary classification task resulting in a highly imbalanced dataset. This yielded some functional attributes regarding the farm/stable and slaughterhouse conditions, such as the type of feed, type of ventilation system, pharmaceutical treatment, floor type, and the duration of waiting in lairage. © 2022 Elsevier B.V.","Boar taint; Data analytics; Feature importance; Imbalanced data; Machine learning","agricultural land; agricultural worker; animal care; animal food; Article; artificial intelligence; boar (male pig); boar taint; building; controlled study; deep learning; evaluation research; factor analysis; food processing; genetic algorithm; information processing; lairage; machine learning; male; meat industry; nonhuman; organoleptic property; pharmaceutical care; pork; predictive model; room ventilation; slaughterhouse; statistical analysis"
"Malathy S., Vanitha C.N., Dhanaraj R.K., Kotteswari C.","Impact of Blockchain-IoE on economy","10.1016/B978-0-323-91850-3.00007-X","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142763657&doi=10.1016%2fB978-0-323-91850-3.00007-X&partnerID=40&md5=9bbc4ec2200696242df5e29021891ef7","Blockchain is popular among the technologically inclined people looking to use the computer to send and receive data while paying attention to data safety and privacy concerns. Blockchains have the ability to maintain digital data, in its transparent form as well as unaltered one, with the help of distributed computing along with cryptography and hashing techniques. Such a blockchain technology, while incorporated with Supply Chain Management (SCM), is creating a huge impact on the economy. SCM is the technique to maintain the process transformation flow from the purchase of raw materials to the production of final products and plays a vital role in economy streamlining the business activities by aligning those with customer satisfaction while keeping an eye open to the competition. The significance of blockchain in the circular economy is more because it considers not only the business parameters but also the society and the environment too. Blockchain-enabled smart contracts are employed to ensure trustworthiness and reliability in the economy. Blockchain will still be more strengthened by integrating the recent technologies such as the internet of things and machine learning in economy-related applications. An optimal and neutral finance management system will be developed by the proper blending of the aforementioned technologies. The case studies of blockchain applications in various industrial fields, at various acceptance levels, and for various organizational purposes are discussed at the end of the chapter. © 2023 Elsevier Inc. All rights reserved.","block building module; blockchain; circular economy; distributed ledger system; integration of blockchain and SCM; Internet of energy; internet of things; IoE; machine-to-machine economy; RFID; smart contacts; supply chain management",
"Malhi A., Apopei V., Madhikermi M., Mandeep, Främling K.","Smartphone Based Grape Leaf Disease Diagnosis and Remedial System Assisted with Explanations","10.1007/978-3-031-15565-9_4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140485328&doi=10.1007%2f978-3-031-15565-9_4&partnerID=40&md5=be9d695909e6bc31235441e4988cdad4","Plant diseases are one of the biggest challenges faced by the agricultural sector due to the damage and economic losses in crops. Despite the importance, crop disease diagnosis is challenging because of the limited-resources farmers have. Subsequently, the early diagnosis of plant diseases results in considerable improvement in product quality. The aim of the proposed work is to design an ML-powered mobile-based system to diagnose and provide an explanation based remedy for the diseases in grape leaves using image processing and explainable artificial intelligence. The proposed system will employ the computer vision empowered with Machine Learning (ML) for plant disease recognition and explains the predictions while providing remedy for it. The developed system uses Convolutional Neural networks (CNN) as an underlying machine/deep learning engine for classifying the top disease categories and Contextual Importance and Utility (CIU) for localizing the disease areas based on prediction. The user interface is developed as an IOS mobile app, allowing farmers to capture a photo of the infected grape leaves. The system has been evaluated using various performance metrics such as classification accuracy and processing time by comparing with different state-of-the-art algorithms. The proposed system is highly compatible with the Apple ecosystem by developing IOS app with high prediction and response time. The proposed system will act as a prototype for the plant disease detector robotic system. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","Agriculture; Grape leaf detection; Machine learning; Mobile app","Computer vision; Crops; Diagnosis; E-learning; Learning systems; Losses; Machine learning; Plants (botany); Smartphones; User interfaces; Agricultural sector; Disease diagnosis; Economic loss; Grape leaf detection; Grape leaves; Leaf disease; Machine-learning; Mobile app; Plant disease; Smart phones; Forecasting"
"Mancipe-Castro L., Gutiérrez-Carvajal R.E.","Prediction of environment variables in precision agriculture using a sparse model as data fusion strategy","10.1016/j.inpa.2021.06.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109427669&doi=10.1016%2fj.inpa.2021.06.007&partnerID=40&md5=883a0dd3b3833573a6c9e65ef9ebf153","Precision agriculture seeks to optimize production processes by monitoring and analyzing environmental variables. For example, establishing farming actions on the crop requires analyzing variables such as temperature, ambient humidity, soil moisture, solar irradiance, and Rainfall. Although these signals might contain valuable information, it is vital to mix up the monitored signals and analyze them as a whole to provide more accurate information than analyzing the signals separately. Unfortunately, monitoring all these variables results in high costs. Hence it is necessary to establish an appropriate method that allows the infer variables behavior without the direct measurement of all of them. This paper introduces a multi-sensor data fusion technique, based on a sparse representation, to find the most straightforward and complete linear equation to predict and understand a particular variable behavior based on other monitored environmental variables measurements. Moreover, this approach aims to provide an interpretable model that allows understanding how these variables are combined to achieve such results. The fusion strategy explained in this manuscript follows a four-step process that includes 1. data cleaning, 2. redundant variable detection, 3. dictionary generation, and 4. sparse regression. The algorithm requires a target variable and two highly correlated signals. It is essential to point out that the developed method has no restrictions to specific variables. Consequently, it is possible to replicate this method for the semiautomatic prediction of multiple critical environmental variables. As a case study, this work used the SML2010 data set of the UCI machine learning repository to predicted the humidity's derivative trend function with an error rate lower than 17% and a mean absolute error lower than 6%. The experiment results show that even though sparse model predictions might not be the most accurate compared to those of linear regression (LR), support vector machine (SVM), and extreme learning machine (ELM) since it is not a black-box model, it guarantees greater interpretability of the problem. © 2021 China Agricultural University","Humidity; Inference of variables; Multi-sensor data fusion; Precision agriculture; Sparse representation","Agricultural robots; Forecasting; Precision agriculture; Sensor data fusion; Soil moisture; Support vector machines; Support vector regression; Data fusion strategy; Environmental variables; Extreme learning machine; Mean absolute error; Multisensor data fusion; Redundant variables; Sparse representation; UCI machine learning repository; Learning systems; air temperature; crop; environmental factor; humidity; irradiance; precision agriculture; prediction; rainfall; soil moisture"
"Manimala R., Muthulakshmi G.","COVID-19 Applications","10.1201/9781003126898-10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140189775&doi=10.1201%2f9781003126898-10&partnerID=40&md5=28a0ef92ac86ede71304fdc052f85706","COVID-19 tracking tools or contact-tracing apps are developed by different countries to protect people from the pandemic situation. There are various technologies that can be used in this digital world to handle the patients in the lockdown period. Blockchain technology is one of the important techniques used in the medical field to maintain the patient’s medical records globally and for drug analysis etc. Blockchain is a public distributed ledger or document that is decentralized across many nodes. The public ledger records all the transactions, where the users in the blockchain network gets a copy of those transactions. This technology is used to track all the transactions in a secured and transparent manner. The patient records are also updated from diagnosis to current status. Here the records are shared but the privacy of a patient is maintained because the patient details are distributed as a hash value. These distributed records are immutable so nobody can change or corrupt the patient details in the blockchain because they can be easily identified. During an emergency, doctors can easily gather the health issues of a patient such as diabetes, blood pressure etc., from this public ledger, without any enquiry. Moreover, the doctor can track the previous medication details. This technology is also used in supply chain management of COVID drugs where the consumer can track from the production to dispatch, for identifying the fake medicine as well as anyone can gather the drug details. If any middlemen change the expiry date and price details it can be easily identified with the help of smart contracts. With this technology, Artificial Intelligence also plays a vital role in serving remote patients. Machine learning models are built by analyzing a massive amount of data. By using the distributed ledger, the data scientist can build the updated models continually using machine learning algorithms. The fusion of blockchain technology and machine learning models improves the accuracy of predictions in the health-care industry. This chapter describes the usage of blockchain technology with machine learning algorithms for serving the people. © 2022 selection and editorial matter, Avadhesh Kumar, Shrddha Sagar, T. Ganesh Kumar and K. Sampath Kumar; individual chapters, the contributors.",,
"Manoharan S., Sariffodeen B., Ramasinghe K.T., Rajaratne L.H., Kasthurirathna D., Wijekoon J.L.","Smart Plant Disorder Identification using Computer Vision Technology","10.1109/IEMCON51383.2020.9284919","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099297150&doi=10.1109%2fIEMCON51383.2020.9284919&partnerID=40&md5=f1aaf578415c09b33a6956ab16ae4f93","The soil composition around the world is depleting at a rapid rate due to overexploitation by the unsustainable use of fertilizers. Streamlining the availability of nutrient deficiency and fertilizer related knowledge among impoverished farming communities would promoter environmentally and scientifically sustainable farming practices. Thus, contributing to several Sustainable Development Goals set out by the United Nations. The most direct solution to the inappropriate fertilizer usage is to add only the necessary amounts of fertilizer required by plants to produce a significant yield without nutrition deficiencies. To this end this paper proposes a Smart Nutrient Disorder Identification system employing computer vision and machine learning techniques for identification purposes and a decentralized blockchain platform to streamline a bias-less procurement system. The proposed system yielded 88% accuracy in disorder identification, while also enabling secure, transparent flow of verified information. © 2020 IEEE.","Blockchain; CNN; Image processing; Machine learning; Nutrient deficiency; RCNN","Fertilizers; Learning systems; Mobile telecommunication systems; Nutrients; Computer vision technology; Direct solution; Farming communities; Machine learning techniques; Nutrient deficiency; Overexploitation; Soil composition; Sustainable Farming; Computer vision"
"Mao D., Wang F., Hao Z., Li H.","Credit evaluation system based on blockchain for multiple stakeholders in the food supply chain","10.3390/ijerph15081627","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051243872&doi=10.3390%2fijerph15081627&partnerID=40&md5=21969e1c489cd18e00b362a7bae9c9e0","The food supply chain is a complex system that involves a multitude of “stakeholders” such as farmers, production factories, distributors, retailers and consumers. “Information asymmetry” between stakeholders is one of the major factors that lead to food fraud. Some current researches have shown that applying blockchain can help ensure food safety. However, they tend to study the traceability of food but not its supervision. This paper provides a blockchain-based credit evaluation system to strengthen the effectiveness of supervision and management in the food supply chain. The system gathers credit evaluation text from traders by smart contracts on the blockchain. Then the gathered text is analyzed directly by a deep learning network named Long Short Term Memory (LSTM). Finally traders’ credit results are used as a reference for the supervision and management of regulators. By applying blockchain, traders can be held accountable for their actions in the process of transaction and credit evaluation. Regulators can gather more reliable, authentic and sufficient information about traders. The results of experiments show that adopting LSTM results in better performance than traditional machine learning methods such as Support Vector Machine (SVM) and Navie Bayes (NB) to analyze the credit evaluation text. The system provides a friendly interface for the convenience of users. © 2018 by the authors. Licensee MDPI, Basel, Switzerland.","Blockchain; Credit evaluation system; Food supply chain; LSTM","credit provision; food safety; food supply; machine learning; stakeholder; valuation; article; catering service; comparative effectiveness; human; machine learning; short term memory; support vector machine; algorithm; Bayes theorem; commercial phenomena; economics; food safety; organization and management; research; stakeholder engagement; Algorithms; Bayes Theorem; Commerce; Food Safety; Food Supply; Humans; Research; Stakeholder Participation; Support Vector Machine"
"Meghla T.I., Rahman M.M., Biswas A.A., Hossain J.T., Khatun T.","Supply Chain Management with Demand Forecasting of Covid-19 Vaccine using Blockchain and Machine Learning","10.1109/ICCCNT51525.2021.9580006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126221311&doi=10.1109%2fICCCNT51525.2021.9580006&partnerID=40&md5=7c601da3ee372293a39b67301ba035fc","Vaccination of the global population against COVID-19 is one of the challenging tasks in supply chain management that humanity has ever faced. The rapid roll-out of the COVID-19 vaccine is a must for making the worldwide immunization campaign successful, but its effectiveness depends on the availability of an operational and transparent distribution chain that can be audited by all related stakeholders. In this paper, the necessity of Blockchain and Machine Learning in supply-chain management with demand forecasting of the COVID-19 vaccine has been presented. The aim is to understand how the convergence of Blockchain technology and ML monitor the prerequisite of vaccine distribution with demand forecasting. Here, we have proposed an approach consists of Blockchain and Machine Learning which will be used to ensure the seamless COVID-19 vaccine distribution with transparency, data integrity, and end-to-end traceability for reducing risk, assuring the safety, and also immutability. Besides this, we have performed demand forecasting for appropriate COVID-19 vaccines according to the geographical area and the storage facilities. Lastly, we have discussed research challenges and also mentioning the limitations with future directions. © 2021 IEEE.","AI; Blockchain; COVID-19; Forecasting; Machine Learning; Pandemic; Supply-chain; Vaccine distribution","Blockchain; Digital storage; Machine learning; Supply chain management; Vaccines; Block-chain; COVID-19; Data integrity; Demand forecasting; Distribution chains; End to end; Global population; Machine-learning; Pandemic; Vaccine distributions; Forecasting"
"Mehedi M.H.K., Hosain A.K.M.S., Ahmed S., Promita S.T., Muna R.K., Hasan M., Reza M.T.","Plant Leaf Disease Detection using Transfer Learning and Explainable AI","10.1109/IEMCON56893.2022.9946513","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143639147&doi=10.1109%2fIEMCON56893.2022.9946513&partnerID=40&md5=5ece4c4b9b3b9e3345210d36d8a6bfd7","Among the major occupational sectors around the world, agriculture has the highest level of involvement. Every year, this sector faces a substantial loss in production and profit due to a large number of diseases in crops and plants. If those diseases are not detected early and taken measures for prevention, it can bring about a devastating result that can financially burden agriculture personnel. Traditional methods of detecting diseases in plants and crops offer high accuracy. However, the procedure is time-consuming, which might be insidious in most cases. Crop diseases need to be detected and cured as soon as possible as most diseases are highly contagious among crops and plants. In this paper, we have used the transfer learning approach with three pre-trained models: EfficientNetV2L, MobileNetV2, and ResNet152V2, to detect various plant diseases. We have proposed a framework to detect 38 types of leaf diseases in 14 different plants, compared the three pre-trained models based on various quantitative performance evaluation parameters, and demonstrated that EfficientNetV2L performed best with 99.63% accuracy. In the end, Explainable Artificial Intelligence (XAI) technique: LIME has been implemented in our model to understand the insight view of the model EfficeintNetV2L's for such prediction. It is used to make our model's predictions more reliable and gives a clear explanation about the reason of such decision. © 2022 IEEE.","EfficientNetV2L; LIME; MobileNetV2; Plant Leaf Disease; ResNet152V2; Transfer Learning; XAI","Crops; Transfer learning; Efficientnetv2l; High-accuracy; Leaf disease; Leaf disease detections; Mobilenetv2; Plant leaf disease; Plant leaves; Resnet152v2; Transfer learning; XAI; Lime"
"Melland A.R., Love S.M., Gourley C.J.P., Smith A.P., Eckard R.J.","The importance of trust in the development and delivery of a decision support tool to reduce environmental nutrient losses from pasture systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-80053126801&partnerID=40&md5=2b2cc5bac8b9f7ff60e0cf4bb330a57a","Managing uncertainty and risk is an increasing challenge for running profitable grazing systems. There is continual pressure to increase efficiency and productivity, while at the same time there is mounting scrutiny of the impact of grazing systems on the environment. Of particular interest is the impact of nitrogen and phosphorus losses from grazed pasture systems to water and the atmosphere. A combination of industry demand for information on environmental management of nutrients on farms, and the few existing decisions support systems (DSS) to help manage these issues in Australia led to a government and industry funded project (the Better Fertiliser Decisions project, BFD) for developing a new decision support system, the Farm Nutrient Loss Index (FNLI). The objective of the FNLI was to provide a DSS that can be used to identify where and when there is a risk of nutrient loss to the environment from grazed pasture systems in Australia. Current fertiliser applications on grazed pasture are based largely on previous practice, budget or recommendations from fertiliser industry staff and consultants. The fertiliser industry is therefore an ideal group for using the FNLI and delivering advice to farmers on how to minimise off-farm nutrient loss. Already the fertiliser industry has developed nutrient management codes of practice and guidelines (eg. Cracking the Nutrient Code) to support advice on environmental nutrient management. However, using the fertiliser industry as intermediaries between research scientists and farmers for delivery of the FNLI raises two challenges. Firstly, farm DSS have traditionally focussed on the extension of production-related outcomes and off-farm impacts have not been considered. There is often no profit-driven incentive for farmers to change management in order to improve off-farm environmental outcomes, which reduces the demand from the private sector for DSS such as the FNLI. Secondly it is well recognised that there has not been widespread use of DSS for on-farm decision making, so new and innovative models of science-farmer interaction will be required to empower farmers to manage nutrients in ways that protect the environment. To develop the FNLI, workshops were held with government scientists, fertiliser industry agronomists and farmers. This paper describes reflections of the authors on how these development activities and the FNLI itself may help the fertiliser industry deliver environmental nutrient management advice to farmers. Trust emerged as an important theme in our reflection on the FNLI development process because it seems to underpin the development of scientific rigour, stakeholder ownership and mutual learning. The FNLI development process offered many opportunities for developing the necessary trust between the government scientists and the fertiliser industry representatives. By collaborating with the fertiliser industry, the BFD project is providing an opportunity to exchange environmental and production-based knowledge between the commercial and public sectors. Our confidence in the fertiliser industry's ability to adequately deliver environmental information and technology is increasing due to the industry's strong commitment to environmental stewardship. To ensure the FNLI is accepted by the fertiliser industry, it is important to maintain a transparent development process and regularly communicate with project stakeholders. This will build trust in both the tool and the development process itself. Developing trust in and relevance of the FNLI through participation of fertiliser industry and farmers in its development has greater potential to lead to adoption of environmental management practices than developing the DSS in isolation and 'selling' it to the industry.","DSS; Fertiliser decisions; FNLI; Pasture systems; Trust","Australia; Change management; Codes of practice; Decision support tools; Development activity; Development process; DSS; Environmental information; Environmental management practices; Environmental outcome; Environmental stewardship; FNLI; Grazing systems; Industry representatives; Innovative models; Managing uncertainty; Mutual learning; Nutrient loss; Nutrient management; On-farm decisions; Pasture systems; Phosphorus loss; Private sectors; Project stakeholders; Public sector; Support systems; Trust; Decision support tools; Environmental information; Environmental management practices; Environmental outcome; Environmental stewardship; Industry representatives; Managing uncertainty; Nitrogen and phosphorus loss; Artificial intelligence; Decision making; Decision support systems; Environmental management; Environmental protection; Farms; Fertilizers; Industrial management; Industry; Innovation; Knowledge management; Nutrients; Phosphorus; Profitability; Agriculture; Budget control; Decision support systems; Environmental management; Environmental technology; Fertilizers; Knowledge management; Nutrients; Profitability; Project management; Project management; Decision making"
"Miles C.","The combine will tell the truth: On precision agriculture and algorithmic rationality","10.1177/2053951719849444","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074134805&doi=10.1177%2f2053951719849444&partnerID=40&md5=39c81367e1c93b1449c6d8429dfb6db7","Recent technological and methodological changes in farming have led to an emerging set of claims about the role of digital technology in food production. Known as precision agriculture, the integration of digital management and surveillance technologies in farming is normatively presented as a revolutionary transformation. Proponents contend that machine learning, Big Data, and automation will create more accurate, efficient, transparent, and environmentally friendly food production, staving off both food insecurity and ecological ruin. This article contributes a critique of these rhetorical and discursive claims to a growing body of critical literature on precision agriculture. It argues precision agriculture is less a revolution than an evolution, an effort to shore up and intensify the conventional farming system responsible for generating many of the social and environmental problems precision agriculture is presented as solving. While precision agriculture advocates portray it as a radical, even democratic epistemological break with the past, this paper locates truth claims surrounding datafication and algorithmic control in farming within deeper historical contexts of the capitalist rationalization of production and efforts to quantify and automate physical and mental labor. Abjuring the growing cultural tendency to treat algorithmic systems as revolutionary in favor of social and historical dimensions of precision agriculture, can help re-frame the discussion about its design and use around real, socially and ecologically oriented change in farming, and so ensure that the possibilities and benefits of precision agriculture are as evenly and effectively shared as possible. © The Author(s) 2019.","algorithm; capitalism; digitization; normativity; Precision agriculture; rationality",
"Miller D.D.","Machine Intelligence in Cardiovascular Medicine","10.1097/CRD.0000000000000294","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078996680&doi=10.1097%2fCRD.0000000000000294&partnerID=40&md5=9d0ab75641628d8a547ebe0150961fb3","The computer science technology trend called artificial intelligence (AI) is not new. Both machine learning and deep learning AI applications have recently begun to impact cardiovascular medicine. Scientists working in the AI domain have long recognized the importance of data quality and provenance to AI algorithm efficiency and accuracy. A diverse array of cardiovascular raw data sources of variable quality - electronic medical records, radiological picture archiving and communication systems, laboratory results, omics, etc. - are available to train AI algorithms for predictive modeling of clinical outcomes (in-hospital mortality, acute coronary syndrome risk stratification, etc.), accelerated image interpretation (edge detection, tissue characterization, etc.) and enhanced phenotyping of heterogeneous conditions (heart failure with preserved ejection fraction, hypertension, etc.). A number of software as medical device narrow AI products for cardiac arrhythmia characterization and advanced image deconvolution are now Food and Drug Administration approved, and many others are in the pipeline. Present and future health professionals using AI-infused analytics and wearable devices have 3 critical roles to play in their informed development and ethical application in practice: (1) medical domain experts providing clinical context to computer and data scientists, (2) data stewards assuring the quality, relevance and provenance of data inputs, and (3) real-time and post-hoc interpreters of AI black box solutions and recommendations to patients. The next wave of so-called contextual adaption AI technologies will more closely approximate human decision-making, potentially augmenting cardiologists' real-time performance in emergency rooms, catheterization laboratories, imaging suites, and clinics. However, before such higher order AI technologies are adopted in the clinical setting and by healthcare systems, regulatory agencies, and industry must jointly develop robust AI standards of practice and transparent technology insertion rule sets. © 2020 Lippincott Williams and Wilkins. All rights reserved.","algorithms; artificial intelligence; artificial neural networks; data science; machine learning","cardiovascular agent; acute coronary syndrome; algorithm; artificial intelligence; artificial neural network; cardiovascular disease; cardiovascular risk; clinical decision making; cluster analysis; computer model; data processing; data science; electronic medical record; gradient descent algorithm; health care; hospital mortality; machine learning; predictive modeling; radiology; Review; cardiology; cardiovascular disease; human; Artificial Intelligence; Cardiology; Cardiovascular Diseases; Humans; Machine Learning; Neural Networks, Computer"
"Moghimi A., Yang C., Miller M.E., Kianian S.F., Marchetto P.M.","A novel approach to assess salt stress tolerance in wheat using hyperspectral imaging","10.3389/fpls.2018.01182","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053076272&doi=10.3389%2ffpls.2018.01182&partnerID=40&md5=f80145260357489d08820470631a7943","Salinity stress has significant adverse effects on crop productivity and yield. The primary goal of this study was to quantitatively rank salt tolerance in wheat using hyperspectral imaging. Four wheat lines were assayed in a hydroponic system with control and salt treatments (0 and 200mM NaCl). Hyperspectral images were captured one day after salt application when there were no visual symptoms. Subsequent to necessary preprocessing tasks, two endmembers, each representing one of the treatment, were identified in each image using successive volume maximization. To simplify image analysis and interpretation, similarity of all pixels to the salt endmember was calculated by a technique proposed in this study, referred to as vector-wise similarity measurement. Using this approach allowed high-dimensional hyperspectral images to be reduced to one-dimensional gray-scale images while retaining all relevant information. Two methods were then utilized to analyze the gray-scale images: minimum difference of pair assignments and Bayesianmethod. The rankings of bothmethods were similar and consistent with the expected ranking obtained by conventional phenotyping experiments and historical evidence of salt tolerance. This research highlights the application of machine learning in hyperspectral image analysis for phenotyping of plants in a quantitative, interpretable, and non-invasive manner. © 2018 Moghimi, Yang, Miller, Kianian and Marchetto.","Bayesian inference; Histogram distance; Hyperspectral imaging; Image processing; Machine learning; Plant phenotyping; Salt stress; Wheat","analytic method; Article; assay; Bayes theorem; controlled study; hydroponics; hyperspectral imaging; image analysis; imaging; machine learning; nonhuman; phenotype; quantitative analysis; salt stress; salt tolerance; Triticum aestivum; wheat"
"Muresan M.P., Szabo P.A., Nedevschi S.","Dot Matrix OCR for Bottle Validity Inspection","10.1109/ICCP48234.2019.8959762","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079229000&doi=10.1109%2fICCP48234.2019.8959762&partnerID=40&md5=f6e4c469f24efe18209a084b2ad28861","Identifying expiration dates on water bottles for fast industrial processing of a large amount of products mainly affects water bottling factories, food warehouses and supermarkets. The impact of this problem is the distribution of expired bottles of water or their existence on the market. One of the key issues for automatic character readers from bottles is dotted text. Furthermore, the transparent and curved nature of the containing bottle in the presence of water increases the difficulty of the text extraction. An optical character recognition solution using a convolutional neural networks is proposed to solve this issue. The proposed solution segments the input image to extract the bottle, detects the text region of interest, then performs pre-processing operations and finally converts the characters extracted from the region of interest on the bottle in human-readable characters. The proposed solution has real time performance and it achieves high quality results on the evaluation set. © 2019 IEEE.","Bottle expiration date; Dotted text; Industrial inspection; OCR; Optical character recognition","Convolutional neural networks; Image segmentation; Optical character recognition; Dotted text; Industrial inspections; Industrial processing; Pre-processing operations; Presence of water; Real time performance; Region of interest; Text extraction; Bottles"
"Nayak H.S., Silva J.V., Parihar C.M., Krupnik T.J., Sena D.R., Kakraliya S.K., Jat H.S., Sidhu H.S., Sharma P.C., Jat M.L., Sapkota T.B.","Interpretable machine learning methods to explain on-farm yield variability of high productivity wheat in Northwest India","10.1016/j.fcr.2022.108640","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136105635&doi=10.1016%2fj.fcr.2022.108640&partnerID=40&md5=a31a6a981128f19927d6044c21d89363","The increasing availability of complex, geo-referenced on-farm data demands analytical frameworks that can guide crop management recommendations. Recent developments in interpretable machine learning techniques offer opportunities to use these methods in agronomic studies. Our objectives were two-fold: (1) to assess the performance of different machine learning methods to explain on-farm wheat yield variability in the Northwestern Indo-Gangetic Plains of India, and (2) to identify the most important drivers and interactions explaining wheat yield variability. A suite of fine-tuned machine learning models (ridge and lasso regression, classification and regression trees, k-nearest neighbor, support vector machines, gradient boosting, extreme gradient boosting, and random forest) were statistically compared using the R2, root mean square error (RMSE), and mean absolute error (MAE). The best performing model was again fine-tuned using a grid search approach for the bias-variance trade-off. Three post-hoc model agnostic techniques were used to interpret the best performing model: variable importance (a variable was considered “important” if shuffling its values increased or decreased the model error considerably), interaction strength (based on Friedman's H-statistic), and two-way interaction (i.e., how much of the total variability in wheat yield was explained by a particular two-way interaction). Model outputs were compared against empirical data to contextualize results and provide a blueprint for future analysis in other production systems. Tree-based and decision boundary-based methods outperformed regression-based methods in explaining wheat yield variability. Random forest was the best performing method in terms of goodness-of-fit and model precision and accuracy with RMSE, MAE, and R2 ranging between 367 and 470 kg ha−1, 276–345 kg ha−1, and 0.44–0.63, respectively. Random forest was then used for selection of important variables and interactions. The most important management variables explaining wheat yield variability were nitrogen application rate and crop residue management, whereas the average of monthly cumulative solar radiation during February and March (coinciding with reproductive phase of wheat) was the most important biophysical variable. The effect size of these variables on wheat yield ranged between 227 kg ha−1 for nitrogen application rate to 372 kg ha−1 for cumulative solar radiation during February and March. The effect of important interactions on wheat yield was detected in the data namely the interaction between crop residue management and disease management and, nitrogen application rate and seeding rate. For instance, farmers’ fields with moderate disease incidence yielded 750 kg ha−1 less when crop residues were removed than when crop residues were retained. Similarly, wheat yield response to residue retention was higher under low seed and N application rates. As an inductive research approach, the appropriate application of interpretable machine learning methods can be used to extract agronomically actionable information from large-scale farmer field data. © 2022 The Authors","Accumulated local effect plot; Big data; Interaction strength; Partial dependency plot; Quantile regression; Random forest; Variable importance","crop yield; disease incidence; machine learning; productivity; regression; India"
"Nikoloski S., Murphy P., Kocev D., Džeroski S., Wall D.P.","Using machine learning to estimate herbage production and nutrient uptake on Irish dairy farms","10.3168/jds.2019-16575","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070853774&doi=10.3168%2fjds.2019-16575&partnerID=40&md5=67cdcf10239dcb560e2a6ad1dbd1112d","Nutrient management on grazed grasslands is of critical importance to maintain productivity levels, as grass is the cheapest feed for ruminants and underpins these meat and milk production systems. Many attempts have been made to model the relationships between controllable (crop and soil fertility management) and noncontrollable influencing factors (weather, soil drainage) and nutrient/productivity levels. However, to the best of our knowledge not much research has been performed on modeling the interconnections between the influencing factors on one hand and nutrient uptake/herbage production on the other hand, by using data-driven modeling techniques. Our paper proposes to use predictive clustering trees (PCT) learned for building models on data from dairy farms in the Republic of Ireland. The PCT models show good accuracy in estimating herbage production and nutrient uptake. They are also interpretable and are found to embody knowledge that is in accordance with existing theoretical understanding of the task at hand. Moreover, if we combine more PCT into an ensemble of PCT (random forest of PCT), we can achieve improved accuracy of the estimates. In practical terms, the number of grazings, which is related proportionally with soil drainage class, is one of the most important factors that moderates the herbage production potential and nutrient uptake. Furthermore, we found the nutrient (N, P, and K) uptake and herbage nutrient concentration to be conservative in fields that had medium yield potential (11 t of dry matter per hectare on average), whereas nutrient uptake was more variable and potentially limiting in fields that had higher and lower herbage production. Our models also show that phosphorus is the most limiting nutrient for herbage production across the fields on these Irish dairy farms, followed by nitrogen and potassium. © 2019 American Dairy Science Association","herbage production; nutrient uptake; predictive clustering trees; random forest","animal; animal food; bovine; dairying; diet; female; Ireland; lactation; machine learning; metabolism; milk; Poaceae; procedures; veterinary medicine; Animal Feed; Animals; Cattle; Dairying; Diet; Female; Ireland; Lactation; Machine Learning; Milk; Nutrients; Poaceae"
"Noviello C., Esposito G., Fasano G., Renga A., Soldovieri F., Catapano I.","Small-UAV radar imaging for cultural heritage inspections: Results from multiple measurements lines","10.1117/12.2593420","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112763178&doi=10.1117%2f12.2593420&partnerID=40&md5=c7ceb09eac3457ac44a564b6bc543ea6","Nowadays the importance of Unmanned Aerial Vehicle (UAV) based sensing technologies is globally recognized. Indeed, thanks to the ability of investigating large areas in a very short time and at very reduced cost, the UAV sensing technology has been widely used in multiple application contexts, including security and surveillance inspections, environmental monitoring, geology, agriculture, archeology and cultural heritage. Actually, the widespread remote sensing technologies mounted on-board UAVs are mainly optical, thermal and multi-spectral sensors, which are passive technologies designed to measure the signals emitted into the optical and (near and far) infrared portions of the electromagnetic spectrum thus providing useful 2D and 3D information about the observed scene. Radar systems represent an important complementary solution. Indeed, radar system is an active system which transmits and receives electromagnetic signals at microwave frequencies, thus offering the advantages of performing inspections in free space and through-obstacle scenarios. However, UAV based radar imaging is not yet a well consolidated technology due to the significant challenges related to the acquisition modality and data processing strategies. Since both transmitting and receiving radar units must be installed on-board the UAV, this introduces not trivial issues related to payload and assets constrains. Moreover, in order to obtain reliable and easily interpretable images, a high precision UAV trajectory reconstruction must be deployed. As a contribution to this topic, an UAV imaging system prototype based on a microwave tomographic approach was recently proposed. Experimental tests at the Archaeological Park of Paestum (SA) has been recently carried out. During the survey, the UAV platform was piloted in path-planning mode, i.e. ""autonomous flight""on a predefined rectangular grid and a novel imaging strategy which exploits multiple measurement lines has been developed. © COPYRIGHT SPIE. Downloading of the abstract is permitted for personal use only.","Inverse scattering; Inverse Scattering; Microwave Tomography; Radar Imaging; Unmanned Aerial Vehicle","Agricultural robots; Antennas; Artificial intelligence; Data handling; Environmental technology; Image processing; Inspection; Radar; Radar measurement; Remote sensing; Unmanned aerial vehicles (UAV); Electromagnetic signals; Electromagnetic spectra; Environmental Monitoring; Multiple applications; Processing strategies; Remote sensing technology; Security and surveillances; Trajectory reconstruction; Radar imaging"
"Ntakolia C., Kokkotis C., Karlsson P., Moustakidis S.","An explainable machine learning model for material backorder prediction in inventory management","10.3390/s21237926","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119934595&doi=10.3390%2fs21237926&partnerID=40&md5=db57989cff9aa7d4e8a11238f299c1b5","Global competition among businesses imposes a more effective and low-cost supply chain allowing firms to provide products at a desired quality, quantity, and time, with lower production costs. The latter include holding cost, ordering cost, and backorder cost. Backorder occurs when a product is temporarily unavailable or out of stock and the customer places an order for future production and shipment. Therefore, stock unavailability and prolonged delays in product delivery will lead to additional production costs and unsatisfied customers, respectively. Thus, it is of high importance to develop models that will effectively predict the backorder rate in an inventory system with the aim of improving the effectiveness of the supply chain and, consequentially, the performance of the company. However, traditional approaches in the literature are based on stochastic approximation, without incorporating information from historical data. To this end, machine learning models should be employed for extracting knowledge of large historical data to develop predictive models. Therefore, to cover this need, in this study, the backorder prediction problem was addressed. Specifically, various machine learning models were compared for solving the binary classification problem of backorder prediction, followed by model calibration and a post-hoc explainability based on the SHAP model to identify and interpret the most important features that contribute to material backorder. The results showed that the RF, XGB, LGBM, and BB models reached an AUC score of 0.95, while the best-performing model was the LGBM model after calibration with the Isotonic Regression method. The explainability analysis showed that the inventory stock of a product, the volume of products that can be delivered, the imminent demand (sales), and the accurate prediction of the future demand can significantly contribute to the correct prediction of backorders. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Inventory backorder prediction; Inventory management; Post-hoc explainability; Prediction models","Competition; Costs; Inventory control; Machine learning; Regression analysis; Sales; Stochastic systems; Supply chains; Backorders; Cost supply; Global competition; Historical data; Inventory backorder prediction; Inventory management; Low-costs; Machine learning models; Post-hoc explainability; Prediction modelling; Forecasting; machine learning; Machine Learning"
"O'Brien M.K., Botonis O.K., Larkin E., Carpenter J., Martin-Harris B., Maronati R., Lee K., Cherney L.R., Hutchison B., Xu S., Rogers J.A., Jayaraman A.","Advanced Machine Learning Tools to Monitor Biomarkers of Dysphagia: A Wearable Sensor Proof-of-Concept Study","10.1159/000517144","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115859004&doi=10.1159%2f000517144&partnerID=40&md5=8b921f541b66b178ac974fbcb47b84ef","Introduction: Difficulty swallowing (dysphagia) occurs frequently in patients with neurological disorders and can lead to aspiration, choking, and malnutrition. Dysphagia is typically diagnosed using costly, invasive imaging procedures or subjective, qualitative bedside examinations. Wearable sensors are a promising alternative to noninvasively and objectively measure physiological signals relevant to swallowing. An ongoing challenge with this approach is consolidating these complex signals into sensitive, clinically meaningful metrics of swallowing performance. To address this gap, we propose 2 novel, digital monitoring tools to evaluate swallows using wearable sensor data and machine learning. Methods: Biometric swallowing and respiration signals from wearable, mechano-acoustic sensors were compared between patients with poststroke dysphagia and nondysphagic controls while swallowing foods and liquids of different consistencies, in accordance with the Mann Assessment of Swallowing Ability (MASA). Two machine learning approaches were developed to (1) classify the severity of impairment for each swallow, with model confidence ratings for transparent clinical decision support, and (2) compute a similarity measure of each swallow to nondysphagic performance. Task-specific models were trained using swallow kinematics and respiratory features from 505 swallows (321 from patients and 184 from controls). Results: These models provide sensitive metrics to gauge impairment on a per-swallow basis. Both approaches demonstrate intrasubject swallow variability and patient-specific changes which were not captured by the MASA alone. Sensor measures encoding respiratory-swallow coordination were important features relating to dysphagia presence and severity. Puree swallows exhibited greater differences from controls than saliva swallows or liquid sips (p < 0.037). Discussion: Developing interpretable tools is critical to optimize the clinical utility of novel, sensor-based measurement techniques. The proof-of-concept models proposed here provide concrete, communicable evidence to track dysphagia recovery over time. With refined training schemes and real-world validation, these tools can be deployed to automatically measure and monitor swallowing in the clinic and community for patients across the impairment spectrum. © 2021 The Author(s) Published by S. Karger AG, Basel.","Clinical decision support; Machine learning; Monitoring; Precision medicine; Wearable sensors","Decision support systems; Machine learning; Clinical decision support; Complex signal; Concept studies; Digital monitoring; Learning tool; Machine-learning; Neurological disorders; Performance; Physiological signals; Proof of concept; Wearable sensors; adult; Article; biometry; breathing; cerebrovascular accident; clinical decision support system; cohort analysis; comparative study; controlled study; data analysis software; data processing; digital technology; disease classification; disease marker; disease severity assessment; dysphagia; feature extraction; female; fluid intake; food intake; human; kinematics; machine learning; major clinical study; male; patient monitoring; probability; proof of concept; saliva; signal detection; swallowing; throat; wireless communication"
"Onishi M., Ise T.","Explainable identification and mapping of trees using UAV RGB image and deep learning","10.1038/s41598-020-79653-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099417131&doi=10.1038%2fs41598-020-79653-9&partnerID=40&md5=998a8ab3d1cc794a9c31501062fe4789","The identification and mapping of trees via remotely sensed data for application in forest management is an active area of research. Previously proposed methods using airborne and hyperspectral sensors can identify tree species with high accuracy but are costly and are thus unsuitable for small-scale forest managers. In this work, we constructed a machine vision system for tree identification and mapping using Red–Green–Blue (RGB) image taken by an unmanned aerial vehicle (UAV) and a convolutional neural network (CNN). In this system, we first calculated the slope from the three-dimensional model obtained by the UAV, and segmented the UAV RGB photograph of the forest into several tree crown objects automatically using colour and three-dimensional information and the slope model, and lastly applied object-based CNN classification for each crown image. This system succeeded in classifying seven tree classes, including several tree species with more than 90% accuracy. The guided gradient-weighted class activation mapping (Guided Grad-CAM) showed that the CNN classified trees according to their shapes and leaf contrasts, which enhances the potential of the system for classifying individual trees with similar colours in a cost-effective manner—a useful feature for forest management. © 2021, The Author(s).",,"article; convolutional neural network; deep learning; forest management; human; photography; plant leaf; tree crown; unmanned aerial vehicle; vision; agriculture; classification; environmental protection; forest; image processing; procedures; remote sensing; tree; Agriculture; Conservation of Natural Resources; Deep Learning; Forests; Image Processing, Computer-Assisted; Neural Networks, Computer; Remote Sensing Technology; Trees"
"Ouyang W., Zhang Y., Zhu M., Zhang X., Chen H., Ren Y., Fan W.","Interpretable Spatial-Temporal Attention Graph Convolution Network for Service Part Hierarchical Demand Forecast","10.1007/978-3-030-32236-6_52","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075828681&doi=10.1007%2f978-3-030-32236-6_52&partnerID=40&md5=61216eb1c9106d88f938d043e8c9bfb1","Accurate service part demand forecast plays a key role in service supply chain management. It enables better decision making in the planning of service part procurement and distribution. To achieve high responsiveness, the service supply chain network exhibits a hierarchical structure: forward stocking locations (FSL) close to the end customer, distribution centers (DC) in the middle and center hub (CH) at the top. Hierarchical forecasts require not only good prediction accuracy at each level of the service supply chain network, but also the consistency between different levels. The accuracy and consistency of hierarchical forecasts are important to be interpretable to the decision-makers (DM). Moreover, service part demand data is the spatial-temporal time series that the observations made at neighboring regions and adjacent timestamps are not independent but dynamically correlated with each other. Recent advances in deep learning enable promising results in modeling the complex spatial-temporal relationship. Researchers use convolutional neural networks (CNN) to model spatial correlations and recurrent neural networks (RNN) to model temporal correlations. However, these deep learning models are non-transparent to the DMs who broadly require justifications in the decision-making processes. Here an interpretable solution is in the urgent demand. In this paper, we present an interpretable general framework STAH (Spatial-Temporal Attention Graph Convolution network for Hierarchical demand forecast). We evaluate our approach on Lenovo Group Ltd.’s service part demand data in India. Experimental results demonstrate the efficacy of our approach, showing superior accuracy while increasing model interpretability. © 2019, Springer Nature Switzerland AG.",,"Convolution; Decision making; Deep learning; Forecasting; Natural language processing systems; Supply chain management; Convolutional neural network; Decision making process; Hierarchical structures; Recurrent neural network (RNN); Service supply chain managements; Service supply chains; Spatial temporal relationship; Temporal correlations; Recurrent neural networks"
"Oyallon E., Zagoruyko S., Huang G., Komodakis N., Lacoste-Julien S., Blaschko M.B., Belilovsky E.","Scattering Networks for Hybrid Representation Learning","10.1109/TPAMI.2018.2855738","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050246820&doi=10.1109%2fTPAMI.2018.2855738&partnerID=40&md5=10a64ebcd5a77f084f60b8555cadab4b","Scattering networks are a class of designed Convolutional Neural Networks (CNNs) with fixed weights. We argue they can serve as generic representations for modelling images. In particular, by working in scattering space, we achieve competitive results both for supervised and unsupervised learning tasks, while making progress towards constructing more interpretable CNNs. For supervised learning, we demonstrate that the early layers of CNNs do not necessarily need to be learned, and can be replaced with a scattering network instead. Indeed, using hybrid architectures, we achieve the best results with predefined representations to-date, while being competitive with end-to-end learned CNNs. Specifically, even applying a shallow cascade of small-windowed scattering coefficients followed by <formula><tex>$1\times 1$</tex></formula>-convolutions results in AlexNet accuracy on the ILSVRC2012 classification task. Moreover, by combining scattering networks with deep residual networks, we achieve a single-crop top-5 error of 11.4% on ILSVRC2012. Also, we show they can yield excellent performance in the small sample regime on CIFAR-10 and STL-10 datasets, exceeding their end-to-end counterparts, through their ability to incorporate geometrical priors. For unsupervised learning, scattering coefficients can be a competitive representation that permits image recovery. We use this fact to train hybrid GANs to generate images. Finally, we empirically analyze several properties related to stability and reconstruction of images from scattering coefficients. IEEE","Deep neural networks; Gray-scale; Hybrid power systems; Invariance; Pipelines; Scattering; Scattering transform; Task analysis; Wavelet transforms; Wavelets","Classification (of information); Convolution; Deep neural networks; Invariance; Neural networks; Unsupervised learning; Classification tasks; Convolutional neural network; Generic representation; Hybrid representations; Scattering co-efficient; Scattering transforms; Supervised and unsupervised learning; Wavelets; Image processing"
"Pallante L., Korfiati A., Androutsos L., Stojceski F., Bompotas A., Giannikos I., Raftopoulos C., Malavolta M., Grasso G., Mavroudi S., Kalogeras A., Martos V., Amoroso D., Piga D., Theofilatos K., Deriu M.A.","Toward a general and interpretable umami taste predictor using a multi-objective machine learning approach","10.1038/s41598-022-25935-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144147605&doi=10.1038%2fs41598-022-25935-3&partnerID=40&md5=bc76d1ecc9d66302af0d3e06c86fc562","The umami taste is one of the five basic taste modalities normally linked to the protein content in food. The implementation of fast and cost-effective tools for the prediction of the umami taste of a molecule remains extremely interesting to understand the molecular basis of this taste and to effectively rationalise the production and consumption of specific foods and ingredients. However, the only examples of umami predictors available in the literature rely on the amino acid sequence of the analysed peptides, limiting the applicability of the models. In the present study, we developed a novel ML-based algorithm, named VirtuousUmami, able to predict the umami taste of a query compound starting from its SMILES representation, thus opening up the possibility of potentially using such a model on any database through a standard and more general molecular description. Herein, we have tested our model on five databases related to foods or natural compounds. The proposed tool will pave the way toward the rationalisation of the molecular features underlying the umami taste and toward the design of specific peptide-inspired compounds with specific taste properties. © 2022, The Author(s).",,"peptide; chemistry; food; machine learning; taste; Food; Machine Learning; Peptides; Taste; Taste Perception"
"Pérez-Pons M.E., Alonso R.S., García O., Marreiros G., Corchado J.M.","Deep q-learning and preference based multi-agent system for sustainable agricultural market","10.3390/s21165276","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111780597&doi=10.3390%2fs21165276&partnerID=40&md5=2f327ea5cb4eab1e15d1139907b11e1f","Yearly population growth will lead to a significant increase in agricultural production in the coming years. Twenty-first century agricultural producers will be facing the challenge of achieving food security and efficiency. This must be achieved while ensuring sustainable agricultural systems and overcoming the problems posed by climate change, depletion of water resources, and the potential for increased erosion and loss of productivity due to extreme weather conditions. Those environmental consequences will directly affect the price setting process. In view of the price oscillations and the lack of transparent information for buyers, a multi-agent system (MAS) is presented in this article. It supports the making of decisions in the purchase of sustainable agricultural products. The proposed MAS consists of a system that supports decision-making when choosing a supplier on the basis of certain preference-based parameters aimed at measuring the sustainability of a supplier and a deep Q-learning agent for agricultural future market price forecast. Therefore, different agri-environmental indicators (AEIs) have been considered, as well as the use of edge computing technologies to reduce costs of data transfer to the cloud. The presented MAS combines price setting optimizations and user preferences in regards to accessing, filtering, and integrating information. The agents filter and fuse information relevant to a user according to supplier attributes and a dynamic environment. The results presented in this paper allow a user to choose the supplier that best suits their preferences as well as to gain insight on agricultural future markets price oscillations through a deep Q-learning agent. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Decision support systems; Deep Q-learning; Edge computing; IoT; Multi-agent systems; Sustainable agriculture","Agricultural products; Agricultural robots; Climate change; Commerce; Data transfer; Decision making; Environmental technology; Food supply; Information filtering; Learning systems; Multi agent systems; Population statistics; Purchasing; Reinforcement learning; Sustainable development; Water resources; Agri-environmental indicators; Agricultural productions; Computing technology; Environmental consequences; Extreme weather conditions; Integrating information; Sustainable agricultural; Sustainable agricultural system; Deep learning; agriculture; climate change; Agriculture; Climate Change"
"Pesapane F., Volonté C., Codari M., Sardanelli F.","Artificial intelligence as a medical device in radiology: ethical and regulatory issues in Europe and the United States","10.1007/s13244-018-0645-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055889949&doi=10.1007%2fs13244-018-0645-y&partnerID=40&md5=366b891adcd85e5c660c7da6ce30ca37","Abstract: Worldwide interest in artificial intelligence (AI) applications is growing rapidly. In medicine, devices based on machine/deep learning have proliferated, especially for image analysis, presaging new significant challenges for the utility of AI in healthcare. This inevitably raises numerous legal and ethical questions. In this paper we analyse the state of AI regulation in the context of medical device development, and strategies to make AI applications safe and useful in the future. We analyse the legal framework regulating medical devices and data protection in Europe and in the United States, assessing developments that are currently taking place. The European Union (EU) is reforming these fields with new legislation (General Data Protection Regulation [GDPR], Cybersecurity Directive, Medical Devices Regulation, In Vitro Diagnostic Medical Device Regulation). This reform is gradual, but it has now made its first impact, with the GDPR and the Cybersecurity Directive having taken effect in May, 2018. As regards the United States (U.S.), the regulatory scene is predominantly controlled by the Food and Drug Administration. This paper considers issues of accountability, both legal and ethical. The processes of medical device decision-making are largely unpredictable, therefore holding the creators accountable for it clearly raises concerns. There is a lot that can be done in order to regulate AI applications. If this is done properly and timely, the potentiality of AI based technology, in radiology as well as in other fields, will be invaluable. Teaching Points: • AI applications are medical devices supporting detection/diagnosis, work-flow, cost-effectiveness. • Regulations for safety, privacy protection, and ethical use of sensitive information are needed. • EU and U.S. have different approaches for approving and regulating new medical devices. • EU laws consider cyberattacks, incidents (notification and minimisation), and service continuity. • U.S. laws ask for opt-in data processing and use as well as for clear consumer consent. © 2018, The Author(s).","Artificial intelligence; Legislation; Policy; Privacy; Radiology",
"Prabhuraj D.K., Reddy A., Laxmikantha B.P., Rajshekhar A.S., Rao M.K.","State-wide GIS for Karnataka - K-GIS benefits from EO images and GIS services",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937681481&partnerID=40&md5=da41182b673e29ff65eda58c82301631","The progressive state of Karnataka, in India, is establishing Karnataka (State) GIS (K-GIS) - which will realise the true power of EO and GIS by embedding them ""within governance"" and taken to ""every citizen"". Two of the 5 major elements of the K-GIS are key - one, a state-wide GIS Asset as an organised geo-database of EO images, satellite-based positioning data, digital maps, crowd-sourced data and geo-tagged attributes - all of these referenced and seamless as a GIS database that is constantly updated/maintained and served as ""authoritative"" data. Second, is the K-GIS Decision Support System (DSS) applications - a suite of GIS Applications services for different ministries/departments in government that enables better and informed governance; citizens - that empowers them with geographical content; to private enterprises for commercial GIS application services and for academia for education/research activities. As part of various developmental programmes, Governments fund, establish and maintain various types of assets and provide social benefits to citizens. There is no state-level Asset Register that can be monitored - thus same type of assets/works are taken up again and again and there is no transparent method of identifying beneficiaries. As part of a state-wide EO and GIS, a unique programme has been taken up to map and create a geo-spatial database of all public-funded Assets and map beneficiaries. While the GIS-based Asset register provides an inventory and helps monitoring/maintaining assets, it also helps in planning new developmental programmes/asset creation and also in planning social programmes for rightful beneficiaries. The Asset-GIS also helps in undertaking a financial analysis of allocation and ROI analysis - as it helps Government and citizens to immediately locate all Assets, their status and also identify distribution of Assets and funding status. The Assets under question total to about 45 individual Assets under 9 categories - agriculture assets, water resources assets, roads, education-assets, health assets, civic assets, communication assets, heritage assets and many others. Mapping and documentation of all public assets and beneficiaries of government support has already been undertaken for almost 1 Million Assets in 5 districts (later to expand to another 10 Million Assets in the state) using EO-image as a map/image base; survey grade precision GPS inventory and geo-tagged to individual Asset-MIS data - leading to a comprehensive Asset-GIS database. A GIS-based Decision Support System allows querying tools, allocation analysis, gap analysis, various MIS reports and other innovative EO-based GIS mapping services. This EO/GIS project in Karnataka is serving as a ""common repository"" accessible to all departments and citizens - leading to a transparent process of information flow for governance, financial allocation, planning and maintaining Assets - apart from identifying gap areas in developments and also identifying social benefits. The paper thus outlines the vision of K-GIS with specific examples of GIS Applications DSS in agriculture, water resources, city planning and administration, publicly funded project monitoring - key/specific examples of EO-images and map based GIS decision support examples of governance. The paper also outlines the scope of the Asset-GIS application and describes how geo-spatial techniques - a combination of EO images+GPS survey+ GIS Applications have enabled this Copyright © 2014 by the International Astronautical Federation All rights reserved.",,"Agriculture; Artificial intelligence; Database systems; Decision support systems; Economic and social effects; Finance; Global positioning system; Mapping; Public administration; Query processing; Surveys; Tracking (position); Water resources; Decision support system (dss); Financial analysis; Geo-spatial database; GIS based decision support systems; Government supports; Private enterprise; State of karnataka; Transparent process; Geographic information systems"
"Prasannakumar M., Latha K.","E-Vivasaya: An efficient farm land data collection for transparent agri-subsidies distribution and prediction of agricultural product demand",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082925080&partnerID=40&md5=016fedd559d72e7bc54bdc23f5ccd9ba","Improvements in Information and Communication Technology (ICT) and the government initiatives in e-governance are only promoting e-agriculture in India. This process not only improves the condition of Indian agriculture but also the life and working conditions of the farmers. Agriculture subsidies are one of evolving issue in the world. In India from last several years government offers subsidies to agriculture zone in direct & indirect method. But how much they are favorable to agriculture division is query. Though the agricultural divisions really benefited by the subsidies but due to misconduct in distribution methods in providing subsidies and schemes are not reached properly to our farmers. And also inadequate estimation of demand and the consequences of over production or under production can cause serious financial consequences for a seed company. It creates the huge price variation in vegetables and food. To solve these problem this paper proposes a system E-vivasaya was invoked to get the proper records of the farmers and farm lands from the farmers via Mobile App. The primary objective of this work to classify the farm records (attributes such as soil type, seeding date, cultivated area, crops) and predict the agriculture product demand using Machine learning techniques. © 2020 SERSC.","Agriculture; Crop yield prediction; Machine learning; Random forest algorithm; Subsidies",
"Qiu T., Underhill A., Sapkota S., Cadle-Davidson L., Jiang Y.","Deep learning-based saliency maps for the quantification of grape powdery mildew at the microscopic level","10.13031/aim.202100496","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114199172&doi=10.13031%2faim.202100496&partnerID=40&md5=946d14ca9aa1f5fc5b955f48ea71b935","Powdery mildew (PM) is one of the most widespread plant diseases and can damage a wide range of crops, causing significant economic losses annually. This urges the breeding of PM resistant crop cultivars and the development of management practices. A major bottleneck is the accuracy and efficiency of image analysis at the microscopic level, which is essential to understand PM infection and accelerate crop breeding and management practice development. The overall goal of this study was to develop a deep learning-based saliency map approach that can quantify PM infection in images of high spatial resolution. A subset of a total of 2690 images of 1-cm leaf disks was randomly selected to extract a total of 21,162 image patches of 224×224 pixels. A custom thresholding method was used to mask out irrelevant background information from a leaf disk image. The remaining image part was cropped into image patches of 224×224 pixels to be classified by pretrained CNN classifiers. For the patches predicted as infected, patch saliency maps were generated using several saliency methods. All patch saliency maps were re-assembled to construct a leaf-level infection map for the quantification of PM infection in leaf disk images. Experimental results showed that with a well-trained CNN classifier (validation accuracy of 95.66%), our approach achieved remarkable accuracy of the localization and quantification of PM hyphae by using only patch-level class annotations, suggesting a great potential of reducing annotation cost for deep learning-based quantification. Compared with the manual assessment, our approach also improved the processing speed by 20 to 60 times. Therefore, the developed approach can be an effective and efficient analysis tool for PM disease research in the future. © ASABE 2021 Annual International Meeting","Disease quantification; Explainable AI; Grape powdery mildew; High-throughput phenotyping","Crops; Fungi; Image segmentation; Losses; Pixels; Background information; Disease research; Efficient analysis; Grape powdery mildew; High spatial resolution; Management practices; Microscopic levels; Thresholding methods; Deep learning"
"Qiu Z., Xu T., Langerman J., Das W., Wang C., Nair N., Aristizabal O., Mamou J., Turnbull D.H., Ketterling J.A., Wang Y.","A Deep Learning Approach for Segmentation, Classification, and Visualization of 3-D High-Frequency Ultrasound Images of Mouse Embryos","10.1109/TUFFC.2021.3068156","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103238757&doi=10.1109%2fTUFFC.2021.3068156&partnerID=40&md5=435c857947ffcf85b19333089531782d","Segmentation and mutant classification of high-frequency ultrasound (HFU) mouse embryo brain ventricle (BV) and body images can provide valuable information for developmental biologists. However, manual segmentation and identification of BV and body requires substantial time and expertise. This article proposes an accurate, efficient and explainable deep learning pipeline for automatic segmentation and classification of the BV and body. For segmentation, a two-stage framework is implemented. The first stage produces a low-resolution segmentation map, which is then used to crop a region of interest (ROI) around the target object and serve as the probability map of the autocontext input for the second-stage fine-resolution refinement network. The segmentation then becomes tractable on high-resolution 3-D images without time-consuming sliding windows. The proposed segmentation method significantly reduces inference time (102.36-0.09 s/volume $\approx 1000\times $ faster) while maintaining high accuracy comparable to previous sliding-window approaches. Based on the BV and body segmentation map, a volumetric convolutional neural network (CNN) is trained to perform a mutant classification task. Through backpropagating the gradients of the predictions to the input BV and body segmentation map, the trained classifier is found to largely focus on the region where the Engrailed-1 (En1) mutation phenotype is known to manifest itself. This suggests that gradient backpropagation of deep learning classifiers may provide a powerful tool for automatically detecting unknown phenotypes associated with a known genetic mutation. © 1986-2012 IEEE.","Classification and visualization; deep learning; high-frequency ultrasound (HFU); image segmentation; mouse embryo","Backpropagation; Classification (of information); Convolutional neural networks; Decoding; Image classification; Image segmentation; Three dimensional computer graphics; Ultrasonics; Automatic segmentations; Body segmentations; Classification tasks; High frequency ultrasounds; Learning classifiers; Manual segmentation; Region of interest; Segmentation methods; Deep learning; animal; echography; image processing; mouse; three-dimensional imaging; Animals; Deep Learning; Image Processing, Computer-Assisted; Imaging, Three-Dimensional; Mice; Neural Networks, Computer; Ultrasonography"
"Ramadasa A., Basappa V., Chakragiri S.V., Patankar D.B.","Geospatial Approach for Integrated Command Area Management","10.1061/(ASCE)IR.1943-4774.0001659","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124084723&doi=10.1061%2f%28ASCE%29IR.1943-4774.0001659&partnerID=40&md5=7b7fa1785e9f2bbfe9e710e9987f701e","Among the goals set by the United Nations 2030 agenda for sustainable development to address the economic component of sustainable development goal (SDG) target 6.4, More Crop Per Drop happens to be the universal motto for using water more efficiently in the agricultural sector. A fool-proof, transparent, integrated approach across different governing sectors is essential to optimally allocate the limited available resources amid the competing agricultural activities. This study has attempted to integrate a linear programming model on a geospatial platform to develop a spatial decision support and management system for integrated command area management. The study shows that the geospatial approach enhances the visualization of conventional optimization outputs under different irrigation efficiencies and fixed water allocation conditions. The geomatic model highlights water-stressed regions with 45% and optimal cropping patterns at 57% irrigation efficiency. The spatial optimization technique suggests geographic distribution of optimal cropping patterns to attain more agricultural productivity per unit of water. © 2022 American Society of Civil Engineers.","Crop water requirements; Decision support system; Geospatial optimization; Integrated command area management; Irrigation efficiencies; Land parcel information system; Supervisory control and data acquisition (SCADA) operations","Artificial intelligence; Crops; Data acquisition; Decision making; Efficiency; Geographical distribution; Information management; Information use; Irrigation; Linear programming; Planning; Productivity; Sustainable development; Water management; Area management; Crop water requirements; Geo-spatial; Geospatial optimization; Integrated command area management; Irrigation efficiency; Land parcel information system; Land parcels; Optimisations; Supervisory control and data acquisition; Supervisory control and data acquisition operation; Decision support systems; agricultural production; data acquisition; decision support system; integrated approach; irrigation; optimization; Sustainable Development Goal; water management; water use"
"Ranasinghe N., Ramanan A., Fernando S., Hameed P.N., Herath D., Malepathirana T., Suganthan P., Niranjan M., Halgamuge S.","Interpretability and accessibility of machine learning in selected food processing, agriculture and health applications","10.4038/jnsfsr.v50i0.11249","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142728547&doi=10.4038%2fjnsfsr.v50i0.11249&partnerID=40&md5=ec1eab76ad7c9ab8f6a518935776e096","Artificial Intelligence (Al) and its data-centric branch of machine learning (ML) have greatly evolved over the last few decades. However, as Al is used increasingly in real world use cases, the importance of the interpretability of and accessibility to Al systems have become major research areas. The lack of interpretability of ML based systems is a major hindrance to widespread adoption of these powerful algorithms. This is due to many reasons including ethical and regulatory concerns, which have resulted in poorer adoption of ML in some areas. The recent past has seen a surge in research on interpretable ML. Generally, designing a ML system requires good domain understanding combined with expert knowledge. New techniques are emerging to improve ML accessibility through automated model design. This paper provides a review of the work done to improve interpretability and accessibility of machine learning in the context of global problems while also being relevant to developing countries. We review work under multiple levels of interpretability including scientific and mathematical interpretation, statistical interpretation and partial semantic interpretation. This review includes applications in three areas, namely food processing, agriculture and health. © 2022, National Science Foundation. All rights reserved.","Disease detection in agriculture; drug repositioning; food processing; interpretation of neural networks; metagenomics",
"Rezania M., Javadi A.A., Giustolisi O.","An evolutionary-based data mining technique for assessment of civil engineering systems","10.1108/02644400810891526","https://www.scopus.com/inward/record.uri?eid=2-s2.0-49149128168&doi=10.1108%2f02644400810891526&partnerID=40&md5=e084820eae8ae5df1b7e37dac99fd087","Purpose - Analysis of many civil engineering phenomena is a complex problem due to the participation of a large number of factors involved. Traditional methods usually suffer from a lack of physical understanding. Furthermore, the simplifying assumptions that are usually made in the development of the traditional methods may, in some cases, lead to very large errors. The purpose of this paper is to present a new method, based on evolutionary polynomial regression (EPR) for capturing nonlinear interaction between various parameters of civil engineering systems. Design/methodology/approach - EPR is a data-driven method based on evolutionary computing, aimed to search for polynomial structures representing a system. In this technique, a combination of the genetic algorithm and the least-squares method is used to find feasible structures and the appropriate constants for those structures. Findings - Capabilities of the EPR methodology are illustrated by application to two complex practical civil engineering problems including evaluation of uplift capacity of suction caissons and shear strength of reinforced concrete deep beams. The results show that the proposed EPR model provides a significant improvement over the existing models. The EPR models generate a transparent and structured representation of the system. For design purposes, the EPR models, presented in this study, are simple to use and provide results that are more accurate than the existing methods. Originality/value - In this paper, a new evolutionary data mining approach is presented for the analysis of complex civil engineering problems. The new approach overcomes the shortcomings of the traditional and artificial neural network-based methods presented in the literature for the analysis of civil engineering systems. EPR provides a viable tool to find a structured representation of the system, which allows the user to gain additional information on how the system performs. © Emerald Group Publishing Limited.","Civil engineering; Data mining; Modelling; Polynomials","Administrative data processing; Building materials; Chlorine compounds; Civil engineering; Data mining; Data structures; Decision support systems; Electron resonance; Electron spin resonance spectroscopy; Engineering; Food processing; Genetic algorithms; Information management; Least squares approximations; Mining; Neural networks; Polynomial approximation; Polynomials; Pressure vessels; Quantum theory; Reinforced concrete; Search engines; Shear strength; Technology; Artificial Neural Network; Data-driven; Design/methodology/approach; Engineering problems; Engineering systems; Evolutionary computing; Least squares methods; Modelling; New approaches; Non-linear interactions; Polynomial regressions; Reinforced concrete deep beams; Simplifying assumptions; Suction caissons; Uplift capacity; Paramagnetic resonance"
"Rustia D.J.A., Wu Y.-F., Shih P.-Y., Chen S.-K., Chung J.-Y., Lin T.-T.","Tree-based deep convolutional neural network for hierarchical identification of low-resolution insect images","10.13031/aim.202100437","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114204721&doi=10.13031%2faim.202100437&partnerID=40&md5=8859679a9f9c001a534615ed8e9ba365","The inability to classify insects up to the species level is the current limitation of recently developed automated insect recognition algorithms. Yet, there are situations in integrated pest management (IPM) that call for more precise classification of insects. This research proposes an effective method for automated identification of low-resolution insect images found on sticky paper traps. Insect image samples were collected from sticky paper trap images that were acquired by wireless image sensor nodes installed in an outdoor mango orchard. A tree-based classifier, made up of taxonomically cascaded convolutional neural network (CNN) models, was used to automatically identify the insects on each sticky paper trap from coarse to fine taxonomic levels. The proposed tree-based classification method can classify the insect images up to an F1-score of 0.94, surpassing the performance of an optimized single multi-class image classifier model with an F1-score of 0.87. The proposed method not only boosts the classification performance, but also offers hierarchical predictions that can be used as easily interpretable information. In addition, model hyperparameter optimization, data augmentation, and classification probability threshold tuning can be applied at each level to optimize its performance. This research can be applied to support farmers in selecting IPM components, such as crop variants, pesticides, parasitoids, and more, in order to control the population of different insect species and prevent production loss. © ASABE 2021 Annual International Meeting","Convolutional neural network; Deep learning; Insect identification; Integrated pest management; Tree-based image classification","Agriculture; Convolution; Convolutional neural networks; Deep neural networks; Image acquisition; Image classification; Pest control; Sensor nodes; Automated identification; Classification methods; Classification performance; Hierarchical identification; Hyper-parameter optimizations; Integrated Pest Management; Probability threshold; Recognition algorithm; Classification (of information)"
"Sabrina F., Sohail S., Farid F., Jahan S., Ahamed F., Gordon S.","An Interpretable Artificial Intelligence Based Smart Agriculture System","10.32604/cmc.2022.026363","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127341562&doi=10.32604%2fcmc.2022.026363&partnerID=40&md5=e108fa83bf09e2ec1ea42205cb1001d8","With increasing world population the demand of food production has increased exponentially. Internet of Things (IoT) based smart agriculture system can play a vital role in optimising crop yield by managing crop requirements in real-Time. Interpretability can be an important factor to make such systems trusted and easily adopted by farmers. In this paper, we propose a novel artificial intelligence-based agriculture system that uses IoT data to monitor the environment and alerts farmers to take the required actions for maintaining ideal conditions for crop production. The strength of the proposed system is in its interpretability which makes it easy for farmers to understand, trust and use it. The use of fuzzy logic makes the system customisable in terms of types/number of sensors, type of crop, and adaptable for any soil types and weather conditions. The proposed system can identify anomalous data due to security breaches or hardware malfunction using machine learning algorithms. To ensure the viability of the system we have conducted thorough research related to agricultural factors such as soil type, soil moisture, soil temperature, plant life cycle, irrigation requirement and water application timing for Maize as our target crop. The experimental results show that our proposed system is interpretable, can detect anomalous data, and triggers actions accurately based on crop requirements. © 2022 Tech Science Press. All rights reserved.","Explainable artificial intelligence; fuzzy logic; internet of things; machine learning; sensors; smart agriculture","Computer circuits; Crops; Cultivation; Fuzzy logic; Learning algorithms; Life cycle; Machine learning; Monitoring; Soil moisture; Agriculture systems; Crop yield; Explainable artificial intelligence; Food production; Fuzzy-Logic; Interpretability; Sensor; Smart agricultures; Soil types; World population; Internet of things"
"Saghezchi F.B., Mantas G., Violas M.A., de Oliveira Duarte A.M., Rodriguez J.","Machine Learning for DDoS Attack Detection in Industry 4.0 CPPSs","10.3390/electronics11040602","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124460277&doi=10.3390%2felectronics11040602&partnerID=40&md5=ce13b7a73afffcadf9778c3b509bc1cb","The Fourth Industrial Revolution (Industry 4.0) has transformed factories into smart Cyber-Physical Production Systems (CPPSs), where man, product, and machine are fully interconnected across the whole supply chain. Although this digitalization brings enormous advantages through customized, transparent, and agile manufacturing, it introduces a significant number of new attack vectors—e.g., through vulnerable Internet-of-Things (IoT) nodes—that can be leveraged by attackers to launch sophisticated Distributed Denial-of-Service (DDoS) attacks threatening the availability of the production line, business services, or even the human lives. In this article, we adopt a Machine Learning (ML) approach for network anomaly detection and construct different data-driven models to detect DDoS attacks on Industry 4.0 CPPSs. Existing techniques use data either artificially synthesized or collected from Information Technology (IT) networks or small-scale lab testbeds. To address this limitation, we use network traffic data captured from a real-world semiconductor production factory. We extract 45 bidirectional network flow features and construct several labeled datasets for training and testing ML models. We investigate 11 different supervised, unsupervised, and semi-supervised algorithms and assess their performance through extensive simulations. The results show that, in terms of the detection performance, supervised algorithms outperform both unsupervised and semi-supervised ones. In particular, the Decision Tree model attains an Accuracy of 0.999 while confining the False Positive Rate to 0.001. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","Cyber-physical system (CPS); Cybersecurity; DDoS attack detection; Industrial control system (ICS); Industry 4.0; Intrusion detection system (IDS); Machine learning; SCADA",
"Sayed G.I., Hassanien A.E.","Explainable AI and Slime Mould Algorithm for Classification of Pistachio Species","10.1007/978-3-031-13702-0_3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141680820&doi=10.1007%2f978-3-031-13702-0_3&partnerID=40&md5=72d1415e9023e033faea877db389cf17","The safety and quality of the food are considered an essential issue in the entire world. This is due to food being the basis of human health. Nowadays, machine learning algorithms have embodied the recent technology in all stages of food processing such as food grading, food quality determination, and food classification. Pistachio nuts have an important role in the agricultural economy. To increase the efficiency of post-harvest industrial processes, there is a need to introduce technologies for classifying different species of pistachio. This study considers an automated model to separate pistachio species. The proposed pistachio species classification consists of three main phases; features selection based on slime mould algorithm phase, feature interpretation based on explainable artificial intelligence phase, and finally classification of pistachio species using logistic regression phase. The proposed pistachio species classification model obtained overall 90% classification accuracy, 90% precision, and 91% f1-score. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","Explainable artificial intelligence; Feature selection; Food Industry; Pistachio species; Swarm intelligence",
"Schoenke J., Aschenbruck N., Interdonato R., Kanawati R., Meisener A.-C., Thierart F., Vial G., Atzmueller M.","Gaia-AgStream: An Explainable AI Platform for Mining Complex Data Streams in Agriculture","10.1007/978-3-030-88259-4_6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119875445&doi=10.1007%2f978-3-030-88259-4_6&partnerID=40&md5=3ee852e65c1f129b82bc022ceead0f53","We present a position paper about our concept for an artificial intelligence (AI) and data streaming platform for the agricultural sector. The goal of our project is to support agroecology in terms of carbon farming and biodiversity protection by providing an AI and data streaming platform called Gaia-AgStream that accelerates the adoption of AI in agriculture and is directly usable by farmers as well as agricultural companies in general. The technical innovations we propose focus on smart sensor networks, unified uncertainty management, explainable AI, root cause analysis and hybrid AI approaches. Our AI and data streaming platform concept contributes to the European open data infrastructure project Gaia-X in terms of interoperability for data and AI models as well as data sovereignty and AI infrastructure. Our envisioned platform and the developed AI components for carbon farming and biodiversity will enable farmers to adopt sustainable and resilient production methods while establishing new and diverse revenue streams by monetizing carbon sequestration and AI ready data streams. The open and federated platform concept allows to bring together research, industry, agricultural start-ups and farmers in order to form sustainable innovation networks. We describe core concepts and architecture of our proposed approach in these contexts, outline practical use cases for our platform and finally outline challenges and future prospects. © 2021, Springer Nature Switzerland AG.","Agroecology; Anomaly detection; Biodiversity; Carbon farming; Complex networks; Data fusion; Data quality; Distributed systems; Explainable AI; Knowledge graph; Machine learning; Root cause analysis; Sensor networks; Uncertainty management","Agriculture; Anomaly detection; Biodiversity; Complex networks; Data integration; Data reduction; Information management; Knowledge graph; Open Data; Quality control; Semantic Web; Sensor data fusion; Sensor networks; Uncertainty analysis; Agro ecologies; Anomaly detection; Carbon farming; Data quality; Data streaming; Explainable artificial intelligence; Knowledge graphs; Root cause analysis; Sensors network; Uncertainty management; Machine learning"
"Senthilkumar C., Kamarasan M.","Optimal Segmentation with Back-Propagation Neural Network (BPNN) Based Citrus Leaf Disease Diagnosis","10.1109/ICSSIT46314.2019.8987749","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080099241&doi=10.1109%2fICSSIT46314.2019.8987749&partnerID=40&md5=cdbf16aea995eb2cc3fcac712e42786d","In recent years, plant diseases in agriculture are mainly accountable for production loss, which leads to a huge economical loss. Citrus plants are utilized as an important part of nutrients such as vitamin C. At the same time, 'Citrus' disease seriously affected the growth and quality of citrus fruits. Recently, computer vision models have been commonly employed to detect and classify plant diseases. In this study, an optimal segmentation with classification model for citrus plant disease is presented. The presented model involves a set of various sub-processes. The citrus lesion spots undergo extraction using a weighted segmentation approach that takes place on improved test image. Next, different characteristics undergo codebook construction. In addition, the optimal characteristics are chosen by a hybridization model. The chosen features are provided to Back Propagation Neural Network (BPNN) for classifying citrus diseases. The presented method is validated on Citrus Disease Image Gallery Dataset. The presented model shows extraordinary results over the compared methods and also attains superior results on the applied test images. © 2019 IEEE.","Citrus fruit; Classification; Lesions; Neural Network; Segmentation","Backpropagation; Classification (of information); Diagnosis; Image enhancement; Image segmentation; Neural networks; Torsional stress; Back-propagation neural networks; Classification models; Codebook constructions; Leaf disease; Lesions; Optimal segmentation; Plant disease; Production loss; Citrus fruits"
"Shanker R., Khan D., Hossain R., Islam M.T., Locock K., Ghose A., Sahajwalla V., Schandl H., Dhodapkar R.","Plastic waste recycling: existing Indian scenario and future opportunities","10.1007/s13762-022-04079-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127568517&doi=10.1007%2fs13762-022-04079-x&partnerID=40&md5=a2b93bee77b2c383137fc24605171836","This review article aims to suggest recycling technological options in India and illustrates plastic recycling clusters and reprocessing infrastructure for plastic waste (PW) recycling in India. The study shows that a majority of states in India are engaged in recycling, road construction, and co-processing in cement kilns while reprocessing capabilities among the reprocessors are highest for polypropylene (PP) and polyethylene (PE) polymer materials. This review suggests that there are key opportunities for mechanical recycling, chemical recycling, waste-to-energy approaches, and bio-based polymers as an alternative to deliver impact to India’s PW problem. On the other hand, overall, polyurethane, nylon, and polyethylene terephthalate appear most competitive for chemical recycling. Compared to conventional fossil fuel energy sources, polyethylene (PE), polypropylene (PP), and polystyrene are the three main polymers with higher calorific values suitable for energy production. Also, multi-sensor-based artificial intelligence and blockchain technology and digitization for PW recycling can prove to be the future for India in the waste flow chain and its management. Overall, for a circular plastic economy in India, there is a necessity for a technology-enabled accountable quality-assured collaborative supply chain of virgin and recycled material. © 2022, The Author(s) under exclusive licence to Iranian Society of Environmentalists (IRSEN) and Science and Research Branch, Islamic Azad University.","Biological recycling; Blockchain technology; Chemical recycling; Digitization; Informal and formal sector; Mechanical recycling","Blockchain; Plastic bottles; Plastic recycling; Polyethylene terephthalates; Polypropylenes; Supply chains; Waste incineration; Waste management; Biological recycling; Block-chain; Blockchain technology; Chemical recycling; Digitisation; Formal sector; Indian scenarios; Informal sector; Mechanical recycling; Plastics recycling; Fossil fuels"
"Shi M., Zhang S., Lu H., Zhao X., Wang X., Cao Z.","Phenotyping multiple maize ear traits from a single image: Kernels per ear, rows per ear, and kernels per row","10.1016/j.compag.2021.106681","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122920048&doi=10.1016%2fj.compag.2021.106681&partnerID=40&md5=52fc2bde60653a8f988254373b6992c2","Certain traits of maize ears, such as kernels per ear, kernels per row, and rows per ear, are highly related with the grain yield and stress resistance. They can be used as quantitative indices for selecting superior varieties and analyzing experimental results in maize breeding. However, these traits are often manually obtained, which is laborious and prone to error. Image-based object counting methods can replace the manual counting procedure safely, which is fast and accurate. Although a constellation of methods have been proposed, problems remain: i) classic image processing-based methods are not robust to variations of illuminations and resolutions; ii) deep learning-based object counting methods can only predict the total kernels per ear. To address this, we propose a high-throughput maize ear phenotyping pipeline. From a single image, our pipeline estimates kernels per ear, rows per ear, and kernels per row in an interpretable way. The image is first input into a Maize Kernel Counting Network (MKNet), which outputs the estimated kernel density map. Then, receiving the density map as input, a Row Mask Generator (RMG) generates a series of masks; each covers a ear row. Naturally, rows per ear and kernels per row can be recovered from the masks. Extensive experiments show that our method can predict kernels per ear, rows per ear, and kernels per row precisely, with a mean absolute error of 7.48,0.32 and 1.07, respectively. The results show that, compared with existing object counting methods, MKNet can not only reduce the counting error on kernels per ear, but also produce more accurate localization of maize kernels. The visualizations also demonstrate that RMG is robust to the irregular shapes of ear rows. © 2022 Elsevier B.V.","Convolutional neural network; Deep learning; Kernels per row; Maize kernel counting; Rows per ear","Convolutional neural networks; Deep learning; Errors; Image processing; Yield stress; Convolutional neural network; Deep learning; Kernel per row; Maize ears; Maize kernel counting; Maize kernels; Object counting; Phenotyping; Row per ear; Single images; Pipelines; artificial neural network; breeding; crop yield; data processing; error analysis; experimental design; experimental study; maize; phenotype"
"Shinkar S.V., Thankachan D.","SCMBQA: Design of a Customised SCM-Aware Sidechaining Model for QoS Enhancement under Attack Scenarios","10.17762/ijritcc.v10i1s.5824","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144358575&doi=10.17762%2fijritcc.v10i1s.5824&partnerID=40&md5=ad3639a03b13193a47ca8f4983feb3c7","Storing & processing data for supply chain management (SCM) systems requires design of high-security and quality of service (QoS) aware models. These modelsassist in improving traceability performance of SCM deployments via integration of transparent & distributed mechanisms. A wide variety of security models are proposed by researchers to perform these tasks, and it is observed that blockchain-based SCM implementations outperform other models in terms of security & QoS metrics.But most of these implementationsare general-purpose and do not incorporate SCM-specific consensus & mining rules. It is also observed that, mining speed& throughput performance of these blockchain-based implementations reduces exponentially w.r.t. number of SCM transactions. To resolve these issues, this paper discusses design of a novel Proof-of-Supply Chain (PoSC) based consensus model, which is specifically designed for sidechain based SCM deployments. The PoSC consensus model is used for high-efficiency SCM-based data storage and communication scenarios. The proposed PoSC consensus model is capable of resisting selfish mining, time jacking, and sybil attacks, which are targeted towards SCM deployments. The model uses temporal performance metrics of miner nodes, and combines them with relationship graphs to form an SCM miner rank. Based on this rank, miner nodes are selected, and their consensus responses are recorded. These responses are processed using an augmented deep learning model, that is trained over 8 different SCM implementations via machine learning. After successful mining, responses obtained from these miners are used to incrementally train the machine learning model which assists in continuous performance improvement. The SCMBQA model was tested on milk supply chain, agriculture supply chain, and electronic supply chain applications, in terms of computational speed, throughput, energy requirement, retrieval & verification delay, and storage requirements. It was observed that the proposed PoSC consensus was capable of improving the computational speed by 8.5%, reduce energy consumption by 4.9%, improve throughput by 9.6%, and reduce storage costs by 15.4% when compared with standard blockchain-based SCM consensus models. This is because the proposed model deploys an intelligent sidechaining approach, that is capable of optimizing number of generated sidechains via temporal QoS & security performance metrics. Due to use of smaller chain lengths, the proposed model is capable of integrating privacy-aware & secure approaches depending upon different SCM stages. Thus, distributor-level security models are different than retailer-level security models, which assists in context-sensitive block deployments. Due to use of PoSC, the proposed model was observed to be 99.5% resilient against internal and external attacks, which makes it useful for real-time SCM deployments. © 2022 The authors.","Blockchain; consensus; context; privacy; QoS; SCM; security; sidechain",
"Shinkar S.V., Thankachan D.","An Empirical Review of Blockchain Models for Supply Chain Management from an Analytical Perspective","10.1109/ICCMC53470.2022.9753962","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129180538&doi=10.1109%2fICCMC53470.2022.9753962&partnerID=40&md5=b0e5eade2f940c21a22c91a82d72407b","Supply chain management (SCM) involves design of multiple processes which includes procurement of goods, manufacturing, warehousing, transportation, distribution and selling to customer. Each of these steps requires design development of secure product tracking, privacy preservation, transparent transaction handling, trust modelling and distributed processing operations. These operational characteristics can be directly mapped with blockchains, because they provide transparency, traceability, immutability, and distributed mining operations. Thus, blockchains are quickly gaining popularity as one of the most favorable solutions for SCM modelling. In order to model SCM, a wide variety of blockchain-based solutions are proposed by researchers over the years, and each of these solutions vary in terms performance parameters. These parameters include, response time, scalability, security level, delay to add a new block, cost of deployment, and computational complexity. Due to such a wide variety of algorithmic availability, it becomes ambiguous for SCM designers to select the best blockchain models for a given application. In order to reduce this ambiguity, a survey of recently proposed blockchain models for SCM application are discussed in this text. Most of these models are based on machine learning, and are characterized on the basis of their nuances, advantages, limitations, and possible future research scopes. Upon referring this descriptive review, readers would be able to summarize characteristics for each SCM implementation, and identify the best suited models for their deployments. This text also compares the reviewed models in terms of statistical parameters like delay of block mining, searching time for SCM transaction, security level, computational complexity, and probable use cases. These performance metrics are compared across different models in order to estimate the best performing models for a given blockchain application. After referring this comparison, researchers will be able identify most optimum model their configuration for application-specific SCM deployments. Furthermore, this text also recommends various methods to improve performance of the reviewed models in order to apply them for real-time deployments. © 2022 IEEE.","Blockchain; machine learning; performance; privacy; SCM; security; transparency","Computational complexity; Distribution of goods; Machine learning; Supply chain management; Transparency; Block-chain; Design development; Multiple process; Performance; Privacy; Privacy preservation; Product tracking; Security; Security level; Trust models; Blockchain"
"Shook J., Gangopadhyay T., Wu L., Ganapathysubramanian B., Sarkar S., Singh A.K.","Crop yield prediction integrating genotype and weather variables using deep learning","10.1371/journal.pone.0252402","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108269569&doi=10.1371%2fjournal.pone.0252402&partnerID=40&md5=55691b3b1af7b51ac00857569837ee79","Accurate prediction of crop yield supported by scientific and domain-relevant insights, is useful to improve agricultural breeding, provide monitoring across diverse climatic conditions and thereby protect against climatic challenges to crop production. We used performance records from Uniform Soybean Tests (UST) in North America to build a Long Short Term Memory (LSTM)-Recurrent Neural Network based model that leveraged pedigree relatedness measures along with weekly weather parameters to dissect and predict genotype response in multiple-environments. Our proposed models outperformed other competing machine learning models such as Support Vector Regression with Radial Basis Function kernel (SVR-RBF), least absolute shrinkage and selection operator (LASSO) regression and the data-driven USDA model for yield prediction. Additionally, for providing interpretability of the important time-windows in the growing season, we developed a temporal attention mechanism for LSTM models. The outputs of such interpretable models could provide valuable insights to plant breeders. © 2021 Shook et al.",,"article; attention; deep learning; genotype; growing season; harvest; human; long short term memory network; nonhuman; North America; pedigree; prediction; radial basis function; soybean; support vector machine; weather; crop; genetics; growth, development and aging; Crops, Agricultural; Deep Learning; Genotype; Weather"
"Sihi D., Dari B., Kuruvila A.P., Jha G., Basu K.","Explainable Machine Learning Approach Quantified the Long-Term (1981–2015) Impact of Climate and Soil Properties on Yields of Major Agricultural Crops Across CONUS","10.3389/fsufs.2022.847892","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128847400&doi=10.3389%2ffsufs.2022.847892&partnerID=40&md5=471d98bdf0f6da83427bb3fc44f307d2","A comprehensive understanding of the long-term data on the crop, soils, environment, climate, and production management would facilitate efficient data-driven decision-making in agriculture production under changing climate. We have employed an explainable machine learning algorithm (random forest model coupled with LIME; Local Interpretable Model-Agnostic Explanations framework) using multi-decadal (1981–2015) data on climate variables, soil properties, and yield of major crops across the Coterminous United States (CONUS). This data-driven approach explained the multi-faceted factors of crop production for corn, soybean, cotton, and wheat under field conditions by leveraging agricultural informatics. We attempted to show how crop yields can better be correlated and explained when production input varies along with changing climatic/environmental and edaphic conditions. Our findings suggest Growing Degree Days (GDDs) as important climatic factors, while water holding capacity is one of the dominant soil properties in interpreting crop yield variability. Our findings will facilitate growers, crop production scientists, land management specialists, stakeholders, and policy makers in their future decision-making processes related to sustainable and long-term soil, water, and crop management practices. Copyright © 2022 Sihi, Dari, Kuruvila, Jha and Basu.","climate change; crop production; environment; explainable machine learning; local interpretable model-agnostic explanations; soils",
"Singh A., Gutub A., Nayyar A., Khan M.K.","Redefining food safety traceability system through blockchain: findings, challenges and open issues","10.1007/s11042-022-14006-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140883499&doi=10.1007%2fs11042-022-14006-4&partnerID=40&md5=18773964a910927c4aeb2dc4f9bcc9dd","In the last few decades, there has been an increase in food safety and traceability issues. To prevent accidents and misconduct, it became essential to establish Food Safety Traceability System (FSTS) to trace the food from producer to consumer. The traceability systems can help track food in supply chains from farms to retail. Numerous technologies such as Radio Frequency Identification (RFID), sensor networks, and data mining have been integrated into traditional food supply chain systems to remove unsafe food products from the chain. But, these are not adequate for the current supply chain market. The emerging technology of blockchain can overcome safety and tracking issues. This can be possible with the help of blockchain features like transparent, decentralized, distributed, and immutable. Most of the previous works missed the discussion of the systematic process and technology involved in implementing the FSTS using blockchain. In this paper, we have discussed an organized state of research of the existing FSTS using blockchain. This survey paper aims to outline a detailed analysis of blockchain technology, FSTS using blockchain, consensus algorithms, security attacks, and solutions. Several survey papers and solutions based on blockchain are included in this research paper. Also, this work discusses some of the open research issues related to FSTS. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.","Blockchain technology; Consensus algorithms; Food safety traceability systems; Security and privacy issues","Blockchain; Data mining; Food safety; Food supply; Radio frequency identification (RFID); Sensor networks; Surveys; Block-chain; Blockchain technology; Consensus algorithms; Food safety traceability system; Food traceabilitys; Food-safety; Radio-frequency-identification; Security and privacy issues; Sensors data; Traceability systems; Supply chains"
"Sinha R., Kachru D., Ricchetti R.R., Singh-Rambiritch S., Muthukumar K.M., Singaravel V., Irudayanathan C., Reddy-Sinha C., Junaid I., Sharma G., Francis-Lyon P.A.","Leveraging genomic associations in precision digital care for weight loss: Cohort study","10.2196/25401","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106492047&doi=10.2196%2f25401&partnerID=40&md5=dbe6636e844974366c31067f975a4fd0","Background: The COVID-19 pandemic has highlighted the urgency of addressing an epidemic of obesity and associated inflammatory illnesses. Previous studies have demonstrated that interactions between single-nucleotide polymorphisms (SNPs) and lifestyle interventions such as food and exercise may vary metabolic outcomes, contributing to obesity. However, there is a paucity of research relating outcomes from digital therapeutics to the inclusion of genetic data in care interventions. Objective: This study aims to describe and model the weight loss of participants enrolled in a precision digital weight loss program informed by the machine learning analysis of their data, including genomic data. It was hypothesized that weight loss models would exhibit a better fit when incorporating genomic data versus demographic and engagement variables alone. Methods: A cohort of 393 participants enrolled in Digbi Health's personalized digital care program for 120 days was analyzed retrospectively. The care protocol used participant data to inform precision coaching by mobile app and personal coach. Linear regression models were fit of weight loss (pounds lost and percentage lost) as a function of demographic and behavioral engagement variables. Genomic-enhanced models were built by adding 197 SNPs from participant genomic data as predictors and refitted using Lasso regression on SNPs for variable selection. Success or failure logistic regression models were also fit with and without genomic data. Results: Overall, 72.0% (n=283) of the 393 participants in this cohort lost weight, whereas 17.3% (n=68) maintained stable weight. A total of 142 participants lost 5% bodyweight within 120 days. Models described the impact of demographic and clinical factors, behavioral engagement, and genomic risk on weight loss. Incorporating genomic predictors improved the mean squared error of weight loss models (pounds lost and percent) from 70 to 60 and 16 to 13, respectively. The logistic model improved the pseudo R2 value from 0.193 to 0.285. Gender, engagement, and specific SNPs were significantly associated with weight loss. SNPs within genes involved in metabolic pathways processing food and regulating fat storage were associated with weight loss in this cohort: rs17300539_G (insulin resistance and monounsaturated fat metabolism), rs2016520_C (BMI, waist circumference, and cholesterol metabolism), and rs4074995_A (calcium-potassium transport and serum calcium levels). The models described greater average weight loss for participants with more risk alleles. Notably, coaching for dietary modification was personalized to these genetic risks. Conclusions: Including genomic information when modeling outcomes of a digital precision weight loss program greatly enhanced the model accuracy. Interpretable weight loss models indicated the efficacy of coaching informed by participants' genomic risk, accompanied by active engagement of participants in their own success. Although large-scale validation is needed, our study preliminarily supports precision dietary interventions for weight loss using genetic risk, with digitally delivered recommendations alongside health coaching to improve intervention efficacy. © Ranjan Sinha, Dashyanng Kachru, Roshni Ray Ricchetti, Simitha Singh-Rambiritch, Karthik Marimuthu Muthukumar, Vidhya Singaravel, Carmel Irudayanathan, Chandana Reddy-Sinha, Imran Junaid, Garima Sharma, Patricia Alice Francis-Lyon. Originally published in the Journal of Medical Internet Research (https://www.jmir.org), 19.05.2021. This is an open-access article distributed under the terms of the Creative Commons Attribution License (https://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work, first published in the Journal of Medical Internet Research, is properly cited. The complete bibliographic information, a link to the original publication on https://www.jmir.org/, as well as this copyright and license information must be included.","Digital therapeutics; Gut microbiota; Health coaching; Lifestyle medicine; Machine learning; MHealth; Mobile apps; Mobile phone; Nutrigenomics; Obesity; Personalized nutrition; Precision nutrition","calcium; monounsaturated fatty acid; adult; allele; Article; body mass; body weight loss; calcium blood level; calcium transport; cholesterol metabolism; cohort analysis; data analysis; demography; female; genetic risk; health program; human; insulin resistance; lifestyle; lipid metabolism; lipid storage; machine learning; major clinical study; male; mobile application; patient engagement; potassium transport; retrospective study; single nucleotide polymorphism; waist circumference; weight loss program; body weight; body weight loss; epidemiology; epigenetics; genetics; genomics; isolation and purification; middle aged; pandemic; physiology; procedures; Body Weight; Cohort Studies; COVID-19; Epigenomics; Female; Genomics; Humans; Male; Middle Aged; Pandemics; Polymorphism, Single Nucleotide; Retrospective Studies; SARS-CoV-2; Weight Loss; Weight Reduction Programs"
"Streich J., Romero J., Gazolla J.G.F.M., Kainer D., Cliff A., Prates E.T., Brown J.B., Khoury S., Tuskan G.A., Garvin M., Jacobson D., Harfouche A.L.","Can exascale computing and explainable artificial intelligence applied to plant biology deliver on the United Nations sustainable development goals?","10.1016/j.copbio.2020.01.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079546842&doi=10.1016%2fj.copbio.2020.01.010&partnerID=40&md5=006c224ddebcd01a3660ed324db007dd","Human population growth and accelerated climate change necessitate agricultural improvements using designer crop ideotypes (idealized plants that can grow in niche environments). Diverse and highly skilled research groups must integrate efforts to bridge the gaps needed to achieve international goals toward sustainable agriculture. Given the scale of global agricultural needs and the breadth of multiple types of omics data needed to optimize these efforts, explainable artificial intelligence (AI with a decipherable decision making process that provides a meaningful explanation to humans) and exascale computing (computers that can perform 1018 floating-point operations per second, or exaflops) are crucial. Accurate phenotyping and daily-resolution climatype associations are equally important for refining ideotype production to specific environments at various levels of granularity. We review advances toward tackling technological hurdles to solve multiple United Nations Sustainable Development Goals and discuss a vision to overcome gaps between research and policy. © 2020 Elsevier Ltd",,"Agriculture; Artificial intelligence; Climate change; Decision making; Digital arithmetic; Planning; Population statistics; Sustainable development; Decision making process; Exascale computing; Floating point operations per seconds; Human population growth; Plant biology; Research groups; Sustainable agriculture; United Nations; Plants (botany); artificial intelligence; bioenergy; botany; climate change; computer analysis; crop; ecological niche; environmental mutagenesis; epigenetics; exascale computing; food security; genetic association; genomics; genotype; greenhouse gas; harvest; human; mathematical computing; metabolomics; multiomics; nonhuman; phenomics; phenotype; priority journal; proteomics; Review; sustainable development; time series analysis; transcriptomics; agriculture; motivation; United Nations; Agriculture; Artificial Intelligence; Goals; Humans; Sustainable Development; United Nations"
"Tahir G.A., Loo C.K.","Explainable deep learning ensemble for food image analysis on edge devices","10.1016/j.compbiomed.2021.104972","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118534024&doi=10.1016%2fj.compbiomed.2021.104972&partnerID=40&md5=8672f6151531800daebad7164c8c9799","Food recognition systems recently garnered much research attention in the relevant field due to their ability to obtain objective measurements for dietary intake. This feature contributes to the management of various chronic conditions. Challenges such as inter and intraclass variations alongside the practical applications of smart glasses, wearable cameras, and mobile devices require resource-efficient food recognition models with high classification performance. Furthermore, explainable AI is also crucial in health-related domains as it characterizes model performance, enhancing its transparency and objectivity. Our proposed architecture attempts to address these challenges by drawing on the strengths of the transfer learning technique upon initializing MobiletNetV3 with weights from a pre-trained model of ImageNet. The MobileNetV3 achieves superior performance using the squeeze and excitation strategy, providing unequal weight to different input channels and contrasting equal weights in other variants. Despite being fast and efficient, there is a high possibility for it to be stuck in the local optima like other deep neural networks, reducing the desired classification performance of the model. Thus, we overcome this issue by applying the snapshot ensemble approach as it enables the M model in a single training process without any increase in the required training time. As a result, each snapshot in the ensemble visits different local minima before converging to the final solution which enhances recognition performance. On overcoming the challenge of explainability, we argue that explanations cannot be monolithic, since each stakeholder perceive the results’, explanations based on different objectives and aims. Thus, we proposed a user-centered explainable artificial intelligence (AI) framework to increase the trust of the involved parties by inferencing and rationalizing the results according to needs and user profile. Our framework is comprehensive in terms of a dietary assessment app as it detects Food/Non-Food, food categories, and ingredients. Experimental results on the standard food benchmarks and newly contributed Malaysian food dataset for ingredient detection demonstrated superior performance on an integrated set of measures over other methodologies. © 2021 Elsevier Ltd","Data augmentation; Deep learning; Ensemble learning; Explainable AI; Food recognition; Mobile application; Neural network; User-centred explainable AI","Deep neural networks; Data augmentation; Deep learning; Ensemble learning; Explainable artificial intelligence; Food recognition; Mobile applications; Neural-networks; Performance; User-centered explainable artificial intelligence; User-centred; Benchmarking; Article; artificial intelligence; binary classification; classification algorithm; comparative study; convolutional neural network; decision making; deep learning; deep neural network; dietitian; food analysis; human; image analysis; machine learning; Malaysian; mobile application; multilabel classification; nutritional assessment; radial basis function; support vector machine; transfer of learning; artificial intelligence; food; image processing; Artificial Intelligence; Deep Learning; Food; Image Processing, Computer-Assisted; Neural Networks, Computer"
"Taj I., Jhanjhi N.Z.","Towards Industrial Revolution 5.0 and Explainable Artificial Intelligence: Challenges and Opportunities","10.12785/ijcds/120124","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135748085&doi=10.12785%2fijcds%2f120124&partnerID=40&md5=a782eeb948a5a8d49b3dc5019b3e7f73","Technological growth is changing our everyday living, making it smarter and more convenient day by day; Smart society 5.0, Healthcare 5.0, Agriculture 5.0 are only a few examples indicative of our fast-evolving lifestyle. The Industrial Revolution 5.0 (IR 5.0) encapsulates future industry development trends to achieve prosperity beyond jobs by incorporating more intelligence in our everyday living with the help of cutting-edge technologies such as Explainable Artificial Intelligence. This paper reviews the enabling technologies for Industry 5.0 and suggests some pertinent research areas requiring more focus. The transition of manufacturing processes from mass production to mass personalization, the anticipated reliance on Cyber-Physical Systems (CPS) and digital twins is visualized, to identify the gaps in fully realizing the revolution. The operations of smart factories to enhance the overall productivity, modern workforce comprising of human-machine collaboration, means of heterogeneous data transmission & data interoperability, and security & privacy issues are reviewed to identify hot research spots, that will eventually fill in the gaps within societal domains to realize Industry 5.0. The potential of the new domain of Explainable Artificial intelligence to understand the application of right tools in a data connected Industry 5.0 compliant smart society is explored. Altogether, this research explores several research challenges and opportunities linked with IR 5.0. © 2022 University of Bahrain. All rights reserved.","Big data analysis; Cloud Storage; Cyber Physical System; Digital Twins; Explainable AI; Smart Society",
"Traganos D., Lee C.B., Blume A., Poursanidis D., Čižmek H., Deter J., Mačić V., Montefalcone M., Pergent G., Pergent-Martini C., Ricart A.M., Reinartz P.","Spatially Explicit Seagrass Extent Mapping Across the Entire Mediterranean","10.3389/fmars.2022.871799","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135517226&doi=10.3389%2ffmars.2022.871799&partnerID=40&md5=8d7be0eaab8eaf2b11e5df0307e5f72e","The seagrass Posidonia oceanica is the main habitat-forming species of the coastal Mediterranean, providing millennial-scale ecosystem services including habitat provisioning, biodiversity maintenance, food security, coastal protection, and carbon sequestration. Meadows of this endemic seagrass species represent the largest carbon storage among seagrasses around the world, largely contributing to global blue carbon stocks. Yet, the slow growth of this temperate species and the extreme projected temperature and sea-level rise due to climate change increase the risk of reduction and loss of these services. Currently, there are knowledge gaps in its basin-wide spatially explicit extent and relevant accounting, therefore accurate and efficient mapping of its distribution and trajectories of change is needed. Here, we leveraged contemporary advances in Earth Observation—cloud computing, open satellite data, and machine learning—with field observations through a cloud-native geoprocessing framework to account the spatially explicit ecosystem extent of P. oceanica seagrass across its full bioregional scale. Employing 279,186 Sentinel-2 satellite images between 2015 and 2019, and a human-labeled training dataset of 62,928 pixels, we mapped 19,020 km2 of P. oceanica meadows up to 25 m of depth in 22 Mediterranean countries, across a total seabed area of 56,783 km2. Using 2,480 independent, field-based points, we observe an overall accuracy of 72%. We include and discuss global and region-specific seagrass blue carbon stocks using our bioregional seagrass extent estimate. As reference data collections, remote sensing technology and biophysical modelling improve and coalesce, such spatial ecosystem extent accounts could further support physical and monetary accounting of seagrass condition and ecosystem services, like blue carbon and coastal biodiversity. We envisage that effective policy uptake of these holistic seagrass accounts in national climate strategies and financing could accelerate transparent natural climate solutions and coastal resilience, far beyond the physical location of seagrass beds. Copyright © 2022 Traganos, Lee, Blume, Poursanidis, Čižmek, Deter, Mačić, Montefalcone, Pergent, Pergent-Martini, Ricart and Reinartz.","Blue Carbon; Coastal ecosystem accounting; Earth Observation; Google Earth Engine Seagrass; Mediterranean; Posidonia oceanica; Sentinel-2",
"Tsakiridis N.L., Diamantopoulos T., Symeonidis A.L., Theocharis J.B., Iossifides A., Chatzimisios P., Pratos G., Kouvas D.","Versatile Internet of Things for Agriculture: An eXplainable AI Approach","10.1007/978-3-030-49186-4_16","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086181553&doi=10.1007%2f978-3-030-49186-4_16&partnerID=40&md5=62df3a310d4be25bb7caddf927de2ab3","The increase of the adoption of IoT devices and the contemporary problem of food production have given rise to numerous applications of IoT in agriculture. These applications typically comprise a set of sensors that are installed in open fields and measure metrics, such as temperature or humidity, which are used for irrigation control systems. Though useful, most contemporary systems have high installation and maintenance costs, and they do not offer automated control or, if they do, they are usually not interpretable, and thus cannot be trusted for such critical applications. In this work, we design Vital, a system that incorporates a set of low-cost sensors, a robust data store, and most importantly an explainable AI decision support system. Our system outputs a fuzzy rule-base, which is interpretable and allows fully automating the irrigation of the fields. Upon evaluating Vital in two pilot cases, we conclude that it can be effective for monitoring open-field installations. © 2020, IFIP International Federation for Information Processing.","eXplainable AI; Internet of Things; Precision irrigation","Agricultural robots; Artificial intelligence; Costs; Decision support systems; Fuzzy inference; Fuzzy rules; Humidity control; Irrigation; Automated control; Critical applications; Food production; Fuzzy rule base; Irrigation controls; Low-cost sensors; Maintenance cost; System output; Internet of things"
"Tu Y., Niu L., Zhao W., Cheng D., Zhang L.","Image cropping with composition and saliency aware aesthetic score map",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101196976&partnerID=40&md5=3edbe5f79906cd5af3d264192d4a2e25","Aesthetic image cropping is a practical but challenging task which aims at finding the best crops with the highest aesthetic quality in an image. Recently, many deep learning methods have been proposed to address this problem, but they did not reveal the intrinsic mechanism of aesthetic evaluation. In this paper, we propose an interpretable image cropping model to unveil the mystery. For each image, we use a fully convolutional network to produce an aesthetic score map, which is shared among all candidate crops during crop-level aesthetic evaluation. Then, we require the aesthetic score map to be both composition-aware and saliency-aware. In particular, the same region is assigned with different aesthetic scores based on its relative positions in different crops. Moreover, a visually salient region is supposed to have more sensitive aesthetic scores so that our network can learn to place salient objects at more proper positions. Such an aesthetic score map can be used to localize aesthetically important regions in an image, which sheds light on the composition rules learned by our model. We show the competitive performance of our model in the image cropping task on several benchmark datasets, and also demonstrate its generality in real-world applications. Copyright 2020, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",,"Benchmarking; Convolutional neural networks; Crops; Deep learning; Learning systems; Aesthetic qualities; Benchmark datasets; Competitive performance; Composition rule; Convolutional networks; Intrinsic mechanisms; Learning methods; Relative positions; Image processing"
"Van De Looverbosch T., He J., Tempelaere A., Kelchtermans K., Verboven P., Tuytelaars T., Sijbers J., Nicolai B.","Inline nondestructive internal disorder detection in pear fruit using explainable deep anomaly detection on X-ray images","10.1016/j.compag.2022.106962","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128410274&doi=10.1016%2fj.compag.2022.106962&partnerID=40&md5=37ba797f9cc2360b1e068b6ac8dd6d75","To preserve the quality of fresh fruit after harvest and to meet the year-round demand for high-quality fruit, pears are stored under a controlled atmosphere. However, due to preharvest events or suboptimal storage conditions, internal disorders might develop resulting in severe quality loss. Examples include internal browning and cavities, which are invisible externally. Here, X-ray radiography is investigated as a technique for internal quality inspection. The detection of defect fruit is approached as an anomaly detection (AD) problem, in which a model is constructed using nominal data and an anomaly score is used to identify defect fruit. In this work, multiple deep AD methods are shown to be effective to detect pears with internal cavity and browning disorders using X-ray radiographs (mean area under the receiver operating characteristic curve (AUC) up to 0.962). The best performing methods were found on par with a state-of-the-art multisensor disorder detection method (mean AUC up to 0.966). By investigating AD performance in function of internal disorder severity, it was shown that defect fruit with a cavity volume percentage > 1.0% could be detected 100% accurate using inline X-ray imaging. For lower cavity area percentages, the accuracy depended on the internal browning severity. Additionally, the explainability of the deep AD methods, i.e., how well human interpretable insight can be provided from each method's predictions, were qualitatively evaluated using anomaly heatmaps, which provided useful insight in the execution of the deep learning algorithms. © 2022 Elsevier B.V.","Deep learning; Food quality inspection; Image processing; Outlier detection; Postharvest technology","Anomaly detection; Deep learning; Defects; Digital storage; Image processing; Learning algorithms; Nondestructive examination; Quality control; Anomaly detection; Anomaly detection methods; Deep learning; Food quality; Food quality inspection; Images processing; Non destructive; Pear fruit; Postharvest technologies; Quality inspection; Fruits; anomaly; detection method; disability; food quality; fruit; image processing; learning; nondestructive testing; X-ray analysis"
"Varshney D., Babukhanwala B., Khan J., Saxena D., Singh A.K.","Machine Learning Techniques for Plant Disease Detection","10.1109/ICOEI51242.2021.9453053","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113443893&doi=10.1109%2fICOEI51242.2021.9453053&partnerID=40&md5=3c290f68ca56681a2ab016ebd469c7dc","Undoubtedly, agriculture is an essential source of livelihood, which stands as a backbone of Indian economy. The plant production is severely affected due to various kinds of diseases, which if accurately and timely detected, could raise health standards and economic growth significantly. The traditional approachesof disease detection and classification involves an immense amount of time, an intense amount of labor and constant monitoring of the farm. By using disease detection methods, diseases caused by bacteria, viruses and fungi are often avoided. Within the upkeep of agricultural goods, crop protection plays a critical role. Techniques of Machine Learning are often used to identify the affected leaf images. The various machine learning algorithms used to determine whether a plant is infected or not with a disease, are discussed in this study. It was done in various steps, such as image acquisition, feature extraction, categorization of the illness and result display. This paper also needs to carry out an accurate study of various techniques for the identification of diseases of plants. The aim is to identify the plant diseases using image analysis. It also, after detection of the illness, says the name of fertilizer to be used. The pests and insects accountable for the pandemic are also described. © 2021 IEEE.","Deep Learning; Disease Detection; Features Extraction; Machine Learning; SVM","Agricultural robots; Agriculture; Diseases; Economics; Learning algorithms; Viruses; Crop protection; Disease detection; Economic growths; Health standards; Leaf images; Machine learning techniques; Plant disease; Plant production; Machine learning"
"Venkat Narayana Rao T., Likhar P.P., Kurni M., Saritha K.","Blockchain: A new perspective in cyber technology","10.1016/B978-0-323-90193-2.00004-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137600371&doi=10.1016%2fB978-0-323-90193-2.00004-1&partnerID=40&md5=39984b5e2c19e47b265315629fa8c55f","The early days of cyberspace expansion saw many people hesitant to use the internet for two dominant reasons: obscurity and skepticism. Yet, the internet soon became a one-stop solution to a diverse range of sectors, where a need to resolve issues such as data confidentiality and integrity gained prime importance. In 2008, an online currency called Bitcoin was launched by an anonymous developer or developer community called Satoshi Nakamoto. Bitcoin was deemed to be a viable alternative to fiat or government-issued currency. What made Bitcoin famous and easily adaptable was the ease of accessibility in the form of a device application or simply “wallet” that included the nodes or “blocks” on which transaction data would be stored and processed instantaneously and the intention behind it to create a trustworthy cash system that would give individuals complete ownership of their transactions, not at risk of security breaches. With the advent and success of Bitcoin, new doors opened for other cryptocurrencies and digital assets like Ethereum and Litecoin, and it was observed that unlike fiduciary money, the sustainability of a thorough and transparent record must be maintained in connection with the exchange of digitalized money between any two parties whose anonymity would be preserved. Eventually, this became a turning point and marked the beginning of blockchain technology, which functioned as a distributed ledger system ensuring secure transactions given its strong and complex cryptographic background strengthened with the help of hashing techniques and timestamps. Nakamoto also devised the first blockchain database as a part of the implementation, and the technology synchronized all transactions across multiple geographies in a peer-to-peer network (P2P) without the involvement of mediating authorities like a bank or payments processing company. Having received extensive attention, blockchains revolve around a fundamental concept that transactions are clustered into blocks and exchanged and checked by a network of nodes in the distributed environment with mutual agreement or consensus. To achieve this, consensus algorithms are implemented to instill certainty regarding user security and ledger consistency in a distributed network. Over time, this technology penetrated spheres other than virtual currency management. It showed the unimaginable potential to eliminate enormous amounts of record organization and storage problems, streamlining supply chains, making blockchain unarguably the most important innovation since the emergence of artificial intelligence. © 2022 Elsevier Inc. All rights reserved.","Bitcoin; Blockchain; Blockchain attacks; Consensus algorithms; Emerging blockchain applications; Hashing; Merkle trees",
"Vermesan O., Bacquet J.","Cognitive hyperconnected digital transformation: Internet of things intelligence evolution",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076949866&partnerID=40&md5=67c36c3c1824cea16a6ec5af8a440655","Cognitive Hyperconnected Digital Transformation provides an overview of the current Internet of Things (IoT) landscape, ranging from research, innovation and development priorities to enabling technologies in a global context. It is intended as a standalone book in a series that covers the Internet of Things activities of the IERC-Internet of Things European Research Cluster, including both research and technological innovation, validation and deployment. The book builds on the ideas put forward by the European Research Cluster, the IoT European Platform Initiative (IoT-EPI) and the IoT European Large-Scale Pilots Programme, presenting global views and state-of-the-art results regarding the challenges facing IoT research, innovation, development and deployment in the next years. Hyperconnected environments integrating industrial/business/consumer IoT technologies and applications require new IoT open systems architectures integrated with network architecture (a knowledge-centric network for IoT), IoT system design and open, horizontal and interoperable platforms managing things that are digital, automated and connected and that function in real-time with remote access and control based on Internet-enabled tools. The IoT is bridging the physical world with the virtual world by combining augmented reality (AR), virtual reality (VR), machine learning and artificial intelligence (AI) to support the physical-digital integrations in the Internet of mobile things based on sensors/actuators, communication, analytics technologies, cyber-physical systems, software, cognitive systems and IoT platforms with multiple functionalities. These IoT systems have the potential to understand, learn, predict, adapt and operate autonomously. They can change future behaviour, while the combination of extensive parallel processing power, advanced algorithms and data sets feed the cognitive algorithms that allow the IoT systems to develop new services and propose new solutions. IoT technologies are moving into the industrial space and enhancing traditional industrial platforms with solutions that break free of device-, operating system- and protocol-dependency. Secure edge computing solutions replace local networks, web services replace software, and devices with networked programmable logic controllers (NPLCs) based on Internet protocols replace devices that use proprietary protocols. Information captured by edge devices on the factory floor is secure and accessible from any location in real time, opening the communication gateway both vertically (connecting machines across the factory and enabling the instant availability of data to stakeholders within operational silos) and horizontally (with one framework for the entire supply chain, across departments, business units, global factory locations and other markets). End-to-end security and privacy solutions in IoT space require agile, context-aware and scalable components with mechanisms that are both fluid and adaptive. The convergence of IT (information technology) and OT (operational technology) makes security and privacy by default a new important element where security is addressed at the architecture level, across applications and domains, using multi-layered distributed security measures. Blockchain is transforming industry operating models by adding trust to untrusted environments, providing distributed security mechanisms and transparent access to the information in the chain. Digital technology platforms are evolving, with IoT platforms integrating complex information systems, customer experience, analytics and intelligence to enable new capabilities and business models for digital business. © 2017 River Publishers. All rights reserved.","Artificial intelligence; Cloud computing; Cognitive systems; Cognitive transformation; Cyber-physical systems; Deep learning; Intelligence evolution; Internet of things; Virtualization; Wireless networks",
"Waithe D., Rennert P., Brostow G., Piper M.D.W.","QuantiFly: Robust trainable software for automated Drosophila egg counting","10.1371/journal.pone.0127659","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930620821&doi=10.1371%2fjournal.pone.0127659&partnerID=40&md5=248446756640123835123f821a92ed81","We report the development and testing of software called QuantiFly: an automated tool to quantify Drosophila egg laying. Many laboratories count Drosophila eggs as a marker of fitness. The existing method requires laboratory researchers to count eggs manually while looking down a microscope. This technique is both time-consuming and tedious, especially when experiments require daily counts of hundreds of vials. The basis of the QuantiFly software is an algorithm which applies and improves upon an existing advanced pattern recognition and machine-learning routine. The accuracy of the baseline algorithm is additionally increased in this study through correction of bias observed in the algorithm output. The QuantiFly software, which includes the refined algorithm, has been designed to be immediately accessible to scientists through an intuitive and responsive user-friendly graphical interface. The software is also open-source, self-contained, has no dependencies and is easily installed (https://github.com/dwaithe/quantifly). Compared to manual egg counts made from digital images, QuantiFly achieved average accuracies of 94% and 85% for eggs laid on transparent (defined) and opaque (yeast-based) fly media. Thus, the software is capable of detecting experimental differences in most experimental situations. Significantly, the advanced feature recognition capabilities of the software proved to be robust to food surface artefacts like bubbles and crevices. The user experience involves image acquisition, algorithm training by labelling a subset of eggs in images of some of the vials, followed by a batch analysis mode in which new images are automatically assessed for egg numbers. Initial training typically requires approximately 10 minutes, while subsequent image evaluation by the software is performed in just a few seconds. Given the average time per vial for manual counting is approximately 40 seconds, our software introduces a timesaving advantage for experiments starting with as few as 20 vials. We also describe an optional acrylic box to be used as a digital camera mount and to provide controlled lighting during image acquisition which will guarantee the conditions used in this study. © 2015 Waithe et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",,"algorithm; animal cell; Article; artifact; automation; camera; computer interface; computer program; Drosophila; egg counting; egg laying; female; image analysis; image processing; luminescence; measurement accuracy; nonhuman; quantitative analysis; time; animal; Drosophila; molecular genetics; physiology; procedures; software; time factor; Algorithms; Animals; Drosophila; Image Processing, Computer-Assisted; Molecular Sequence Data; Oviposition; Software; Time Factors"
"Wang M., Wander M., Mueller S., Martin N., Dunn J.B.","Evaluation of survey and remote sensing data products used to estimate land use change in the United States: Evolving issues and emerging opportunities","10.1016/j.envsci.2021.12.021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121980391&doi=10.1016%2fj.envsci.2021.12.021&partnerID=40&md5=fef3c8c8b2b0ce331fd83b00f19d4238","Transparent, consistent, and statistically reliable land use/ land cover area estimates are needed to assess land use change and greenhouse gas emissions associated with biofuel production and other land uses that are influenced by policy. As relevant studies have increased rapidly during past decades, the methods used to combine data extracted from land use land cover (LULC) surveys and remote sensing-based products and track or report sources of uncertainty vary notably. This paper reviews six data sources that are most commonly used to investigate LULC and change in the contiguous U.S. by highlighting the main characteristics, strengths and weaknesses and considering how uncertainty is assessed by the June Area Survey (JAS), the Census of Agriculture (COA), the Farm Survey Agency (FSA) acreage, the National Resources Inventory (NRI), the National Wetlands Inventory (NWI), and the Forest Inventory and Analysis (FIA); and two remote sensing-based data products, the Cropland Data Layer (CDL) and the National Land Cover Database (NLCD). The summary and conclusion identify important research gaps or challenges limiting current land use/land cover and change studies (e.g., lack of high-quality reference data and uncertainty quantification, etc.) and opportunities and emerging techniques (data fusion and machine learning) that will improve reliability of land use/land cover assessments and associated policies. Blended approaches that marry high quality ground truth data that are more finely resolved than data supplied by government surveys with multitemporal imagery are needed track use of non-agricultural lands vulnerable to agricultural expansion. These considerations are notably important as the U.S. considers the renewal and possibly revision of its Renewable Fuel Standard, which includes provisions that require monitoring of agricultural land expansion. © 2021","Biofuel policy; Error; Land use change; Land use classification; Remote sensing; Survey data; Thematic maps; Uncertainty","cropland; data quality; environmental policy; forest; grassland; information processing; land use; reliability; remote sensing; Review; uncertainty; United States; wetland"
"Wang M., Ma X., Si J., Tang H., Wang H., Li T., Ouyang W., Gong L., Tang Y., He X., Huang W., Liu X.","Adverse Drug Reaction Discovery Using a Tumor-Biomarker Knowledge Graph","10.3389/fgene.2020.625659","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100043183&doi=10.3389%2ffgene.2020.625659&partnerID=40&md5=c959f0f7e832496db05a2190285870d2","Adverse drug reactions (ADRs) are a major public health concern, and early detection is crucial for drug development and patient safety. Together with the increasing availability of large-scale literature data, machine learning has the potential to predict unknown ADRs from current knowledge. By the machine learning methods, we constructed a Tumor-Biomarker Knowledge Graph (TBKG) which contains four types of node: Tumor, Biomarker, Drug, and ADR using biomedical literatures. Based on this knowledge graph, we not only discovered potential ADRs of antitumor drugs but also provided explanations. Experiments on real-world data show that our model can achieve 0.81 accuracy of three cross-validation and the ADRs discovery of Osimertinib was chosen for the clinical validation. Calculated ADRs of Osimertinib by our model consisted of the known ADRs which were in line with the official manual and some unreported rare ADRs in clinical cases. Results also showed that our model outperformed traditional co-occurrence methods. Moreover, each calculated ADRs were attached with the corresponding paths of “tumor-biomarker-drug” in the knowledge graph which could help to obtain in-depth insights into the underlying mechanisms. In conclusion, the tumor-biomarker knowledge-graph based approach is an explainable method for potential ADRs discovery based on biomarkers and might be valuable to the community working on the emerging field of biomedical literature mining and provide impetus for the mechanism research of ADRs. © Copyright © 2021 Wang, Ma, Si, Tang, Wang, Li, Ouyang, Gong, Tang, He, Huang and Liu.","adverse drug reaction; antitumor drugs; biomarker; explainable model; knowledge graph","cytotoxic granule protein; epidermal growth factor receptor; macrophage activating factor; nucleic acid; osimertinib; plasma protein; protein; protein tyrosine kinase; tumor marker; unclassified drug; adverse drug reaction; anemia; APACHE; Article; Bayes theorem; cancer therapy; clinical validation; co occurrence analysis; constipation; cross validation; diagnostic accuracy; dialysis; European Union; Food and Drug Administration; hospital information system; hospitalization; human; immunogenetics; information processing; kappa statistics; kidney failure; lymphocytopenia; machine learning; medical literature; nephrosclerosis; non small cell lung cancer; publication; reliability; sensitivity and specificity; statistical analysis; training; tumor biomarker knowledge graph; Unified Medical Language System; validation process"
"Wang Y., Chandrasekaran J., Haberkorn F., Dong Y., Gopinath M., Batarseh F.A.","DeepFarm: AI-Driven Management of Farm Production using Explainable Causality","10.1109/STC55697.2022.00013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143434951&doi=10.1109%2fSTC55697.2022.00013&partnerID=40&md5=69032a77ab65df69633e3116fdd26e52","American agriculture has been afflicted by numerous outlier events in the past decade, such as several natural disasters, cyber-attacks, trade wars, and a global pandemic. Such unprecedented black-swans have created outcome uncertainties throughout the food supply chain, starting at the farm level for agricultural producers and aggregating at the consumption level for households and international trade flows. The primary drivers behind the shocks in agricultural productivity include strong weather-related events, transitory transportation disruptions, shipping delays, and policy shifts. This paper presents DeepFarm, an Artificial Intelligence (AI)-enabled framework to measure and manage uncertainties while evaluating multiple cause-effect scenarios in agricultural farm production. We deploy Deep Learning (DL) models to predict the impact of crop yield during outlier events such as extreme weather events and cyber-attacks. Additionally, we use a causal inference-based approach to quantity the impact of such events affecting the critical phases of farm production. Models are developed; experiments are performed; the results are recorded, evaluated, and discussed. Our results suggest that DeepFarm can effectively forecast and quantity the impact of outlier events on crop yield across different regions in the US. © 2022 IEEE.","AI for Agriculture; Causality; DeepAR; Farm Production; GAN; Synthetic Data","Computer crime; Crime; Crops; Deep learning; Disasters; Food supply; Network security; Productivity; Statistics; Supply chains; Artificial intelligence for agriculture; Causality; Crop yield; Cyber-attacks; Deepar; Farm production; GAN; Natural disasters; Synthetic data; Uncertainty; International trade"
"Weller D.L., Love T.M.T., Belias A., Wiedmann M.","Predictive Models May Complement or Provide an Alternative to Existing Strategies for Assessing the Enteric Pathogen Contamination Status of Northeastern Streams Used to Provide Water for Produce Production","10.3389/fsufs.2020.561517","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093535977&doi=10.3389%2ffsufs.2020.561517&partnerID=40&md5=f76de4514a7637bb8697d978172d68ba","While the Food Safety Modernization Act established standards for the use of surface water for produce production, water quality is known to vary over space and time. Targeted approaches for identifying hazards in water that account for this variation may improve growers' ability to address pre-harvest food safety risks. Models that utilize publicly-available data (e.g., land-use, real-time weather) may be useful for developing these approaches. The objective of this study was to use pre-existing datasets collected in 2017 (N = 181 samples) and 2018 (N = 191 samples) to train and test models that predict the likelihood of detecting Salmonella and pathogenic E. coli markers (eaeA, stx) in agricultural water. Four types of features were used to train the models: microbial, physicochemical, spatial and weather. “Full models” were built using all four features types, while “nested models” were built using between one and three types. Twenty learners were used to develop separate full models for each pathogen. Separately, to assess information gain associated with using different feature types, six learners were randomly selected and used to develop nine, nested models each. Performance measures for each model were then calculated and compared against baseline models where E. coli concentration was the sole covariate. In the methods, we outline the advantages and disadvantages of each learner. Overall, full models built using ensemble (e.g., Node Harvest) and “black-box” (e.g., SVMs) learners out-performed full models built using more interpretable learners (e.g., tree- and rule-based learners) for both outcomes. However, nested eaeA-stx models built using interpretable learners and microbial data performed almost as well as these full models. While none of the nested Salmonella models performed as well as the full models, nested models built using spatial data consistently out-performed models that excluded spatial data. These findings demonstrate that machine learning approaches can be used to predict when and where pathogens are likely to be present in agricultural water. This study serves as a proof-of-concept that can be built upon once larger datasets become available and provides guidance on the learner-data combinations that should be the foci of future efforts (e.g., tree-based microbial models for pathogenic E. coli). © Copyright © 2020 Weller, Love, Belias and Wiedmann.","agricultural water; E. coli; eaeA; machine learning; predictive model; Salmonella; stx",
"Wilkinson G.G., Kanellopoulos I., Kontoes C., Mégier J.","A comparison of neural network and expert system methods for analysis of remotely-sensed imagery","10.1109/IGARSS.1992.576627","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969601828&doi=10.1109%2fIGARSS.1992.576627&partnerID=40&md5=28461c31da7b4975925e9d8b3ee77be5","This paper describes an experimental comparison which has been made between two alternative methods of image classification: one based on a neural network and the other on a rule-based expert system. Both methods were applied to the same image data. The results show that both methods give useful performance improvements in comparison with more traditional parametric classifiers. It was also found that the performance level attained by the two approaches was approximately the same. The neural network was, however, faster to develop although the expert system was much more transparent and easier for a user to understand.","Crops; Expert systems; Image analysis; Image classification; Lakes; Multi-layer neural network; Neural networks; Open area test sites; Production systems; Remote sensing","Crops; Expert systems; Geology; Image analysis; Lakes; Network layers; Neural networks; Remote sensing; Space optics; Experimental comparison; Open area test sites; Parametric classifier; Performance level; Production system; Remotely sensed imagery; Rule based expert systems; System methods; Image classification"
"Xie W., Kimura M., Takaki K., Asada Y., Iida T., Jia X.","Interpretable Framework of Physics-Guided Neural Network With Attention Mechanism: Simulating Paddy Field Water Temperature Variations","10.1029/2021WR030493","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130605509&doi=10.1029%2f2021WR030493&partnerID=40&md5=15585a16eb565a8faf6d9e95543954f6","With the development of large-scale rice cultivation management initiatives in East Asia, there is concern that a reduction in the number of human cultivators per unit area may lead to poor water management, which could result in decreased land productivity, owing to abnormally high- and low-temperature damage to crops. Accurate simulation of paddy field water temperature is important for studying its impact on crops and providing timely information to aid in decision-making for more efficient management under limited resources. We propose a neural-network framework that considers the heat transfer by the vegetation canopy and applies physical-theory constraints in its training. A novel tuning method is proposed to cope with the trade-off between water temperature accuracy and physical consistency during training to ensure that the calculated water temperature variations in a paddy field enjoy high accuracy and physical consistency. In the experiments, the proposed framework outperforms physical process models and pure neural network models while maintaining high accuracy in the case of sparse data sets. Furthermore, an attention-mechanism input layer is integrated into the model to rank feature importance, providing global interpretation to the proposed framework. We also perform sensitivity analysis on the physical process and propose models to compare their different strategies of feature ranking. The results show that the two methods have different sensitivities to different feature patterns, but they complement each other. In summary, the proposed model is credible and stable for practical applications and has the potential to guide more efficient paddy management. © 2022. American Geophysical Union. All Rights Reserved.","deep learning; global interpretation; PGNN","Cultivation; Decision making; Deep learning; Economic and social effects; Heat transfer; Information management; Sensitivity analysis; Temperature control; Temperature distribution; Water management; Attention mechanisms; Deep learning; Global interpretation; High-accuracy; Neural-networks; Paddy field waters; PGNN; Physical process; Temperature variation; Water temperatures; Crops; artificial neural network; cultivation; heat transfer; temperature gradient; trade-off; water temperature; Far East"
"Zegarra E., MacHicao J.C.","Structural analysis of potato market behavior using neural network modelling in Peru","10.1109/IHTC53077.2021.9698916","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127298259&doi=10.1109%2fIHTC53077.2021.9698916&partnerID=40&md5=91f7f1ffdcc7df169a0836a0a30920b3","The complex behavior of crop markets is always difficult to characterize, especially under structural market failures that cause increasingly unstable and unprofitable prices. In this paper we propose an innovative analytical tool to identify potential potato market failures related to uncoordinated decisions in production which in time causes negative effects on farmers' wellbeing and persistently high rates of poverty in potato production areas. Based on a database including geographical origin, volume and price for potato production during the period 1997-2021, this work generates a market price prediction neural network model, using it to identify coordination problems in the functioning of the market and to test an alternative micro-scenario for a critical period of high volatility and price crisis. Using AI modelling and expert knowledge allows a better understanding of market coordination problems, to design more effective strategies and policy interventions towards reduction of poverty in potato producing rural areas in Peru. © 2021 IEEE.","agriculture; explainable artificial intelligence; modelling; potato price; rural poverty; sustainability","Agriculture; Artificial intelligence; Rural areas; Sustainable development; Analytical tool; Coordination problems; Explainable artificial intelligence; Market behaviours; Market failures; Modeling; Neural network model; Potato price; Rural poverty; Structural market; Commerce"
[No author name available],"Proceedings - 2022 9th International Conference on Digital Home, ICDH 2022",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146333259&partnerID=40&md5=c4f5e0be7f8917239d679a1d9320d087","The proceedings contain 47 papers. The topics discussed include: on-device high accuracy plant classifier; an explainable adversarial attacks on privacy-preserving image classification; remote sensing image classification of sugarcane harvest based on TensorFlow; automatic target-scoring model based on image processing; ultrasound image segmentation algorithm of ocular muscle of breeding pig based on continuous minimum cut; multilevel domain adaptive detection method for haze scenes; crop disease recognition based on deep learning; personalized outfit compatibility prediction based on regional attention; graph transformer for human parsing; and session-based recommendation via memory network and dwell-time attention.",,
[No author name available],"42nd SGAI International Conference on Innovative Techniques and Applications of Artificial Intelligence, AI 2022",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144960095&partnerID=40&md5=99a9788b74e59f7562d1a9e06137dc49","The proceedings contain 31 papers. The special focus in this conference is on Innovative Techniques and Applications of Artificial Intelligence. The topics include: Competitive Learning with Spiking Nets and Spike Timing Dependent Plasticity; an Evolutionary Game Theory Model of the Decision to Confront; hidden Markov Models for Surprising Pattern Detection in Discrete Symbol Sequence Data; The ODeLIndA Dataset for Field-of-View Obstruction Detection Using Transfer Learning for Real-Time Industrial Applications; automated Quality Inspection of High Voltage Equipment Supported by Machine Learning and Computer Vision; on Predicting the Work Load for Service Contractors; OAK4XAI: Model Towards Out-of-Box eXplainable Artificial Intelligence for Digital Agriculture; deep Learning for Detecting Tilt Angle and Orientation of Photovoltaic Panels on Satellite Imagery; recurrent Neural Networks for Music Genre Classification; job Assignment Problem and Traveling Salesman Problem: A Linked Optimisation Problem; explainable Boosting Machines for Network Intrusion Detection with Features Reduction; accelerating Cyber-Breach Investigations Through Novel Use of Artificial Immune System Algorithms; Comparing ML Models for Food Production Forecasting; comparing Peircean Algorithm with Various Bio-inspired Techniques for Multi-dimensional Function Optimization; Medical Recommendation System Based on Daily Clinical Reports: A Proposed NLP Approach for Emergency Departments; mentaLex: A Mental Processes Lexicon Based on the Essay Dataset; credit Card Fraud Using Adversarial Attacks; anomaly Detection and Root Cause Analysis on Log Data; Developing Testing Frameworks for AI Cameras; time is Budget: A Heuristic for Reducing the Risk of Ruin in Multi-armed Gambler Bandits; twitter Flu Trend: A Hybrid Deep Neural Network for Tweet Analysis; two-Phase Open-Domain Question Answering System; Have a Break from Making Decisions, Have a MARS: The Multi-valued Action Reasoning System; Data Augmentation for Pathology Prioritisation: An Improved LSTM-Based Approach.",,
[No author name available],"9th Workshop on Engineering Applications on Applied Computer Sciences in Engineering, WEA 2022",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144199050&partnerID=40&md5=524b2f7898b9f2a73ec9925f4a101324","The proceedings contain 39 papers. The special focus in this conference is on Engineering Applications on Applied Computer Sciences in Engineering. The topics include: Artificial Intelligence Methods to Solve Energy Transmission Problems Through Data Analysis from Different Data Sources; a Knowledge-Based Expert System for Risk Management in Health Audit Projects; Effect of Speckle Filtering in the Performance of Segmentation of Ultrasound Images Using CNNs; multivariate Financial Time Series Forecasting with Deep Learning; the Notion of the Quasicentral Path in Linear Programming; p-Median Equivalence and Partitioning in Logistics Problems; a Hybrid Algorithm Based on Ant Colony System for Flexible Job Shop; cost Optimization of an Assembly Sequence of an Electric Propulsion Module of an Electro-Solar Boat; Hybrid ILS-VND Algorithm for the Vehicle Routing Problem with Release Times; Globally Explainable AutoML Evolved Models of Corporate Credit Risk; The Organization of Fruit Collection Transport in Conditions of Extreme Rurality: A Rural CVRP Case; design of Electric Vessels Test Routes Using Image Processing and Optimization Techniques; optimization of Routes for Covered Walkways at University Campus by Kruskal Algorithm; stating on the Use of Operations Research for Historical Analysis: A Hierarchic-Transport Model Clio-Combinatorics Approach and Its Applications in Current Problem Solving; methodology for Selecting Scenarios in Improvement Process with Multiple Performance Measures; agent-Based Simulation Model for the Validation of an Organizational Structure Aiming at Self-organization and Increasing Agility; replicator Dynamics of the Hawk-Dove Game with Agent-based Simulation; food Availability Dynamic Model for Colombia; A Low-Cost 3D Mapping System for Indoor Scenes Based on a 2D LiDAR On-Board an UGV; power Simulation Process Through the Analysis of Geometry, Irradiance and Interconnection Impact in Photovoltaic Roof Tiles; bioactivity Predictors for the Inhibition of Staphylococcus Aureus Quinolone Resistance Protein.",,
[No author name available],"3rd International Congress on Blockchain and Applications, BLOCKCHAIN 2021",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115275849&partnerID=40&md5=58eae513af0c66d41e89eb50b4f7dff0","The proceedings contain 38 papers. The special focus in this conference is on Blockchain and Applications. The topics include: Towards Informational Self-determination: Data Portability Requests Based on GDPR by Providing Public Platforms for Authorised Minimal Invasive Privacy Protection; blockchain and the Riemann Zeta Function; Case Study: The Automation of an over the Counter Financial Derivatives Transaction Using the CORDA Blockchain; application of Blockchain to Peer to Peer Energy Trading in Microgrids; the Value and Applications of Blockchain Technology in Business: A Systematic Review of Real Use Cases; a Preliminary Review on Complementary Applications of Databases and Blockchain Technology; Blockchain Platform Selection for Security Token Offering (STO) Using Multi-criteria Decision Model; Towards a Holistic DLT Architecture for IIoT: Improved DAG for Production Lines; a Secure Blockchain-Based Solution for Management of Pandemic Data in Healthcare Systems; a Blockchain-Enabled Fog Computing Model for Peer-To-Peer Energy Trading in Smart Grid; investigation on Vulnerabilities Location in Solidity Smart Contracts; benchmarking Constrained IoT Devices in Blockchain-Based Agri-Food Traceability Applications; towards Micropayment for Intermediary Based Trading; BlockFLow: Decentralized, Privacy-Preserving, and Accountable Federated Machine Learning; COVID-19 Early Symptom Prediction Using Blockchain and Machine Learning; a Smart Contract Architecture to Enhance the Industrial Symbiosis Process Between the Pulp and Paper Companies - A Case Study; establish Trust for Sharing Data for Smart Territories Thanks to Consents Notarized by Blockchain; Blockchain and AI in Art: A Quick Look into Contemporary Art Industries; machine Learning Powered Autoscaling for Blockchain-Based Fog Environments; energy Trading Between Prosumers Based on Blockchain Technology.",,
[No author name available],"Erratum regarding missing Declaration of Competing Interest statements in previously published articles (International Journal of Forecasting (2019) 35(1) (170–180), (S0169207018301523), (10.1016/j.ijforecast.2018.09.003))","10.1016/j.ijforecast.2021.01.014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106595984&doi=10.1016%2fj.ijforecast.2021.01.014&partnerID=40&md5=5b598729d7725a833ed08ac77f318748","Declaration of Competing Interest statements were not included in published version of the following articles that appeared in previous issues of International Journal of Forecasting. Hence, the authors of the below articles were contacted after publication to request a Declaration of Interest statement: “Trading and non-trading period realized market volatility: Does it matter for forecasting the volatility of US stocks?” INTFOR (International Journal of Forecasting, 36/2: 628–645) 10.1016/j.ijforecast.2019.08.002 Declaration of Competing Interest: The authors were contacted after publication to request a Declaration of Interest statement. “What do professional forecasters actually predict?” INTFOR (International Journal of Forecasting, 34/2: 288–311) 10.1016/j.ijforecast.2017.12.004 Declaration of Competing Interest: The authors were contacted after publication to request a Declaration of Interest statement. “Predicting bank insolvencies using machine learning techniques” INTFOR (International Journal of Forecasting, 36/3: 1092–1113) 10.1016/j.ijforecast.2019.11.005 Declaration of Competing Interest: The authors were contacted after publication to request a Declaration of Interest statement. “Inversion copulas from nonlinear state space models with an application to inflation forecasting” INTFOR (International Journal of Forecasting, 34/3: 389–407) 10.1016/j.ijforecast.2018.01.002 Declaration of Competing Interest: The authors were contacted after publication to request a Declaration of Interest statement. “Demand forecasting with user-generated online information” INTFOR (International Journal of Forecasting, 35/1: 197–212) 10.1016/j.ijforecast.2018.03.005 Declaration of Competing Interest: The authors were contacted after publication to request a Declaration of Interest statement. “Automatic Interpretable Retail forecasting with promotional scenarios” INTFOR (International Journal of Forecasting, 36/4: 1389–1406) 10.1016/j.ijforecast.2020.02.003 Declaration of Competing Interest: The authors were contacted after publication to request a Declaration of Interest statement. “Can Google search data help predict macroeconomic series?” INTFOR (International Journal of Forecasting, 36/3: 1163–1172) 10.1016/j.ijforecast.2018.12.006 Declaration of Competing Interest: The authors were contacted after publication to request a Declaration of Interest statement. “FFORMA: Feature-based forecast model averaging” INTFOR (International Journal of Forecasting, 36/1: 86–92) 10.1016/j.ijforecast.2019.02.011 Declaration of Competing Interest: The authors were contacted after publication to request a Declaration of Interest statement. “Probabilistic forecasting in day-ahead electricity markets: Simulating peak and off-peak prices” INTFOR (International Journal of Forecasting, 36/4: 1193–1210) 10.1016/j.ijforecast.2019.11.006 Declaration of Competing Interest: The authors were contacted after publication to request a Declaration of Interest statement. “Forecasting of density functions with an application to cross-sectional and intraday returns” INTFOR (International Journal of Forecasting, 35/4: 1304–1317) 10.1016/j.ijforecast.2019.05.007 Declaration of Competing Interest: The authors were contacted after publication to request a Declaration of Interest statement. “Do IMF forecasts respect Okun's law? Evidence for advanced and developing economies” INTFOR (International Journal of Forecasting, 35/3: 1131–1142) 10.1016/j.ijforecast.2019.03.001 Declaration of Competing Interest: The authors were contacted after publication to request a Declaration of Interest statement. “Probabilistic electricity price forecasting with NARX networks: Combine point or probabilistic forecasts?” INTFOR (International Journal of Forecasting, 36/2: 466–479) 10.1016/j.ijforecast.2019.07.002 Declaration of Competing Interest: The authors were contacted after publication to request a Declaration of Interest statement. “Understanding intraday electricity markets: Variable selection and very short-term price forecasting using LASSO” INTFOR (International Journal of Forecasting, 35/4: 1533–1547) 10.1016/j.ijforecast.2019.02.001 Declaration of Competing Interest: The authors were contacted after publication to request a Declaration of Interest statement. “Forecasting sales in the supply chain: Consumer analytics in the big data era” INTFOR (International Journal of Forecasting, 35/1: 170–180) 10.1016/j.ijforecast.2018.09.003 Declaration of Competing Interest: The authors were contacted after publication to request a Declaration of Interest statement. “Predicting LGD distributions with mixed continuous and discrete ordinal outcomes” INTFOR (International Journal of Forecasting, 36/3: 1003–1022) 10.1016/j.ijforecast.2019.10.005 Declaration of Competing Interest: The authors were contacted after publication to request a Declaration of Interest statement. © 2021",,
[No author name available],"ACI 2022 - Proceedings of the Workshop on Advances in Computational Intelligence, its Concepts and Applications, co-located with International Semantic Intelligence Conference, ISIC 2022",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143223775&partnerID=40&md5=d85445207b0d4ca7e25b2e6843c17772","The proceedings contain 38 papers. The topics discussed include: web benefit utilizations with K-means clustering approach for efficient clustering; explainable AI framework for multi-label classification using supervised machine learning models; measuring of similarity between pair of words using word net; microcontroller based electronic queue control system; intelligent recognition of characters from ancient manuscripts-a review; corn leaf disease identification with improved accuracy; a survey on soybean seed varieties and defects identification using neural network; student attendance system based on face recognition and machine learning; forecasting of fruits stock life using CNN-based deep learning techniques: a comprehensive study; digital image processing application in agriculture (pest detection) – a review; evolution of smart home energy management system using Internet of things and machine learning algorithms; and stock market prediction using machine learning techniques.",,
[No author name available],"25th Iberoamerican Congress on Progress in Pattern Recognition, Image Analysis, Computer Vision, and Applications, CIARP 2021",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124256832&partnerID=40&md5=e857b2090b69dae430ee91ba1158a8ca","The proceedings contain 45 papers. The special focus in this conference is on Progress in Pattern Recognition, Image Analysis, Computer Vision, and Applications. The topics include: Enhancing Hyper-to-Real Space Projections Through Euclidean Norm Meta-heuristic Optimization; using Particle Swarm Optimization with Gradient Descent for Parameter Learning in Convolutional Neural Networks; object Delineation by Iterative Dynamic Trees; low-Cost Domain Adaptation for Crop and Weed Segmentation; MIGMA: The Facial Emotion Image Dataset for Human Expression Recognition; construction of Brazilian Regulatory Traffic Sign Recognition Dataset; japanese Kana and Brazilian Portuguese Manuscript Database; skelibras: A Large 2D Skeleton Dataset of Dynamic Brazilian Signs; cricket Scene Analysis Using the RetinaNet Architecture; a Coarse to Fine Corneal Ulcer Segmentation Approach Using U-net and DexiNed in Chain; texture-Based Image Transformations for Improved Deep Learning Classification; towards Precise Recognition of Pollen Bearing Bees by Convolutional Neural Networks; web Application Attacks Detection Using Deep Learning; Less Is More: Accelerating Faster Neural Networks Straight from JPEG; optimizing Person Re-Identification Using Generated Attention Masks; self-supervised Bernoulli Autoencoders for Semi-supervised Hashing; interpretable Concept Drift; interpreting a Conditional Generative Adversarial Network Model for Crime Prediction; interpreting Decision Patterns in Financial Applications; metal Artifact Reduction Based on Color Mapping and Inpainting Techniques; Replacing Data Augmentation with Rotation-Equivariant CNNs in Image-Based Classification of Oral Cancer; new Improvement in Obtaining Monogenic Phase Congruency; evaluating the Construction of Feature Descriptors in the Performance of the Image Data Stream Classification; clustering-Based Partitioning of Water Distribution Networks for Leak Zone Location; bias Quantification for Protected Features in Pattern Classification Problems; regional Commodities Price Volatility Assessment Using Self-driven Recurrent Networks; semi-supervised Deep Learning Based on Label Propagation in a 2D Embedded Space.",,
[No author name available],"1st International Conference on Smart and Sustainable Agriculture, SSA 2021",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119820741&partnerID=40&md5=8fb06d68c4a664002207b52d5472596a","The proceedings contain 12 papers. The special focus in this conference is on Smart and Sustainable Agriculture. The topics include: Development of Soil Nitrogen Estimation System in Oil Palm Land with Sentinel-1 Image Analysis Approach; new Monitoring Framework Intelligent Irrigation System; ensuring Smart Agriculture System Communication Confidentiality Using a New Network Steganography Method; deploying Deep Neural Networks on Edge Devices for Grape Segmentation; abnormal Behavior Detection in Farming Stream Data; eWeightSmart - A Smart Approach to Beef Production Management; Gaia-AgStream: An Explainable AI Platform for Mining Complex Data Streams in Agriculture; comparison of Machine Learning and Deep Learning Methods for Grape Cluster Segmentation; smart and Sustainable Agriculture: Machine Learning Behind This (R)evolution; a Methodology for Early Detection of Plant Diseases Using Real Time Object Detection Algorithm.",,
[No author name available],"IFIP WG 5.7 International Conference on Advances in Production Management Systems, APMS 2021",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115345037&partnerID=40&md5=cd9f5921cd62b251e13e51e5552206f9","The proceedings contain 377 papers. The special focus in this conference is on Advances in Production Management Systems. The topics include: Reflections from a Hybrid Approach Used to Develop a Specification of a Shopfloor Platform for Smart Manufacturing in an Engineered-to-Order SME; industry 4.0: Expectations, Impediments and Facilitators; study of the Predictive Mechanism with Big Data-Driven Lean Manufacturing and Six Sigma Methodology; blockchain for Product Authenticity in the Cannabis Supply Chain; the Automation of Lean Practices: Digitalized or Digitally Wasted?; development of an Eco-efficiency Distribution Model: A Case Study of a Danish Wholesaler; suppliers Selection Ontology for Viable Digital Supply Chain Performance; evaluating the Deployment of Collaborative Logistics Models for Local Delivery Services; Minimising Total Costs of a Two-Echelon Multi-Depot Capacitated Vehicle Routing Problem (2E-MD-CVRP) that Describes the Utilisation of the Amsterdam City Canal Network for Last Mile Parcel Delivery; a Review of Explainable Artificial Intelligence; blockchain-Based Master Data Management in Supply Chains: A Design Science Study; a Literature Review on Smart Technologies and Logistics; sustainable and Resilience Improvement Through the Design for Circular Digital Supply Chain; accessibility Considerations in the Design of Serious Games for Production and Logistics; experiencing the Role of Cooperation and Competition in Operations and Supply Chain Management with a Multiplayer Serious Game; towards a Serious Game on Data Sharing in Business Ecosystems; seed-and-Prune Approach for Rapid Discovery of Tensegrity-Like Structures of the Desired Shape; tensegrity Morphing: Machine Learning-Based Tensegrity Deformation Predictor for Traversing Cluttered Environments; distribution of Vaccines During a Pandemic (Covid-19); preface.",,
[No author name available],"IFIP WG 5.7 International Conference on Advances in Production Management Systems, APMS 2021",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115294698&partnerID=40&md5=f7b42b85adb98c318d3808ae2e8e1484","The proceedings contain 377 papers. The special focus in this conference is on Advances in Production Management Systems. The topics include: Reflections from a Hybrid Approach Used to Develop a Specification of a Shopfloor Platform for Smart Manufacturing in an Engineered-to-Order SME; industry 4.0: Expectations, Impediments and Facilitators; study of the Predictive Mechanism with Big Data-Driven Lean Manufacturing and Six Sigma Methodology; blockchain for Product Authenticity in the Cannabis Supply Chain; the Automation of Lean Practices: Digitalized or Digitally Wasted?; development of an Eco-efficiency Distribution Model: A Case Study of a Danish Wholesaler; suppliers Selection Ontology for Viable Digital Supply Chain Performance; evaluating the Deployment of Collaborative Logistics Models for Local Delivery Services; Minimising Total Costs of a Two-Echelon Multi-Depot Capacitated Vehicle Routing Problem (2E-MD-CVRP) that Describes the Utilisation of the Amsterdam City Canal Network for Last Mile Parcel Delivery; a Review of Explainable Artificial Intelligence; blockchain-Based Master Data Management in Supply Chains: A Design Science Study; a Literature Review on Smart Technologies and Logistics; sustainable and Resilience Improvement Through the Design for Circular Digital Supply Chain; accessibility Considerations in the Design of Serious Games for Production and Logistics; experiencing the Role of Cooperation and Competition in Operations and Supply Chain Management with a Multiplayer Serious Game; towards a Serious Game on Data Sharing in Business Ecosystems; seed-and-Prune Approach for Rapid Discovery of Tensegrity-Like Structures of the Desired Shape; tensegrity Morphing: Machine Learning-Based Tensegrity Deformation Predictor for Traversing Cluttered Environments; distribution of Vaccines During a Pandemic (Covid-19); preface.",,
[No author name available],"IFIP WG 5.7 International Conference on Advances in Production Management Systems, APMS 2021",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115262905&partnerID=40&md5=51a0969fe0c34791f1dde84660fb2852","The proceedings contain 377 papers. The special focus in this conference is on Advances in Production Management Systems. The topics include: Reflections from a Hybrid Approach Used to Develop a Specification of a Shopfloor Platform for Smart Manufacturing in an Engineered-to-Order SME; industry 4.0: Expectations, Impediments and Facilitators; study of the Predictive Mechanism with Big Data-Driven Lean Manufacturing and Six Sigma Methodology; blockchain for Product Authenticity in the Cannabis Supply Chain; the Automation of Lean Practices: Digitalized or Digitally Wasted?; development of an Eco-efficiency Distribution Model: A Case Study of a Danish Wholesaler; suppliers Selection Ontology for Viable Digital Supply Chain Performance; evaluating the Deployment of Collaborative Logistics Models for Local Delivery Services; Minimising Total Costs of a Two-Echelon Multi-Depot Capacitated Vehicle Routing Problem (2E-MD-CVRP) that Describes the Utilisation of the Amsterdam City Canal Network for Last Mile Parcel Delivery; a Review of Explainable Artificial Intelligence; blockchain-Based Master Data Management in Supply Chains: A Design Science Study; a Literature Review on Smart Technologies and Logistics; sustainable and Resilience Improvement Through the Design for Circular Digital Supply Chain; accessibility Considerations in the Design of Serious Games for Production and Logistics; experiencing the Role of Cooperation and Competition in Operations and Supply Chain Management with a Multiplayer Serious Game; towards a Serious Game on Data Sharing in Business Ecosystems; seed-and-Prune Approach for Rapid Discovery of Tensegrity-Like Structures of the Desired Shape; tensegrity Morphing: Machine Learning-Based Tensegrity Deformation Predictor for Traversing Cluttered Environments; distribution of Vaccines During a Pandemic (Covid-19); preface.",,
[No author name available],"IFIP WG 5.7 International Conference on Advances in Production Management Systems, APMS 2021",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115243953&partnerID=40&md5=406977e3ece29f6a6cd7a6cd6aa3816a","The proceedings contain 377 papers. The special focus in this conference is on Advances in Production Management Systems. The topics include: Reflections from a Hybrid Approach Used to Develop a Specification of a Shopfloor Platform for Smart Manufacturing in an Engineered-to-Order SME; industry 4.0: Expectations, Impediments and Facilitators; study of the Predictive Mechanism with Big Data-Driven Lean Manufacturing and Six Sigma Methodology; blockchain for Product Authenticity in the Cannabis Supply Chain; the Automation of Lean Practices: Digitalized or Digitally Wasted?; development of an Eco-efficiency Distribution Model: A Case Study of a Danish Wholesaler; suppliers Selection Ontology for Viable Digital Supply Chain Performance; evaluating the Deployment of Collaborative Logistics Models for Local Delivery Services; Minimising Total Costs of a Two-Echelon Multi-Depot Capacitated Vehicle Routing Problem (2E-MD-CVRP) that Describes the Utilisation of the Amsterdam City Canal Network for Last Mile Parcel Delivery; a Review of Explainable Artificial Intelligence; blockchain-Based Master Data Management in Supply Chains: A Design Science Study; a Literature Review on Smart Technologies and Logistics; sustainable and Resilience Improvement Through the Design for Circular Digital Supply Chain; accessibility Considerations in the Design of Serious Games for Production and Logistics; experiencing the Role of Cooperation and Competition in Operations and Supply Chain Management with a Multiplayer Serious Game; towards a Serious Game on Data Sharing in Business Ecosystems; seed-and-Prune Approach for Rapid Discovery of Tensegrity-Like Structures of the Desired Shape; tensegrity Morphing: Machine Learning-Based Tensegrity Deformation Predictor for Traversing Cluttered Environments; distribution of Vaccines During a Pandemic (Covid-19); preface.",,
[No author name available],"IFIP WG 5.7 International Conference on Advances in Production Management Systems, APMS 2021",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115238865&partnerID=40&md5=72391323446d6e4796d55d84c8cabc0e","The proceedings contain 377 papers. The special focus in this conference is on Advances in Production Management Systems. The topics include: Reflections from a Hybrid Approach Used to Develop a Specification of a Shopfloor Platform for Smart Manufacturing in an Engineered-to-Order SME; industry 4.0: Expectations, Impediments and Facilitators; study of the Predictive Mechanism with Big Data-Driven Lean Manufacturing and Six Sigma Methodology; blockchain for Product Authenticity in the Cannabis Supply Chain; the Automation of Lean Practices: Digitalized or Digitally Wasted?; development of an Eco-efficiency Distribution Model: A Case Study of a Danish Wholesaler; suppliers Selection Ontology for Viable Digital Supply Chain Performance; evaluating the Deployment of Collaborative Logistics Models for Local Delivery Services; Minimising Total Costs of a Two-Echelon Multi-Depot Capacitated Vehicle Routing Problem (2E-MD-CVRP) that Describes the Utilisation of the Amsterdam City Canal Network for Last Mile Parcel Delivery; a Review of Explainable Artificial Intelligence; blockchain-Based Master Data Management in Supply Chains: A Design Science Study; a Literature Review on Smart Technologies and Logistics; sustainable and Resilience Improvement Through the Design for Circular Digital Supply Chain; accessibility Considerations in the Design of Serious Games for Production and Logistics; experiencing the Role of Cooperation and Competition in Operations and Supply Chain Management with a Multiplayer Serious Game; towards a Serious Game on Data Sharing in Business Ecosystems; seed-and-Prune Approach for Rapid Discovery of Tensegrity-Like Structures of the Desired Shape; tensegrity Morphing: Machine Learning-Based Tensegrity Deformation Predictor for Traversing Cluttered Environments; distribution of Vaccines During a Pandemic (Covid-19); preface.",,
[No author name available],"19th International Conference on Artificial Intelligence in Medicine, AIME 2021",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111365519&partnerID=40&md5=db4a7e7c84974663e2afed7dc1d7015b","The proceedings contain 59 papers. The special focus in this conference is on Artificial Intelligence in Medicine. The topics include: ICU Days-to-Discharge Analysis with Machine Learning Technology; transformers for Multi-label Classification of Medical Text: An Empirical Comparison; semantic Web Framework to Computerize Staged Reflex Testing Protocols to Mitigate Underutilization of Pathology Tests for Diagnosing Pituitary Disorders; using Distribution Divergence to Predict Changes in the Performance of Clinical Predictive Models; analysis of Health Screening Records Using Interpretations of Predictive Models; seasonality in Infection Predictions Using Interpretable Models for High Dimensional Imbalanced Datasets; monitoring Quality of Life Indicators at Home from Sparse, and Low-Cost Sensor Data; detection of Parkinson's Disease Early Progressors Using Routine Clinical Predictors; detecting Mild Cognitive Impairment Using Smooth Pursuit and a Modified Corsi Task; a Petri Dish for Histopathology Image Analysis; neural Clinical Event Sequence Prediction Through Personalized Online Adaptive Learning; Using Event-Based Web-Scraping Methods and Bidirectional Transformers to Characterize COVID-19 Outbreaks in Food Production and Retail Settings; deep Kernel Learning for Mortality Prediction in the Face of Temporal Shift; model Evaluation Approaches for Human Activity Recognition from Time-Series Data; unsupervised Learning to Subphenotype Heart Failure Patients from Electronic Health Records; stratification of Parkinson’s Disease Patients via Multi-view Clustering; disentangled Hyperspherical Clustering for Sepsis Phenotyping; phenotypes for Resistant Bacteria Infections Using an Efficient Subgroup Discovery Algorithm; predicting Drug-Drug Interactions from Heterogeneous Data: An Embedding Approach; detection of Junctional Ectopic Tachycardia by Central Venous Pressure; fMRI Multiple Missing Values Imputation Regularized by a Recurrent Denoiser.",,
[No author name available],"15th International Conference on Soft Computing Models in Industrial and Environmental Applications, SOCO 2020",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091292024&partnerID=40&md5=e193967517c86d3009366e110bb9b47b","The proceedings contain 83 papers. The special focus in this conference is on Soft Computing Models in Industrial and Environmental Applications. The topics include: A Smart Crutch Tip for Monitoring the Activities of Daily Living Based on a Novel Neural-Network Intelligent Classifier; Hourly Air Quality Index (AQI) Forecasting Using Machine Learning Methods; interpretable Deep Learning with Hybrid Autoencoders to Predict Electric Energy Consumption; on the Performance of Deep Learning Models for Time Series Classification in Streaming; An Approach to Forecasting and Filtering Noise in Dynamic Systems Using LSTM Architectures; novel Approach for Person Detection Based on Image Segmentation Neural Network; an Adaptive Cognitive Model to Integrate Machine Learning and Visual Streaming Data; smart Song Equalization Based on the Classification of Musical Genres; machine Learning in Classification of the Wax Structure of Breathing Openings on Leaves Affected by Air Pollution; A Preliminary Study for Automatic Activity Labelling on an Elder People ADL Dataset; software Sensors for the Monitoring of Bioprocesses; RGB Images Driven Recognition of Grapevine Varieties; discovering Spatio-Temporal Patterns in Precision Agriculture Based on Triclustering; counting Livestock with Image Segmentation Neural Network; smart, Precision or Digital Agriculture and Farming - Current State of Technology; an Automated Platform for Microrobot Manipulation; growth Models of Female Dairy Cattle; a Preliminary Study on Crop Classification with Unsupervised Algorithms for Time Series on Images with Olive Trees and Cereal Crops; blocks of Jobs for Solving Two-Machine Flow Shop Problem with Normal Distributed Processing Times; soft Computing Analysis of Pressure Decay Leak Test Detection.",,
[No author name available],"7th Workshop on Engineering Applications, WEA 2020",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094136203&partnerID=40&md5=2db74fe8af9af883e02677030db2c192","The proceedings contain 44 papers. The special focus in this conference is on Engineering Applications. The topics include: Design and Structural Analysis of a Machine for Characterizing Strain Gauge on Paper Substrate; computational Analysis of an Electrodynamic Speaker and Implementation in 3D Printing; computational Analysis to Design Loudspeakers with Nonconventional Forms; Solving an Urban Goods Distribution Problem as the 2E-CVRP Model Using a MILP-based Decomposition Approach; an Efficient Algorithm for Minimizing Regular Criteria in the Job-Shop Scheduling Multi-resource Resource Flexibility with Linear Routes; a Fast Pareto Approach to Minimize Regular Criteria in the Job-shop Scheduling Problem with Maintenance Activities, Sequence Dependent and Set-up Times; a Mathematical Model for the Optimization of the Non-metallic Mining Supply Chain in the Mining District of Calamarí-Sucre (Colombia); a Hybrid Algorithm to Minimize Regular Criteria in the Job-shop Scheduling Problem with Maintenance Activities, Sequence Dependent and Set-up Times; a Simple Yet Effective Algorithm to Compute Incremental All-Pairs Shortest Distances; an Interpretable Automated Machine Learning Credit Risk Model; Integration of Machine Learning Models in PACS Systems to Support Diagnostic in Radiology Services; quantifying Irregular Morphology Electrograms in Atrial Fibrillation Using Fractional Fourier Domains; Towards a Conceptual Framework for the Development of Artificial Muscles Using SMA; exploring the Facial and Neurological Activation Due to Predetermined Visual Stimulus Using Kinect and Emotiv Sensors; electrophysiological and Mechanical Approaches to the Swallowing Analysis; genesis of Atrial Fibrillation Under Different Diffuse Fibrosis Density Related with Atmospheric Pollution. In-Silico Study; IRBASIR-B: Rule Induction from Similarity Relations, a Bayesian Approach.",,
[No author name available],"2nd International Conference on Computing, Communications and Data Engineering, CCODE 2019",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079608947&partnerID=40&md5=0ad37bea3c313b41e707f8f4f1f23f2d","The proceedings contain 61 papers. The special focus in this conference is on Computing, Communications and Data Engineering. The topics include: Improving the accuracy of prediction of plant diseases using dimensionality reduction-based ensemble models; generic architecture for ubiquitous IoT applications; Performance evaluation of spark SQL for batch processing; ioT-based traffic management; detection of autism spectrum disorder effectively using modified regression algorithm; gene sequence analysis of breast cancer using genetic algorithm; impact of single server queue having machine repair with catastrophes using probability generating function method; utilization of blockchain technology to overthrow the challenges in healthcare industry; monitor and abolish the wildfire using internet of things and cloud computing; an efficient image retrieval system for remote sensing images using deep hashing network; critical review on privacy and security issues in data mining; a review of semantic annotation models for analysis of healthcare data based on data mining techniques; review of optimization-based feature selection algorithms on healthcare dataset; survey: A comparative study of different security issues in big data; mineral identification using unsupervised classification from hyperspectral data; accountable communication in ubiquitous computing; prediction of real estate price using clustering techniques; Study and analysis of matrix operations in RLNC using various computing; comprehensive survey of IoT communication technologies; tea leaf disease prediction using texture-based image processing; cost effective model for using different cloud services; sentiment analysis on movie reviews; privacy-preserving data mining in spatiotemporal databases based on mining negative association rules; spatial data-based prediction models for crop yield analysis: A systematic review.",,
[No author name available],"GECCO 2019 Companion - Proceedings of the 2019 Genetic and Evolutionary Computation Conference Companion",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070570488&partnerID=40&md5=25161d5f26a88b75797be56da83eb817","The proceedings contain 364 papers. The topics discussed include: combining artificial neural networks and evolution to solve multiobjective knapsack problems; understanding exploration and exploitation powers of meta-heuristic stochastic optimization algorithms through statistical analysis; generating interpretable reinforcement learning policies using genetic programming; low-dimensional Euclidean embedding for visualization of search spaces in combinatorial optimization; discovering test statistics using genetic programming; stochastic program synthesis via recursion schemes; hot off the press in expert systems on underwater robotic missions: success history applied to differential evolution for underwater glider path planning; a two-phase genetic algorithm for incorporating environmental considerations with production, inventory and routing decisions in supply chain networks; and hybrid estimation of distribution algorithm for solving a resource level allocation problem in a legal business.",,
[No author name available],"15th European Conference on Ambient Intelligence, AmI 2019",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076292210&partnerID=40&md5=46c40a0c5267be3c78a19664ebe72200","The proceedings contain 30 papers. The special focus in this conference is on Ambient Intelligence. The topics include: Enabling machine learning across heterogeneous sensor networks with graph autoencoders; development of an acoustically adaptive modular system for near real-time clarity-enhancement; Experiences from using lora and IEEE 802.15.4 for IoT-enabled classrooms; adaptive service selection for enabling the mobility of autonomous vehicles; discovering user location semantics using mobile notification handling behaviour; data-driven intrusion detection for ambient intelligence; spoken language identification using convNets; Indoor air quality and wellbeing - Enabling awareness and sensitivity with ambient IOT displays; ATHsENSe: An experiment in translating urban data to multisensory immersive artistic experiences in public space; power efficient clock synchronization in bluetooth-based mesh networks; characterization of individual mobility for non-routine scenarios from crowd sensing and clustered data; a flexible and scalable architecture for human-robot interaction; toward supporting food journaling using air quality data mining and a social robot; viewing experience of augmented reality objects as ambient media - A comparison of multimedia devices; ranking robot-assisted surgery skills using kinematic sensors; UAQE: Urban air quality evaluator; enhancing an eco-driving gamification platform through wearable and vehicle sensor data integration; a distributed multi-agent system (mas) application for continuous and integrated big data processing; human activities recognition using accelerometer and gyroscope; towards habit recognition in smart homes for people with dementia; classifying teachers’ self-reported productivity, stress and indoor environmental quality using environmental sensors; Ambient explanations: ambient intelligence and explainable AI; user requirements for the design of smart homes: dimensions and goals.",,
[No author name available],"20th IFIP Working Conference on Virtual Enterprises, PRO-VE 2019",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072978311&partnerID=40&md5=d1698c35f01feba3cdb515850be97755","The proceedings contain 56 papers. The special focus in this conference is on Virtual Enterprises. The topics include: Developing a Green Product-Based in an Open Innovation Environment. Case Study: Electrical Vehicle; commute Green! The Potential of Enterprise Social Networks for Ecological Mobility Concepts; development of a Methodology for the Analysis and Evaluation of Alternative Actions in Disruption Management in Production; actionable Collaborative Common Operational Picture in Crisis Situation: A Comprehensive Architecture Powered with Social Media Data; a Knowledge-Based System for Collecting and Integrating Production Information; interactive Machine Learning: Managing Information Richness in Highly Anonymized Conversation Data; methods of Data Mining for Quality Assurance in Glassworks; a Digital-Enabled Framework for Intelligent Collaboration in Small Teams; supporting Transparent Information/Knowledge Federation in Collaborative Administrative Environments; A Meta-Model of Cyber-Physical-Social System: The CPSS Paradigm to Support Human-Machine Collaboration in Industry 4.0; a Method of Ontology Evolution and Concept Evaluation Based on Knowledge Discovery in the Heavy Haul Railway Risk System; designing a Trusted Data Brokerage Framework in the Aviation Domain; a Model of Evolution of a Collaborative Business Ecosystem Influenced by Performance Indicators; verifying for Compliance to Data Constraints in Collaborative Business Processes; collaborative Networks Management from a Theory of Constraints Perspective; next Generation Government - Hyperconnected, Smart and Augmented; inter-governmental Collaborative Networks for Digital Government Innovation Transfer – Structure, Membership, Operations; Where Are Females in OSS Projects? Socio Technical Interactions; a Digital Platform Architecture to Support Multi-dimensional Surplus Capacity Sharing; investigating Supply Chains Models and Enabling Technologies Towards Collaborative Networks.",,
[No author name available],"Sustainability assessment by emergy approach: Gold mining extraction in Colombia",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062421010&partnerID=40&md5=cf4a5e3a8772e13e957ec822ed0f0cff","Due of its great climate diversity, Colombia has an abundance of natural resources and possesses a wide range of mining products, including coal, gold, platinum, nickel, emerald, limestone, among others that are extracted at a smaller scale. This extraction is carried out in two ways: a formal largescale extraction and other smallerscale, traditional and artisanal; the latter lacks adequate and defined technology, usually in some cases it is considered an illegal activity, making it unsafe, unprofitable, uncompetitive and environmentally unsustainable. In the last decade, there has been a significant increase in both the volume and value of production of primary goods, particularly in the mining and hydrocarbons sector, which has positively and significantly affected the country's gross domestic product (GDP) (FEDESARROLLO, 2012), currently being one of the most dynamic of the Colombian economy. The GDP from this sector has grown from 5.2 to 10.3 trillion pesos between 2000 and 2011 (Colombian Ombudsman, 2010), although in the last two years (2013 2014) this activity has gone into recess. Thus, according to the largescale mining sector (LSM), in 2011 mining represented 24.2% of exports; 2.4% of GDP; 20% of the total foreign direct investment; 650 billion pesos in construction of infrastructure; 2.6 trillion pesos in purchases from domestic suppliers, 65 billion pesos of investment in social responsibility and 178 billion pesos in environmental responsibility (LSM, 2012). This constitutes evidence for the mining sector in Colombia to be considered one of the main economic engines, since it does not only contribute with employment creation (there were 836000 in 2011, between direct and indirect jobs), but also with investments in infrastructure, public utilities, and social and environmental management (LSM, 2012). In royalties, the mining sector contribution to the country is 16.5%; 13% of it comes from coal companies (1.2 trillion pesos a year). This constitutes evidence for the mining sector in Colombia to be considered one of the main economic engines, since it does not only contribute with employment creation (there were 836000 in 2011, between direct and indirect jobs), but also with investments in infrastructure, public utilities, and social and environmental management (LSM, 2012). However, it is impossible to avoid discrepancies and political, economic, environmental and social polemics around this productive activity in the country, since mishandled mining practices lead to: social impacts, since many of these unformalized activities allow child labor, make use of intensive techniques in unskilled labor, generating poor quality jobs with low levels of industrial, social, and health security for miners, it is usually developed in remote and deprived areas; furthermore, it generates conflicts between large mining industries due to concession contracts awarding. Regarding political and economic impacts, a minimum working capital and scarce financial resources for investment are evidenced, and therefore an improper handling of inputs and royalties from this activity is presented. In a greater relevance, there are the irreversible environmental impacts such as destruction of ecosystems, damage to protected areas, air pollution, and pollution and impact on the availability of water resources. Globally, water demand is driven primarily by the population and economic growth, and it is anticipated that in the coming decades, it will increase considerably, while supplies will remain almost constant or decreasing by factors such as climate change, over pumping and pollution of aquifers (Drelich, 2012). It is not unknown that the primary input in gold extraction is water; the water that is used in this sector comes from a variety of sources, and sources and quality are the main areas of controversy and debate in this productive sector. The main problem of the mining industry is to generate confidence in the development of a responsible, sustainable and transparent strategy in the use of water (Drelich, 2012). Undoubtedly, the flow of resources from this activity is increasing and projections show that the growing trend will continue, since the international scene shows an important dynamism of the mining market. This situation could be exploited by Colombia, given its geographical location and its geological potential (FEDESARROLLO, 2012); it is estimated that US$250 billion will be invested in mining projects in Latin America between now and 2020. Thus, the mining sector gains importance among public policies, not only due to the high revenues generated by its operation, but also because of the social and environmental impact of the sector activity. Hence the importance of seeking for solutions, methodologies and sustainable alternatives to assimilate the challenge of turning the mineral wealth in an opportunity for development, and thus respond to future generations about how resources from nonrenewable assets were invested without affecting renewable resources. This highlights the fact that, despite the importance that the mining sector has taken, the debate about the true benefits and costs, or the environmental, economic, energy and social problems of the sector's activity has intensified. It is misleading to decide whether mining offers a significant potential or a threat to society without a methodological tool that allows predicting how sustainable is this productive activity, which represents a profitable business for many, which provides social and economic welfare (ultimate goal of the implementation of development projects of this magnitude), and for other sectors of the society symbolizes the opposite, considering as ineffective and undervalued all corrective and preventive measures that have been implemented by the government agencies or those regulatory entities that have some kind of control in the field of sustainable management of the processes of extraction and use of nonrenewable resources, including products that are generated in such activity, in response to the environmental awareness that has been growing in recent years. Based on the concept of sustainability as ""the compatibility between energy, economics (maximum performance) and environmental aspects"" (Redclif, 1987), all development projects especially those that threaten the environmental integrity such as the exploitation of natural resources and mining processes, should be focused on being an economic use alternative that provides an energy yield with acceptable environmental burden. That is, this highly demanding production activity in the country (including byproducts generated in it) should be given a particular management by means of methodological tools to harmonize the economic with the energy and environmental aspects; since these three factors cannot be assessed independently, but they must be analyzed together and in an interrelated way, in order to give management on a sustainable basis, which avoids the discrepancies noted above. In addition to these tools, it is possible to identify where the weaknesses lie, which apparently make this activity a threat to some sectors of the society. It is then necessary to establish, among the many valuation methodologies available, those that allow a sustainable assessment of the current management and mining process in Colombia in both artisanal and large-scale mining; likewise identify the gaps in it, whose purpose is to make mining a lever for development not only with good labor, industrial and environmental safety practices, but also going further in its commitment to the country and the city that hosts it. That is, for the management of mining resources, a valuation method should be used thereof, which is bearable and balanced from the economic, energy and environmental levels, as in the current regulations governing this sector a large imbalance is evident between these aspects. That is to say, in many situations mining is presented with a great economic benefit, but it entails irreversible environmental damage or major social problems that trigger collective chaos; or on the contrary, many mining licenses are denied impeding economic growth because of an environmental impact that may be acceptable, discrepancies caused by no uniformity of a regulatory framework for the mining sector and the lack of methodological tools to assess the sustainability of different productive sectors of society, which and/or balance economic, energy and environmental aspects. Globally, the possibility of quantifying the sustainability of different production sectors (agriculture, energy, legislative, sanitation) has been subject of study using the method of emergy which allow not only to quantify parameters, but also to analyze the implications and interrelationships of economic and environmental aspects of these long-term processes.Thus, this research aims to develop a methodological tool; emergy analysis to assess and compare the sustainability of the current small and large scale mining systems in Colombia, including byproducts generated in this process, emphasizing on the use of water resources, gaps in these systems which may not make them sustainable, and a uniform methodology that can be used as a road map to regulate that productive sector in a sustainable way, because without doubt, regulation constitutes the source of many of the limitations of the mining sector. Copyright © American Institute of Chemical Engineers. All rights reserved.",,"Accident prevention; Aquifers; Climate change; Coal deposits; Conservation; Data mining; Developing countries; Economic geology; Employment; Engines; Environmental management; Environmental protection; Environmental regulations; Extraction; Groundwater pollution; Hydrogeology; Investments; Laws and legislation; Lime; Mining; Population statistics; Public utilities; Resource valuation; Social aspects; Sustainable development; Water resources; Artisanal and large scale mining; Environmental responsibility; Foreign direct investments; Gross domestic products; Minimum working capitals; Social and environmental; Social and environmental impact; Sustainability assessment; Economic and social effects"
[No author name available],"3rd International Conference on Manufacture Engineering, Quality and Production System, ICMEQP 2014",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84902262199&partnerID=40&md5=20b39bba97acb6ba0ecb98724b860cc2","The proceedings contain 194 papers. The special focus in this conference is on Manufacture Engineering, Quality and Production System. The topics include: Synthesis of spherical La2Mo2O9 nanoparticles using sol-gel process; synthesis and catalytic activity of Fe-MCM-41 nanoparticles; photochromic inhibition of dyed veneer covered with modified transparent film; nonlinear TE-polarized surface Plasmons at the interface between graphene and metamaterials; modeling and simulation of reflection mode gallium nitride photocathode; application and development of resin capsules in Chinese coal mines; on detection technologies of pre-stressed duct grouting fullness; voltage phase difference detection for superconductor quench; the research on the hydrolysis and application of the starch from mung beans; real time non-destructive testing methods of welding; real-time weld process monitoring; study on heat aging properties of starch based aqueous polymer isocyanate adhesive for wood; use of glucose to improve the environmental aspects of chrome tanning process; research on machined surface morphology of hardened steels based on machining feature; effect of enzyme washing on the tensile property of denim fabric; comparison of microwave method with traditional method to extract tea polyphenols; finite element analysis of four fracture mechanism in the thermal barrier coating; effects of inhibit woody materials photochromic coated with water-based paints; leak-off coefficient analysis in stimulation treatment design; prediction model of silicon content in hot metal using optimized BP network; customizing procedure of finite element analysis for sheet metal forming; study on pharmaceutical wastewater pretreated by chemical coagulation method; design of PS identification algorithm in ground deformation monitoring; the mechanism movement design of caving tool in CBM; literature review of studies on self-centering bridge pier joint; equilibrium state of football players affected by disturbance; research on the process of liquid droplet impinging on the liquid film; influence of floor opening location on the dynamic characteristics of the building; the effect of the floor openings rate on the dynamic characteristics of the building; intelligent control strategy for complex industrial process with uncertainty; UAV formation control based on the improved APF; design of a playback control system for flight parameter recorder; study on smooth sliding mode control of parallel robot; error analysis of a manipulators; design of elevator controller based on FPGA; reliability study of aviation equipment; a novel unity-gain phase shifter for measuring power system quantities; implementation aware hardware Trojan trigger; research on single transistor open fault diagnosis of photovoltaic grid-connected inverter; computerized automatic generation method of categorized hub spectrum according to its form; data fusion algorithm research based on multi scout radar networking; single chip microcomputer cluster management; theoretical study of solar car based on finite element; optimization of plastic trunk lid molding parameters based on ANN; modular design of combined comfort furniture and Iranian dining table; modular design of combined comfort furniture and Iranian dining table; the design and implementation of spread spectrum communication system; the design of flash network courseware; a linearization regression method to determine life data distribution type; the application of fuzzy comprehensive evaluation method in mine; behavior mode of lead user's participation in NPD in mass customization; research on renewable resources industrial synergy policy system in China; partner selection of green supply chain based on corporate social responsibility; the study on network practice platform of higher college of engineering; an review of research on enterprise green procurement; enterprise inventory management and simulation; reliability evaluation of the crew organization of high-speed railway; the action network of clean development mechanism (CDM) in China; genetic neural network based financial distress prediction; contaminant lock life prediction of double flapper-nozzle servo valve; mould running system design to achieve the minimum waste; views about material application trends in product design; factor analysis on agricultural mechanization level in Changsha and environmental impacts of E-commerce logistics in China.",,
[No author name available],"2013 International Conference on Advanced Technologies and Solutions in Industry, ICATSI 2013",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84880362348&partnerID=40&md5=2a94894453f2d65a9f5cf6d5251c79ba","The proceedings contain 175 papers. The special focus in this conference is on Materials Science, Mechanical Engineering, Construction Technology, and Control. The topics include: microstructure of electromagnetically levitated Si droplets solidified on copper plate; tensile test of shape memory alloys and numerical simulation; effect of hot extrusion process on microstructure and properties of wide and hollow AZ31 magnesium alloy profiles; Ti2AlN prepared by self-propagating high-temperature combustion method using TiN as additive; corrosion inhibition of chloroacetic-acid modified imidazoline for Q235 steel in H2SO4 solution; characterization and preparation of polyamide 66/OV-POSS nanocomposite fibre; electronspun thermal responsive and photocatalytic Zn(NO3)2/PNIPAAm nanofibers; an assessment and utilization of thermodynamic parameters of Al-containing advanced high strength steels; study of physical properties of poly(vinyl alcohol) - collagen hydrogels using a response surface methodology; fluorescence enhancement of methyl orange by silver nanopartiles; flux cored wire material gas shielded arc welding thick steel plate welded crack analysis; crystallization behavior of poly(lactic acid) nucleated by a hydrazide compound; synthesis and gas sensing property of poly(m-aminophenol) the preparation of tri-cellulose acetate hybrid material containing rare earth europium (III) complex; study on mechanical properties of PP modified by nucleating agent under the low temperature; effect of Zn on microstructure and mechanical properties of Al-Zn-Mg-Cu-Zr alloy by powder metallurgy; effects of CaO additions on the structure and dielectric properties of aluminoborosilicate glasses; impact damage research of sandwich composite laminates; preparation, characteristics and bioactivity of gypenosides-loaded microcapsules; an easy way to synthesize YAG nanoparticles for transparent ceramics via allegro vacuum freeze drying; effect of laser peening on residual stress and micro-hardness of TC4 titanium alloy; research on new shapemeter of cold rolling thin strip; experiment and simulation study on parameter obtaining of hydraulic mount with air spring; structure and lightweight improvement of new type of mining bucket; performance evaluation of electric vehicle with 2-speed I-AMT; experimental study on emission characteristics of HCCI operation with N-Heptane; the research on degradation failure life and degradation data structure; the reliability evaluation method for success or failure product; cavitation erosion behavior in different throttling pipelines; decoherence of flux qubits under sub-ohmic bath; key problems on new underpass beneath the existing highway; compaction characteristic of lime modified expansive soil; advanced FEM analysis of steel pitched-roof portal frames with tapered members; study on corrosion resistant performance of sulfoaluminate cement; focused plenoptic camera and spatial resolution improving technology; focal length measurement of lens based on linear array CCD; influence of parameters of photonic crystal fiber Bragg grating on slow light delay; divergent light output of full-spectrum solar simulator integrator design; analysis on a novel concatenated code for optical transmission systems; research on PAPR reduction techniques for asymmetrically clipped optical OFDM communication system; improved PSO based feedback control algorithm in the application of PMD compensation system; the research on human simulating intelligent control of the inverted pendulum based on feedback linearization; the measure and control system design for temperature and humidity in general storeroom; detection of single-phase grounding fault line based on fuzzy set theory; boundary of crop detection using a laser scanner; automatic tracking tunnel cables using egomotion estimation; research on the optimal design of soccer robot based on the mechanical analysis; incremental tensor discriminant analysis for image detection; incremental tensor principal component analysis for image recognition; the ontology-based medical CT image semantic retrieval system; an adaptive regularized fast iterative shrinkage-thresholding algorithm for image reconstruction in compressed sensing; three-step iterative method for completely generalized set-valued strongly nonlinear quasi-variational inclusions; a new super-resolution reconstruction algorithm based on block sparse representation; an acoustic study on focus in Chinese: the variation of intensity; abnormal image monitoring for transmission line based on digital image processing; a rough-fuzzy RBF neural network based on PSO algorithm; the research of infrared image generation method based on the OGRE; the application of modified BP neural network method to the evaluation of the quality of teaching; building and clustering analysis of brain functional network in acupuncture; an improved SDIF radar pulse signal main sorting algorithm; research on algorithm of Boolean function isomorphism decision based on ROBDD; parameter optimization of street-Phelps model based on particle swarm optimization; multi-objective optimization of automobile powertrain based on genetic algorithm; palm vein recognition algorithm using curvelet and Wavelet; study on the architecture and key technology for internet of things; an improved method based on fast bilateral filter for high dynamic image rendering; a new AVS loop-filtering fast algorithm; AVS quick mode selection algorithm based on adaptive threshold; an evolutionary annealing approach to alloy tensile organization evolution; multi algorithm in CFD software and its application to numerical simulation of 2D regular wave; applying fuzzy set in elevator safety management evaluation method; 3D model optimization in virtual equipment operation simulation system; research on virtual reality based equipment operation training simulation with GL studio; research on general design of HLA based communication command equipment operation simulation system; filtering of digital hologram; research on the variety discrimination of apple using a hybrid possibilistic clustering; the research on two test methods of the normal distribution; on computer aided formation framework for composite material; exploring agent-based modeling for emergency logistics collaborative decision making; a discussion about value management in civil engineering; cost control of the civil engineering based on activity-based costing; research on the evaluation index of product design based on consumer, designer and manufacturer; the effects of advanced materials on aircraft production cost; the research status and the development trend of protection in DC distribution power system and rationality fuzzy comprehensive evaluation of mining ventilation system.",,
[No author name available],"9th Mexican International Conference on Artificial Intelligence, MICAI 2010",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038358391&partnerID=40&md5=3c9a0b177b2edbd9b57a74af22ca1ec0","The proceedings contain 43 papers. The special focus in this conference is on Artificial Intelligence. The topics include: Music Composition Based on Linguistic Approach; a Practical Robot Coverage Algorithm for Unknown Environments; an Algorithm for the Automatic Generation of Human-Like Motions Based on Examples; line Maps in Cluttered Environments; fuzzy Cognitive Maps for Modeling Complex Systems; semantic Representation and Management of Student Models: An Approach to Adapt Lecture Sequencing to Enhance Learning; an Effective Heuristic for the No-Wait Flowshop with Sequence-Dependent Setup Times Problem; optimizing Alternatives in Precedence Networks; AI-Based Integrated Scheduling of Production and Transportation Operations within Military Supply Chains; discourse Segmentation for Spanish Based on Shallow Parsing; turbo Codification Techniques for Error Control in a Communication Channel; a New Graphical Recursive Pruning Method for the Incremental Pruning Algorithm; a New Pruning Method for Incremental Pruning Algorithm Using a Sweeping Scan-Line through the Belief Space; POMDP Filter: Pruning POMDP Value Functions with the Kaczmarz Iterative Method; Testing Image Segmentation for Topological SLAM with Omnidirectional Images; automatic Image Annotation Using Multiple Grid Segmentation; spatio-temporal Image Tracking Based on Optical Flow and Clustering: An Endoneurosonographic Application; one Trilateral Filter Based on Surface Normal; beta-Measure for Probabilistic Segmentation; robust Spatial Regularization and Velocity Layer Separation for Optical Flow Computation on Transparent Sequences; towards Document Plagiarism Detection Based on the Relevance and Fragmentation of the Reused Text; SAR Image Denoising Using the Non-Subsampled Contourlet Transform and Morphological Operators; scheme-Based Synthesis of Inductive Theories; a Possibilistic Intuitionistic Logic; massive Particles for Brain Tractography.",,
[No author name available],"9th Mexican International Conference on Artificial Intelligence, MICAI 2010",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038232348&partnerID=40&md5=37389033c79b9ced51d1b54b05df4811","The proceedings contain 84 papers. The special focus in this conference is on Artificial Intelligence. The topics include: Music Composition Based on Linguistic Approach; a Practical Robot Coverage Algorithm for Unknown Environments; an Algorithm for the Automatic Generation of Human-Like Motions Based on Examples; line Maps in Cluttered Environments; fuzzy Cognitive Maps for Modeling Complex Systems; semantic Representation and Management of Student Models: An Approach to Adapt Lecture Sequencing to Enhance Learning; an Effective Heuristic for the No-Wait Flowshop with Sequence-Dependent Setup Times Problem; optimizing Alternatives in Precedence Networks; AI-Based Integrated Scheduling of Production and Transportation Operations within Military Supply Chains; discourse Segmentation for Spanish Based on Shallow Parsing; turbo Codification Techniques for Error Control in a Communication Channel; a New Graphical Recursive Pruning Method for the Incremental Pruning Algorithm; a New Pruning Method for Incremental Pruning Algorithm Using a Sweeping Scan-Line through the Belief Space; POMDP Filter: Pruning POMDP Value Functions with the Kaczmarz Iterative Method; Testing Image Segmentation for Topological SLAM with Omnidirectional Images; automatic Image Annotation Using Multiple Grid Segmentation; spatio-temporal Image Tracking Based on Optical Flow and Clustering: An Endoneurosonographic Application; one Trilateral Filter Based on Surface Normal; beta-Measure for Probabilistic Segmentation; robust Spatial Regularization and Velocity Layer Separation for Optical Flow Computation on Transparent Sequences; towards Document Plagiarism Detection Based on the Relevance and Fragmentation of the Reused Text; SAR Image Denoising Using the Non-Subsampled Contourlet Transform and Morphological Operators; scheme-Based Synthesis of Inductive Theories; a Possibilistic Intuitionistic Logic; massive Particles for Brain Tractography.",,
[No author name available],"Proceedings - 24th EUROMICRO Conference, EURMIC 1998",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051245615&partnerID=40&md5=0cbfb30ebf71405aea646eac37b659c1","The proceedings contain 163 papers. The topics discussed include: using sound to communicate program execution; experiments with MHEG player/studio: an interactive hypermedia visualization and authoring system; on function approximators implementable as layered neural networks; a transparent and flexible development environment for rapid design of cognitive systems; integration of image processing and automated testing in a manufacturing client-server network; novel internal units for a neural network based adaptive fuzzy inference systems; process improvement by change of paradigm in an agriculture company; managing change in software development using a process improvement approach; a change process model in an SCM tool; software process improvement planning with neural networks; measuring the effectiveness of introducing new methods in the software development process; performance and quality aspects of virtual software enterprises; an approach to schedule estimation and tracking for rapid development projects; test tools for the year 2000 challenges; practical aspects on the assessment of a review process; performing high-level synthesis via program transformations within a theorem prover; specification of exception handling in grammar-based hardware synthesis; and rule base driven conversion of an object oriented design data structure into standard hardware description languages.",,
